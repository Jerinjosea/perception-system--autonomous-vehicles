{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "SingleImgDepthYoloNotebook.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "t51RsFcXEMHk",
        "m0jfQRuyqhHq",
        "IwvIc7iFZ__d",
        "8_2iY7HwCTlm"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7471a85327c94be7ade9ec458ad9c2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e979c5d3a9064163a52f8b1d3e4c9e06",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_911495f95a314edeb7991fbf8eb1f9b8",
              "IPY_MODEL_8316d5b506f941ad895849c9c1267dc2"
            ]
          }
        },
        "e979c5d3a9064163a52f8b1d3e4c9e06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "911495f95a314edeb7991fbf8eb1f9b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_71422304fd664c7eb9fe037b8747bfed",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2e723bcd0f8466a867feee83964ca51"
          }
        },
        "8316d5b506f941ad895849c9c1267dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9135e14591284d039d6cff7ad9ba8774",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/3 [00:00&lt;?, ?epoch/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14f7924c51334a348f5e837f8a38deb2"
          }
        },
        "71422304fd664c7eb9fe037b8747bfed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2e723bcd0f8466a867feee83964ca51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9135e14591284d039d6cff7ad9ba8774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14f7924c51334a348f5e837f8a38deb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EU_yqgXM4XV"
      },
      "source": [
        "#Anchor Box Calculation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2N5uR4jM32T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        },
        "outputId": "55dfbaf7-cd3c-4182-a860-4d01e0b26032"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class main:\n",
        "  def __init__(self,no):\n",
        "    self.num_clusters = no\n",
        "\n",
        "   \n",
        "args = main(9)\n",
        "\n",
        "'''\n",
        "Created on Feb 20, 2017\n",
        "@author: jumabek\n",
        "'''\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import argparse\n",
        "#import cv2\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import random \n",
        "import math\n",
        "\n",
        "width_in_cfg_file = 1248.\n",
        "height_in_cfg_file = 1248.\n",
        "\n",
        "def IOU(X,centroids):\n",
        "    similarities = []\n",
        "    k = len(centroids)\n",
        "    for centroid in centroids:\n",
        "        c_x,c_y,c_z = centroid\n",
        "        x,y,z = X\n",
        "        inner_vol = min(x,c_x)*min(y,c_y)*min(z,c_z)\n",
        "        similarity = inner_vol/((x*y*z+c_x*c_y*c_z)-inner_vol)\n",
        "        similarities.append(similarity) # will become (k,) shape\n",
        "    return np.array(similarities) \n",
        "\n",
        "def avg_IOU(X,centroids):\n",
        "    n,d = X.shape\n",
        "    sum = 0.\n",
        "    for i in range(X.shape[0]):\n",
        "        #note IOU() will return array which contains IoU for each centroid and X[i] // slightly ineffective, but I am too lazy\n",
        "        sum+= max(IOU(X[i],centroids)) \n",
        "    return sum/n\n",
        "\n",
        "def write_anchors_to_file(centroids,X,anchor_file):\n",
        "    f = open(anchor_file,'w')\n",
        "    \n",
        "    anchors = centroids.copy()\n",
        "    print(anchors.shape)\n",
        "\n",
        "    for i in range(anchors.shape[0]):\n",
        "        anchors[i][0]*=width_in_cfg_file\n",
        "        anchors[i][1]*=height_in_cfg_file\n",
        "        anchors[i][2]*= 5\n",
        "         \n",
        "\n",
        "    widths = anchors[:,0]+ anchors[:,1]\n",
        "    sorted_indices = np.argsort(widths)\n",
        "\n",
        "    print('Anchors = ', anchors[sorted_indices])\n",
        "        \n",
        "    for i in sorted_indices[:-1]:\n",
        "        f.write('%0.5f,%0.5f,%0.5f, '%(anchors[i,0],anchors[i,1],anchors[i,2]))\n",
        "\n",
        "    #there should not be comma after last anchor, that's why\n",
        "    f.write('%0.5f,%0.5f,%0.5f\\n'%(anchors[sorted_indices[-1:],0],anchors[sorted_indices[-1:],1],anchors[sorted_indices[-1:],2]))\n",
        "    \n",
        "    f.write('%f\\n'%(avg_IOU(X,centroids)))\n",
        "    plt.scatter(centroids.shape[0], avg_IOU(X,centroids))\n",
        "\n",
        "def kmeans(X,centroids,eps,anchor_file):\n",
        "    \n",
        "    N = X.shape[0]\n",
        "    iterations = 0\n",
        "    k,dim = centroids.shape\n",
        "    print(\"k,dim =\",k,dim)\n",
        "    prev_assignments = np.ones(N)*(-1)    \n",
        "    iter = 0\n",
        "    old_D = np.zeros((N,k))\n",
        "\n",
        "    while True:\n",
        "        D = [] \n",
        "        iter+=1           \n",
        "        for i in range(N):\n",
        "            d = 1 - IOU(X[i],centroids)\n",
        "            D.append(d)\n",
        "        D = np.array(D) # D.shape = (N,k)\n",
        "        \n",
        "        print(\"iter {}: dists = {}\".format(iter,np.sum(np.abs(old_D-D))))\n",
        "            \n",
        "        #assign samples to centroids \n",
        "        assignments = np.argmin(D,axis=1)\n",
        "        \n",
        "        if (assignments == prev_assignments).all() :\n",
        "            print(\"Centroids = \",centroids)\n",
        "            write_anchors_to_file(centroids,X,anchor_file)\n",
        "            return\n",
        "\n",
        "        #calculate new centroids\n",
        "        centroid_sums=np.zeros((k,dim),np.float)\n",
        "        for i in range(N):\n",
        "            centroid_sums[assignments[i]]+=X[i]        \n",
        "        for j in range(k):            \n",
        "            centroids[j] = centroid_sums[j]/(np.sum(assignments==j))\n",
        "        \n",
        "        prev_assignments = assignments.copy()     \n",
        "        old_D = D.copy()  \n",
        "\n",
        "    \n",
        "\n",
        "annotation_dims = []\n",
        "\n",
        "size = np.zeros((1,1,3))\n",
        "file_path = '/gdrive/My Drive/data/'\n",
        "for scene  in nusc.scene :\n",
        "  sample_token = scene['first_sample_token']\n",
        "  sample = nusc.get('sample',sample_token)\n",
        "  sensor = 'LIDAR_TOP'\n",
        "  lidar_top_data = nusc.get('sample_data', sample['data'][sensor])\n",
        "  ego_pose = nusc.get('ego_pose', lidar_top_data['ego_pose_token'])\n",
        "  for annotation in sample['anns']:\n",
        "    annotation = nusc.get('sample_annotation',annotation)\n",
        "    x,y,z = annotation['size']\n",
        "    x = float(x) / 140.\n",
        "    y = float(y) / 140.\n",
        "    z = float(z) / 5.\n",
        "    annotation_dims.append(tuple(map(float,(x,y,z))))\n",
        "#print(annotation_dims)  \n",
        "annotation_dims = np.array(annotation_dims)\n",
        "\n",
        "eps = 0.005\n",
        "\n",
        "if args.num_clusters == 0:\n",
        "    for num_clusters in range(1,11): #we make 1 through 10 clusters \n",
        "        anchor_file = 'anchors%d.txt'%(num_clusters)\n",
        "\n",
        "        indices = [ random.randrange(annotation_dims.shape[0]) for i in range(num_clusters)]\n",
        "        centroids = annotation_dims[indices]\n",
        "        kmeans(annotation_dims,centroids,eps,anchor_file)\n",
        "        print('centroids.shape', centroids.shape)\n",
        "else:\n",
        "    anchor_file = 'anchors%d.txt'%(args.num_clusters)\n",
        "    indices = [ random.randrange(annotation_dims.shape[0]) for i in range(args.num_clusters)]\n",
        "    centroids = annotation_dims[indices]\n",
        "    kmeans(annotation_dims,centroids,eps,anchor_file)\n",
        "    print('centroids.shape', centroids.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k,dim = 9 3\n",
            "iter 1: dists = 2008.8511362947934\n",
            "iter 2: dists = 148.06174692543664\n",
            "iter 3: dists = 126.85651053757705\n",
            "iter 4: dists = 52.696428972132054\n",
            "iter 5: dists = 73.18639120720397\n",
            "iter 6: dists = 34.29783300882434\n",
            "iter 7: dists = 18.73626612605078\n",
            "iter 8: dists = 21.718356518589218\n",
            "iter 9: dists = 25.323835754230295\n",
            "iter 10: dists = 27.426342100837054\n",
            "iter 11: dists = 17.162267348407312\n",
            "iter 12: dists = 11.091516384992842\n",
            "iter 13: dists = 5.215621621679143\n",
            "iter 14: dists = 11.138090208285835\n",
            "iter 15: dists = 10.20486098591151\n",
            "iter 16: dists = 5.121823042387248\n",
            "iter 17: dists = 1.965023341247727\n",
            "iter 18: dists = 1.2500247812116378\n",
            "iter 19: dists = 5.41486612437906\n",
            "iter 20: dists = 3.5481020177110727\n",
            "iter 21: dists = 3.182340860223835\n",
            "iter 22: dists = 0.8699741538837484\n",
            "Centroids =  [[0.01904226 0.05000714 0.57981667]\n",
            " [0.01292338 0.03109058 0.31196364]\n",
            " [0.00437949 0.00429515 0.33207692]\n",
            " [0.01426509 0.03369488 0.33257358]\n",
            " [0.03385    0.00955714 0.2802    ]\n",
            " [0.00541857 0.00702296 0.34746   ]\n",
            " [0.02044107 0.08856518 0.812525  ]\n",
            " [0.01698816 0.00436449 0.2062    ]\n",
            " [0.0148418  0.03654656 0.39955556]]\n",
            "(9, 3)\n",
            "Anchors =  [[  5.4656       5.36034286   1.66038462]\n",
            " [  6.76237714   8.76465306   1.7373    ]\n",
            " [ 21.20122776   5.44688327   1.031     ]\n",
            " [ 42.2448      11.92731429   1.401     ]\n",
            " [ 16.12837403  38.80104935   1.55981818]\n",
            " [ 17.80283774  42.05120863   1.66286792]\n",
            " [ 18.52256508  45.61010794   1.99777778]\n",
            " [ 23.76474286  62.40891429   2.89908333]\n",
            " [ 25.51045714 110.52934286   4.062625  ]]\n",
            "centroids.shape (9, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAT+klEQVR4nO3dcayd9X3f8fenJgayKMGD26nYDvZWJ8AWFqenKGnGujSjcZkU0yjqrls2sUVDW4K1oSQqkbooYqq6LK2oqtJ2zoaiRhoWchnyJDKTjqRdF9P5UAhgI6M7J8PXRN3tVK+ioTF2vvvjPC7Hx9c+5+Lje+2f3y/pyOf5/X7Pud/z872f+9znec7zpKqQJLXrB1a6AEnS+WXQS1LjDHpJapxBL0mNM+glqXGXrXQBo6655prasGHDSpchSReVp5566k+qamaxvgsu6Dds2EC/31/pMiTpopLkf5+pz103ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMZNFPRJtiQ5mGQuyb2L9L89ydeSPJ3k2SS3de1Xd+2vJPn1aRcvSRpvbNAnWQU8APwUcCOwLcmNI8N+AXi4qjYDs8BvdO1/Afxr4FNTq1iStCSTbNHfDMxV1aGqOgbsBLaOjCngrd3ztwEvA1TVn1fVHzAIfEnSCpgk6NcCh4eW57u2YZ8D7kgyDzwGbF9KEUnuStJP0l9YWFjKqpKkMaZ1MHYb8KWqWgfcBnw5ycSvXVU7qqpXVb2ZmUUvviZJeoMmCeMjwPqh5XVd27CPAQ8DVNVe4ArgmmkUKEk6N5ME/T5gU5KNSVYzONi6e2TMS8AHAZLcwCDo3QcjSReAsdejr6rjSe4G9gCrgAeran+S+4B+Ve0GPgl8Mck9DA7M3llVBZDk2wwO1K5Ocjvwk1V14Py8HUnSqIluPFJVjzE4yDrc9tmh5weA959h3Q3nUJ8k6Rz5yVhJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMmCvokW5IcTDKX5N5F+t+e5GtJnk7ybJLbhvo+0613MMmHplm8JGm8sXeYSrIKeAC4FZgH9iXZPXI7wF8AHq6q30xyI4O7UW3ons8CfxO4FvjdJO+oqhPTfiOSpMVNskV/MzBXVYeq6hiwE9g6MqYY3BcW4G3Ay93zrcDOqvpeVX0LmOteT5K0TCYJ+rXA4aHl+a5t2OeAO5LMM9ia376EdUlyV5J+kv7CwsKEpUuSJjGtg7HbgC9V1TrgNuDLSSZ+7araUVW9qurNzMxMqSRJEkywjx44AqwfWl7XtQ37GLAFoKr2JrkCuGbCdSVJ59EkW937gE1JNiZZzeDg6u6RMS8BHwRIcgNwBbDQjZtNcnmSjcAm4H9Oq3hJ0nhjt+ir6niSu4E9wCrgwaran+Q+oF9Vu4FPAl9Mcg+DA7N3VlUB+5M8DBwAjgOf8IwbSVpeGeTxhaPX61W/31/pMiTpopLkqarqLdbnJ2MlqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcRMFfZItSQ4mmUty7yL99yd5pnu8mOToUN/nkzzfPf7hNIuXJI039p6xSVYBDwC3AvPAviS7q+rAyTFVdc/Q+O3A5u75PwDeA7wbuBz4epKvVNWfTfVdSJLOaJIt+puBuao6VFXHgJ3A1rOM3wY81D2/Efj9qjpeVX8OPAtsOZeCJUlLM0nQrwUODy3Pd22nSXIdsBF4omv6JrAlyZuTXAN8AFi/yHp3Jekn6S8sLCylfknSGNM+GDsL7KqqEwBV9TjwGPANBlv5e4EToytV1Y6q6lVVb2ZmZsolSdKlbZKgP8KpW+HrurbFzPL6bhsAquoXq+rdVXUrEODFN1KoJOmNmSTo9wGbkmxMsppBmO8eHZTkemANg632k22rklzdPb8JuAl4fBqFS5ImM/asm6o6nuRuYA+wCniwqvYnuQ/oV9XJ0J8FdlZVDa3+JuC/JwH4M+COqjo+1XcgSTqrnJrLK6/X61W/31/pMiTpopLkqarqLdbnJ2MlqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY2bKOiTbElyMMlcknsX6b8/yTPd48UkR4f6/l2S/UleSPJr6W43JUlaHmNvJZhkFfAAcCswD+xLsruqDpwcU1X3DI3fDmzunv8Y8H4G94oF+APgx4GvT6l+SdIYk2zR3wzMVdWhqjoG7AS2nmX8NuCh7nkBVwCrgcsZ3EP2j994uZKkpZok6NcCh4eW57u20yS5DtgIPAFQVXuBrwHf6R57quqFcylYkrQ00z4YOwvsqqoTAEl+GLgBWMfgl8NPJLlldKUkdyXpJ+kvLCxMuSRJurRNEvRHgPVDy+u6tsXM8vpuG4CfBp6sqleq6hXgK8D7Rleqqh1V1auq3szMzGSVS5ImMknQ7wM2JdmYZDWDMN89OijJ9cAaYO9Q80vAjye5LMmbGByIddeNJC2jsUFfVceBu4E9DEL64aran+S+JB8eGjoL7KyqGmrbBfwv4Dngm8A3q+q/TK16SdJYOTWXV16v16t+v7/SZUjSRSXJU1XVW6zPT8ZKUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNG3srQUnw6NNH+MKeg7x89FWuvepKPv2hd3L75kXvvyNdcAx6aYxHnz7CZx55jldfOwHAkaOv8plHngMw7HVRcNeNNMYX9hz8y5A/6dXXTvCFPQdXqCJpaQx6aYyXj766pHbpQmPQS2Nce9WVS2qXLjQGvTTGpz/0Tq5806pT2q580yo+/aF3rlBF0tJMFPRJtiQ5mGQuyb2L9N+f5Jnu8WKSo137B4ban0nyF0lun/abkM6n2zev5Zc+8i7WXnUlAdZedSW/9JF3eSBWF42xtxJMsgp4EbgVmGdws/BtVXXgDOO3A5ur6p+OtP9VYA5YV1XfPdPX81aCkrR053orwZuBuao6VFXHgJ3A1rOM3wY8tEj7R4GvnC3kJUnTN0nQrwUODy3Pd22nSXIdsBF4YpHuWRb/BUCSu5L0k/QXFhYmKEmSNKlpH4ydBXZV1SknHSf5IeBdwJ7FVqqqHVXVq6rezMzMlEuSpEvbJEF/BFg/tLyua1vMmbbafwb4z1X12tLKkySdq0mCfh+wKcnGJKsZhPnu0UFJrgfWAHsXeY0z7beXJJ1nY4O+qo4DdzPY7fIC8HBV7U9yX5IPDw2dBXbWyGk8STYw+Ivg96ZVtCRpcmNPr1xunl4pSUt3rqdXSpIuYga9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxEwV9ki1JDiaZS3LvIv33J3mme7yY5OhQ39uTPJ7khSQHulsLSpKWyWXjBiRZBTwA3ArMA/uS7K6qAyfHVNU9Q+O3A5uHXuK3gV+sqq8meQvw/WkVL0kab5It+puBuao6VFXHgJ3A1rOM3wY8BJDkRuCyqvoqQFW9UlXfPceaJUlLMEnQrwUODy3Pd22nSXIdsBF4omt6B3A0ySNJnk7yhe4vhNH17krST9JfWFhY2juQJJ3VtA/GzgK7qupEt3wZcAvwKeBHgb8O3Dm6UlXtqKpeVfVmZmamXJIkXdomCfojwPqh5XVd22Jm6XbbdOaBZ7rdPseBR4H3vJFCJUlvzCRBvw/YlGRjktUMwnz36KAk1wNrgL0j616V5ORm+k8AB0bXlSSdP2ODvtsSvxvYA7wAPFxV+5Pcl+TDQ0NngZ1VVUPrnmCw2+a/JXkOCPDFab4BSdLZZSiXLwi9Xq/6/f5KlyFJF5UkT1VVb7E+PxkrSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWrcREGfZEuSg0nmkty7SP/9SZ7pHi8mOTrUd2Ko77RbEEqSzq/Lxg1Isgp4ALiVwc2+9yXZXVV/ee/XqrpnaPx2YPPQS7xaVe+eXsmSpKWYZIv+ZmCuqg5V1TFgJ7D1LOO3AQ9NozhJ0rmbJOjXAoeHlue7ttMkuQ7YCDwx1HxFkn6SJ5Pcfob17urG9BcWFiYsXZI0iWkfjJ0FdlXViaG267ob1v4s8KtJ/sboSlW1o6p6VdWbmZmZckmSdGmbJOiPAOuHltd1bYuZZWS3TVUd6f49BHydU/ffS5LOs0mCfh+wKcnGJKsZhPlpZ88kuR5YA+wdaluT5PLu+TXA+4EDo+tKks6fsWfdVNXxJHcDe4BVwINVtT/JfUC/qk6G/iyws6pqaPUbgH+f5PsMfqn82+GzdSRJ519OzeWV1+v1qt/vr3QZknRRSfJUdzz0NH4yVpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekho3UdAn2ZLkYJK5JPcu0n9/kme6x4tJjo70vzXJfJJfn1bhkqTJjL1nbJJVwAPArcA8sC/J7uF7v1bVPUPjtwObR17m3wC/P5WKJUlLMskW/c3AXFUdqqpjwE5g61nGbwMeOrmQ5EeAvwY8fi6FSpLemEmCfi1weGh5vms7TZLrgI3AE93yDwC/AnzqbF8gyV1J+kn6CwsLk9QtSZrQtA/GzgK7qupEt/xx4LGqmj/bSlW1o6p6VdWbmZmZckmSdGkbu48eOAKsH1pe17UtZhb4xNDy+4BbknwceAuwOskrVXXaAV1J0vkxSdDvAzYl2cgg4GeBnx0dlOR6YA2w92RbVf3cUP+dQM+Ql6TlNXbXTVUdB+4G9gAvAA9X1f4k9yX58NDQWWBnVdX5KVWS9EbkQsvlXq9X/X5/pcuQpItKkqeqqrdYn5+MlaTGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1bqKgT7IlycEkc0lOuxVgkvuTPNM9XkxytGu/Lskfde37k/zzab8BSdLZjb1nbJJVwAPArcA8sC/J7qo6cHJMVd0zNH47sLlb/A7wvqr6XpK3AM936748zTchSTqzSbbobwbmqupQVR0DdgJbzzJ+G/AQQFUdq6rvde2XT/j1JElTNEnwrgUODy3Pd22nSXIdsBF4YqhtfZJnu9f4vFvzkrS8xu66WaJZYFdVnTjZUFWHgZuSXAs8mmRXVf3x8EpJ7gLu6hZfSXJwynUt1TXAn6xwDRcK5+JUzsfrnItTrfR8XHemjkmC/giwfmh5Xde2mFngE4t1VNXLSZ4HbgF2jfTtAHZMUMuySNI/093ULzXOxamcj9c5F6e6kOdjkl03+4BNSTYmWc0gzHePDkpyPbAG2DvUti7Jld3zNcDfAVZ6a12SLiljt+ir6niSu4E9wCrgwaran+Q+oF9VJ0N/FthZVTW0+g3AryQpIMAvV9Vz030LkqSzmWgffVU9Bjw20vbZkeXPLbLeV4GbzqG+lXLB7Ea6ADgXp3I+XudcnOqCnY+cugEuSWqN57VLUuMMeklq3CUb9Enu6a6/83ySh5JcsciYn0lyoBv3n1aizuUybj6SvD3J15I8neTZJLetVK3LIcm/7OZif5J/tUh/kvxad/2nZ5O8ZyXqXA4TzMXPdXPwXJJvJPnbK1Hnchk3H0PjfjTJ8SQfXc76FlVVl9yDwSd7vwVc2S0/DNw5MmYT8DSwplv+wZWue4XnYwfwL7rnNwLfXum6z+N8/C3geeDNDE5Y+F3gh0fG3AZ8hcHZZO8F/nCl617BufixoZ+Tn2p1Liadj27cKgZXCHgM+OhK133JbtEz+E+6MsllDP7TRi/N8M+AB6rqTwGq6v8sc33Lbdx8FPDW7vnbFulvyQ0Mwuq7VXUc+D3gIyNjtgK/XQNPAlcl+aHlLnQZjJ2LqvrGyZ8T4EkGH6ps1STfGwDbgd8BLojcuCSDvqqOAL8MvMTgCpv/r6oeHxn2DuAdSf5HkieTbFnuOpfLhPPxOeCOJPMMtlK2L2uRy+t54JYkVyd5M4Ot9/UjYya+BtRFbpK5GPYxBn/ptGrsfCRZC/w08JsrUN+iLsmg7z6lu5XBBdiuBf5KkjtGhl3GYPfN32NwRc4vJrlqOetcLhPOxzbgS1W1jsE395eTNPn9U1UvAJ8HHgf+K/AMcOKsKzVqKXOR5AMMgv7nl63AZTbhfPwq8PNV9f1lLu+MmvxBncDfB75VVQtV9RrwCIP9jMPmgd1V9VpVfQt4kUHwt2iS+fgYg333VNVe4AoGF3FqUlX9x6r6kar6u8CfMvj/H7aUa0Bd1CaYC5LcBPwHYGtV/d/lrnE5TTAfPWBnkm8DHwV+I8nty1zmKS7VoH8JeG+SNycJ8EHghZExjzLYmifJNQx25RxaziKX0STz8VLXTpIbGAT9wrJWuYyS/GD379sZ7IMdPetqN/CPu7Nv3stgd9d3lrnMZTFuLrr2R4B/VFWn/RJozbj5qKqNVbWhqjYwuIDjx6vq0WUvdMi0L1N8UaiqP0yyC/gj4DiDs2t2jFy/Zw/wk0kOMPjT7NOtbqlMOB+fZLD76h4GB2bvrO70gkb9TpKrgdeAT1TV0ZO3wqyq32JwnOI2YA74LvBPVqzS82/cXHwWuJrBlivA8bpAr+I4JePm44LjJRAkqXGX6q4bSbpkGPSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcf8fsmUF3ALpu5QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu1geigrSzaD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40928b10-35dd-4db3-c2a4-68c5f5908ca0"
      },
      "source": [
        "from collections import Counter \n",
        "\n",
        "annotation_dims = []\n",
        "cat = []\n",
        "size = np.zeros((1,1,3))\n",
        "file_path = '/gdrive/My Drive/data/'\n",
        "for scene  in nusc.scene :\n",
        "  sample_token = scene['first_sample_token']\n",
        "  sample = nusc.get('sample',sample_token)\n",
        "  sensor = 'LIDAR_TOP'\n",
        "  lidar_top_data = nusc.get('sample_data', sample['data'][sensor])\n",
        "  ego_pose = nusc.get('ego_pose', lidar_top_data['ego_pose_token'])\n",
        "  for annotation in sample['anns']:\n",
        "    annotation = nusc.get('sample_annotation',annotation)\n",
        "    print(annotation['size'],annotation['category_name'])\n",
        "    x,y,z = annotation['size']\n",
        "    cat.append(annotation['category_name'])\n",
        "    #x = float(x) / 140.\n",
        "    #y = float(y) / 140.\n",
        "    #z = float(z) / 5.\n",
        "    annotation_dims.append(tuple(map(float,(x,y,z))))\n",
        "print(annotation_dims)\n",
        "d = Counter(cat)   \n",
        "print(d)\n",
        "print(annotation_dims[1])\n",
        "print(max(x[0] for x in annotation_dims))\n",
        "print(max(x[1] for x in annotation_dims))\n",
        "print(max(x[2] for x in annotation_dims))\n",
        "#print(sum(annotation_dims[:,1]))\n",
        "#print(sum(annotation_dims[:,2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.621, 0.669, 1.642] human.pedestrian.adult\n",
            "[0.775, 0.769, 1.711] human.pedestrian.adult\n",
            "[2.011, 4.633, 1.573] vehicle.car\n",
            "[0.752, 0.819, 1.637] human.pedestrian.adult\n",
            "[0.427, 0.359, 0.794] movable_object.trafficcone\n",
            "[0.689, 1.77, 1.709] vehicle.bicycle\n",
            "[0.661, 0.703, 1.839] human.pedestrian.adult\n",
            "[1.837, 4.32, 1.631] vehicle.car\n",
            "[0.648, 0.709, 1.609] human.pedestrian.adult\n",
            "[1.977, 0.703, 1.149] movable_object.barrier\n",
            "[1.91, 0.555, 1.055] movable_object.barrier\n",
            "[1.019, 0.915, 1.67] human.pedestrian.adult\n",
            "[0.934, 0.891, 1.835] human.pedestrian.adult\n",
            "[0.8, 0.908, 1.835] human.pedestrian.adult\n",
            "[0.872, 0.903, 1.719] human.pedestrian.adult\n",
            "[1.964, 0.694, 1.131] movable_object.barrier\n",
            "[1.708, 4.01, 1.631] vehicle.car\n",
            "[0.79, 0.741, 1.725] human.pedestrian.adult\n",
            "[2.877, 10.201, 3.595] vehicle.truck\n",
            "[2.135, 4.956, 2.17] vehicle.car\n",
            "[0.767, 0.951, 1.835] human.pedestrian.adult\n",
            "[1.967, 0.704, 0.962] movable_object.barrier\n",
            "[2.06, 0.759, 1.1] movable_object.barrier\n",
            "[1.993, 0.744, 1.245] movable_object.barrier\n",
            "[0.476, 0.461, 0.72] movable_object.trafficcone\n",
            "[1.969, 0.716, 1.092] movable_object.barrier\n",
            "[2.909, 6.908, 3.558] vehicle.bus.rigid\n",
            "[0.803, 0.87, 1.78] human.pedestrian.adult\n",
            "[0.842, 0.884, 1.749] human.pedestrian.adult\n",
            "[1.99, 0.726, 0.921] movable_object.barrier\n",
            "[0.708, 0.863, 1.616] human.pedestrian.adult\n",
            "[0.734, 0.775, 1.821] human.pedestrian.adult\n",
            "[2.069, 0.712, 1.088] movable_object.barrier\n",
            "[0.733, 0.746, 1.695] human.pedestrian.adult\n",
            "[0.913, 0.873, 1.697] human.pedestrian.adult\n",
            "[2.05, 0.693, 1.081] movable_object.barrier\n",
            "[1.847, 4.115, 1.526] vehicle.car\n",
            "[1.977, 0.764, 1.144] movable_object.barrier\n",
            "[1.842, 0.677, 0.885] movable_object.barrier\n",
            "[0.793, 1.0, 1.604] human.pedestrian.adult\n",
            "[1.939, 4.819, 1.736] vehicle.car\n",
            "[2.073, 0.633, 1.078] movable_object.barrier\n",
            "[1.945, 0.649, 1.11] movable_object.barrier\n",
            "[3.016, 3.992, 2.916] vehicle.construction\n",
            "[1.964, 0.72, 1.104] movable_object.barrier\n",
            "[1.972, 4.698, 1.581] vehicle.car\n",
            "[0.759, 0.837, 1.916] human.pedestrian.adult\n",
            "[0.739, 0.771, 1.766] human.pedestrian.adult\n",
            "[0.694, 0.902, 1.807] human.pedestrian.adult\n",
            "[0.336, 0.332, 0.693] movable_object.trafficcone\n",
            "[0.751, 0.807, 1.706] human.pedestrian.adult\n",
            "[0.777, 0.958, 1.757] human.pedestrian.adult\n",
            "[1.787, 4.535, 2.059] vehicle.truck\n",
            "[0.942, 1.04, 1.937] human.pedestrian.adult\n",
            "[0.687, 0.716, 1.73] human.pedestrian.adult\n",
            "[0.9, 0.956, 1.827] human.pedestrian.adult\n",
            "[0.728, 0.858, 2.0] human.pedestrian.adult\n",
            "[0.767, 0.872, 1.809] human.pedestrian.adult\n",
            "[0.634, 0.618, 1.752] human.pedestrian.adult\n",
            "[0.599, 0.835, 1.265] movable_object.pushable_pullable\n",
            "[1.908, 0.579, 1.051] movable_object.barrier\n",
            "[2.042, 0.714, 1.073] movable_object.barrier\n",
            "[0.971, 0.937, 1.568] human.pedestrian.adult\n",
            "[2.126, 0.716, 1.031] movable_object.barrier\n",
            "[2.037, 0.731, 1.1] movable_object.barrier\n",
            "[1.907, 4.727, 1.957] vehicle.car\n",
            "[2.034, 0.683, 1.127] movable_object.barrier\n",
            "[1.908, 0.721, 1.106] movable_object.barrier\n",
            "[1.99, 0.651, 1.107] movable_object.barrier\n",
            "[0.621, 0.647, 1.778] human.pedestrian.adult\n",
            "[0.688, 0.944, 1.904] human.pedestrian.adult\n",
            "[0.578, 0.613, 1.752] human.pedestrian.adult\n",
            "[0.909, 1.105, 2.0] human.pedestrian.adult\n",
            "[0.751, 1.03, 1.975] human.pedestrian.adult\n",
            "[2.001, 4.734, 1.481] vehicle.car\n",
            "[0.631, 0.61, 1.929] human.pedestrian.adult\n",
            "[0.697, 0.498, 1.761] human.pedestrian.adult\n",
            "[0.665, 0.736, 1.89] human.pedestrian.adult\n",
            "[1.871, 4.488, 1.515] vehicle.car\n",
            "[0.546, 0.439, 1.622] human.pedestrian.adult\n",
            "[0.64, 0.395, 1.807] human.pedestrian.adult\n",
            "[0.489, 0.491, 1.851] human.pedestrian.adult\n",
            "[0.612, 0.736, 1.877] human.pedestrian.adult\n",
            "[1.803, 4.495, 1.56] vehicle.car\n",
            "[0.585, 0.681, 1.711] human.pedestrian.adult\n",
            "[0.908, 1.109, 2.211] human.pedestrian.adult\n",
            "[0.712, 0.601, 1.891] human.pedestrian.adult\n",
            "[0.755, 1.235, 2.083] human.pedestrian.adult\n",
            "[2.037, 4.958, 1.639] vehicle.car\n",
            "[0.724, 0.828, 1.835] human.pedestrian.adult\n",
            "[0.738, 0.783, 1.52] human.pedestrian.adult\n",
            "[0.699, 0.738, 1.95] human.pedestrian.adult\n",
            "[0.552, 0.918, 1.739] human.pedestrian.adult\n",
            "[0.677, 0.834, 1.658] human.pedestrian.adult\n",
            "[0.525, 1.622, 1.696] vehicle.bicycle\n",
            "[0.547, 0.718, 1.325] human.pedestrian.adult\n",
            "[2.016, 4.752, 1.758] vehicle.car\n",
            "[0.612, 0.798, 1.56] human.pedestrian.adult\n",
            "[2.905, 0.44, 0.92] movable_object.barrier\n",
            "[3.025, 0.396, 1.021] movable_object.barrier\n",
            "[3.586, 0.413, 0.973] movable_object.barrier\n",
            "[0.466, 0.689, 0.842] movable_object.pushable_pullable\n",
            "[1.971, 4.574, 1.499] vehicle.car\n",
            "[3.034, 0.395, 0.94] movable_object.barrier\n",
            "[3.277, 0.533, 0.957] movable_object.barrier\n",
            "[2.725, 9.584, 3.172] vehicle.bus.rigid\n",
            "[1.979, 4.782, 1.954] vehicle.car\n",
            "[2.01, 4.529, 1.704] vehicle.car\n",
            "[2.029, 4.686, 1.569] vehicle.car\n",
            "[2.17, 4.756, 1.917] vehicle.car\n",
            "[0.673, 0.639, 1.821] human.pedestrian.adult\n",
            "[2.33, 14.01, 3.889] vehicle.trailer\n",
            "[3.277, 0.535, 0.909] movable_object.barrier\n",
            "[3.062, 0.416, 0.979] movable_object.barrier\n",
            "[2.339, 6.418, 3.964] vehicle.truck\n",
            "[2.02, 4.59, 1.687] vehicle.car\n",
            "[0.692, 0.756, 1.752] human.pedestrian.adult\n",
            "[3.28, 0.533, 0.91] movable_object.barrier\n",
            "[2.902, 0.488, 0.944] movable_object.barrier\n",
            "[3.118, 0.413, 0.916] movable_object.barrier\n",
            "[3.284, 0.522, 0.91] movable_object.barrier\n",
            "[0.567, 0.882, 1.627] human.pedestrian.adult\n",
            "[2.176, 4.746, 1.748] vehicle.car\n",
            "[1.991, 4.562, 1.494] vehicle.car\n",
            "[2.03, 4.717, 1.387] vehicle.car\n",
            "[2.557, 7.407, 2.811] vehicle.bus.rigid\n",
            "[0.715, 0.935, 1.682] human.pedestrian.adult\n",
            "[2.217, 4.734, 1.981] vehicle.car\n",
            "[0.681, 0.708, 1.986] human.pedestrian.adult\n",
            "[0.921, 1.027, 1.909] human.pedestrian.adult\n",
            "[2.884, 0.422, 0.972] movable_object.barrier\n",
            "[1.861, 4.554, 1.473] vehicle.car\n",
            "[2.065, 4.893, 1.938] vehicle.car\n",
            "[2.06, 5.295, 1.927] vehicle.truck\n",
            "[1.943, 4.959, 1.499] vehicle.car\n",
            "[1.872, 4.791, 1.698] vehicle.car\n",
            "[1.924, 4.782, 1.481] vehicle.car\n",
            "[1.933, 5.006, 1.673] vehicle.car\n",
            "[2.078, 5.765, 2.301] vehicle.car\n",
            "[1.869, 4.73, 1.456] vehicle.car\n",
            "[1.941, 5.375, 1.715] vehicle.truck\n",
            "[0.791, 0.642, 1.911] human.pedestrian.adult\n",
            "[1.907, 4.621, 1.561] vehicle.car\n",
            "[2.026, 4.617, 1.743] vehicle.car\n",
            "[2.045, 4.942, 1.829] vehicle.car\n",
            "[1.886, 4.493, 1.473] vehicle.car\n",
            "[1.998, 5.33, 1.914] vehicle.truck\n",
            "[2.061, 4.433, 1.65] vehicle.car\n",
            "[2.107, 4.086, 1.485] vehicle.car\n",
            "[2.009, 4.306, 1.72] vehicle.car\n",
            "[1.996, 4.572, 1.712] vehicle.car\n",
            "[1.944, 4.622, 1.921] vehicle.car\n",
            "[1.993, 6.049, 2.0] vehicle.truck\n",
            "[2.038, 4.468, 1.758] vehicle.car\n",
            "[2.012, 4.787, 1.831] vehicle.car\n",
            "[1.956, 4.496, 1.766] vehicle.car\n",
            "[2.014, 4.946, 1.692] vehicle.car\n",
            "[2.107, 4.793, 1.744] vehicle.car\n",
            "[2.592, 7.42, 2.558] vehicle.truck\n",
            "[2.185, 5.069, 1.875] vehicle.car\n",
            "[2.167, 5.091, 2.083] vehicle.car\n",
            "[1.891, 4.81, 1.873] vehicle.car\n",
            "[2.525, 7.556, 2.252] vehicle.construction\n",
            "[1.872, 4.495, 1.587] vehicle.car\n",
            "[1.984, 5.291, 1.865] vehicle.truck\n",
            "[1.966, 4.668, 1.851] vehicle.car\n",
            "[2.749, 8.702, 3.078] vehicle.truck\n",
            "[0.558, 0.576, 1.017] movable_object.trafficcone\n",
            "[0.467, 0.555, 1.221] movable_object.trafficcone\n",
            "[0.859, 0.644, 1.135] movable_object.trafficcone\n",
            "[2.06, 4.512, 1.723] vehicle.car\n",
            "[2.09, 4.795, 2.0] vehicle.car\n",
            "[2.003, 4.204, 1.563] vehicle.car\n",
            "[3.132, 13.818, 3.606] vehicle.bus.rigid\n",
            "[2.111, 4.549, 2.347] vehicle.construction\n",
            "[1.874, 3.885, 1.555] vehicle.car\n",
            "[2.094, 5.567, 1.996] vehicle.car\n",
            "[2.073, 4.456, 1.617] vehicle.car\n",
            "[2.115, 4.659, 1.756] vehicle.car\n",
            "[2.052, 5.751, 1.998] vehicle.truck\n",
            "[0.809, 0.737, 1.715] human.pedestrian.adult\n",
            "[0.809, 0.737, 1.658] human.pedestrian.adult\n",
            "[1.834, 4.455, 1.578] vehicle.car\n",
            "[0.809, 0.737, 1.658] human.pedestrian.adult\n",
            "[1.813, 0.636, 0.994] movable_object.barrier\n",
            "[2.932, 6.855, 2.217] vehicle.truck\n",
            "[2.932, 6.855, 2.217] vehicle.truck\n",
            "[2.846, 12.9, 4.581] vehicle.bus.rigid\n",
            "[2.06, 4.398, 1.754] vehicle.car\n",
            "[1.615, 4.448, 1.474] vehicle.car\n",
            "[1.876, 4.319, 1.704] vehicle.car\n",
            "[2.129, 4.584, 1.591] vehicle.car\n",
            "[1.879, 4.496, 1.527] vehicle.car\n",
            "[2.066, 4.502, 1.865] vehicle.car\n",
            "[1.883, 4.398, 1.627] vehicle.car\n",
            "[0.809, 0.737, 1.658] human.pedestrian.adult\n",
            "[0.809, 0.737, 1.658] human.pedestrian.adult\n",
            "[2.732, 5.837, 2.0] vehicle.car\n",
            "[1.862, 4.923, 1.588] vehicle.car\n",
            "[1.743, 4.98, 1.689] vehicle.car\n",
            "[1.955, 5.104, 1.645] vehicle.car\n",
            "[0.583, 0.485, 1.68] human.pedestrian.adult\n",
            "[2.011, 5.159, 1.979] vehicle.car\n",
            "[1.694, 4.594, 1.489] vehicle.car\n",
            "[0.636, 0.58, 1.697] human.pedestrian.adult\n",
            "[1.696, 4.983, 1.604] vehicle.car\n",
            "[0.55, 1.833, 1.21] vehicle.bicycle\n",
            "[0.636, 0.58, 1.281] human.pedestrian.adult\n",
            "[4.739, 1.338, 1.401] static_object.bicycle_rack\n",
            "[1.854, 5.019, 2.0] vehicle.car\n",
            "[2.168, 5.001, 1.831] vehicle.car\n",
            "[2.006, 4.765, 1.548] vehicle.car\n",
            "[1.598, 4.304, 1.485] vehicle.car\n",
            "[2.291, 5.791, 2.981] vehicle.truck\n",
            "[0.636, 0.58, 1.785] human.pedestrian.adult\n",
            "[0.834, 1.128, 1.632] human.pedestrian.adult\n",
            "[0.734, 0.817, 1.807] human.pedestrian.adult\n",
            "[0.636, 0.864, 1.837] human.pedestrian.adult\n",
            "[0.636, 0.58, 1.281] human.pedestrian.adult\n",
            "[0.55, 1.833, 1.137] vehicle.bicycle\n",
            "[0.636, 0.58, 1.785] human.pedestrian.adult\n",
            "[0.636, 0.58, 1.826] human.pedestrian.adult\n",
            "[0.451, 0.894, 1.695] human.pedestrian.adult\n",
            "[1.935, 4.494, 1.537] vehicle.car\n",
            "[0.646, 0.553, 1.737] human.pedestrian.adult\n",
            "[0.636, 0.58, 1.697] human.pedestrian.adult\n",
            "[0.636, 0.58, 1.697] human.pedestrian.adult\n",
            "[0.674, 0.883, 1.78] human.pedestrian.adult\n",
            "[0.636, 0.58, 1.697] human.pedestrian.adult\n",
            "[1.891, 5.048, 1.513] vehicle.car\n",
            "[1.54, 4.031, 1.568] vehicle.car\n",
            "[0.87, 1.189, 1.889] human.pedestrian.adult\n",
            "[0.674, 0.883, 1.829] human.pedestrian.adult\n",
            "[0.509, 0.466, 1.725] human.pedestrian.adult\n",
            "[0.49, 0.768, 1.846] human.pedestrian.adult\n",
            "[1.771, 4.268, 1.643] vehicle.car\n",
            "[2.883, 12.086, 3.419] vehicle.bus.rigid\n",
            "[1.672, 4.478, 1.597] vehicle.car\n",
            "[1.928, 4.916, 1.673] vehicle.car\n",
            "[2.056, 4.49, 1.636] vehicle.car\n",
            "[2.2, 5.02, 1.749] vehicle.car\n",
            "[2.2, 4.545, 1.679] vehicle.car\n",
            "[2.0, 5.093, 1.595] vehicle.car\n",
            "[2.2, 5.257, 2.121] vehicle.car\n",
            "[1.937, 4.419, 1.564] vehicle.car\n",
            "[2.126, 4.583, 1.57] vehicle.car\n",
            "[2.154, 4.582, 1.65] vehicle.car\n",
            "[1.974, 4.623, 1.638] vehicle.car\n",
            "[1.797, 4.099, 1.544] vehicle.car\n",
            "[1.8, 4.4, 1.553] vehicle.car\n",
            "[2.126, 4.592, 1.641] vehicle.car\n",
            "[2.0, 4.32, 1.49] vehicle.car\n",
            "[0.819, 0.675, 1.855] human.pedestrian.adult\n",
            "[0.826, 1.284, 1.869] human.pedestrian.personal_mobility\n",
            "[1.819, 4.727, 2.112] vehicle.car\n",
            "[0.643, 0.548, 1.979] human.pedestrian.adult\n",
            "[0.643, 0.589, 1.752] human.pedestrian.adult\n",
            "[0.643, 0.548, 1.603] human.pedestrian.adult\n",
            "[0.643, 0.548, 1.714] human.pedestrian.adult\n",
            "[0.61, 1.785, 0.953] vehicle.bicycle\n",
            "[2.001, 5.249, 2.037] vehicle.car\n",
            "[0.643, 0.565, 1.879] human.pedestrian.adult\n",
            "[1.821, 4.475, 1.622] vehicle.car\n",
            "[0.643, 0.748, 1.714] human.pedestrian.adult\n",
            "[0.652, 0.638, 1.876] human.pedestrian.adult\n",
            "[0.643, 0.548, 1.714] human.pedestrian.adult\n",
            "[0.643, 0.548, 1.643] human.pedestrian.adult\n",
            "[0.718, 0.804, 1.883] human.pedestrian.adult\n",
            "[3.165, 13.124, 4.593] vehicle.bus.rigid\n",
            "[0.693, 0.716, 1.876] human.pedestrian.adult\n",
            "[1.822, 4.288, 1.85] vehicle.car\n",
            "[1.913, 4.805, 1.577] vehicle.car\n",
            "[0.643, 0.548, 1.714] human.pedestrian.adult\n",
            "[0.643, 0.548, 1.656] human.pedestrian.adult\n",
            "[0.643, 0.548, 1.784] human.pedestrian.adult\n",
            "[0.811, 0.737, 2.043] human.pedestrian.adult\n",
            "[0.643, 0.565, 1.776] human.pedestrian.adult\n",
            "[1.72, 4.614, 1.525] vehicle.car\n",
            "[1.81, 4.519, 1.526] vehicle.car\n",
            "[0.643, 0.548, 1.643] human.pedestrian.adult\n",
            "[0.869, 0.686, 1.745] human.pedestrian.adult\n",
            "[0.643, 0.548, 1.74] human.pedestrian.adult\n",
            "[1.645, 3.96, 1.492] vehicle.car\n",
            "[0.643, 0.548, 1.643] human.pedestrian.adult\n",
            "[0.811, 0.737, 1.752] human.pedestrian.adult\n",
            "[0.747, 0.71, 1.844] human.pedestrian.adult\n",
            "[0.643, 0.548, 1.714] human.pedestrian.adult\n",
            "[0.595, 0.617, 1.73] human.pedestrian.adult\n",
            "[0.643, 0.548, 1.855] human.pedestrian.adult\n",
            "[0.693, 0.716, 1.876] human.pedestrian.adult\n",
            "[0.672, 2.025, 1.223] vehicle.bicycle\n",
            "[0.643, 0.61, 1.888] human.pedestrian.adult\n",
            "[0.643, 0.589, 1.752] human.pedestrian.adult\n",
            "[1.913, 4.805, 1.607] vehicle.car\n",
            "[1.916, 4.886, 1.554] vehicle.car\n",
            "[2.424, 6.524, 3.065] vehicle.car\n",
            "[0.95, 0.844, 1.699] human.pedestrian.adult\n",
            "[0.643, 0.548, 1.97] human.pedestrian.adult\n",
            "[0.643, 0.548, 1.891] human.pedestrian.adult\n",
            "[0.643, 0.548, 1.583] human.pedestrian.adult\n",
            "[0.646, 1.807, 1.082] vehicle.bicycle\n",
            "[0.643, 0.975, 1.943] human.pedestrian.adult\n",
            "[0.643, 0.548, 1.714] human.pedestrian.adult\n",
            "[0.878, 0.879, 1.876] human.pedestrian.adult\n",
            "[0.732, 0.641, 1.632] human.pedestrian.adult\n",
            "[1.803, 4.486, 1.513] vehicle.car\n",
            "[0.556, 0.965, 1.598] human.pedestrian.adult\n",
            "[0.47, 1.268, 1.706] vehicle.motorcycle\n",
            "[1.711, 4.047, 1.637] vehicle.car\n",
            "[0.475, 0.438, 1.796] human.pedestrian.adult\n",
            "[0.592, 0.622, 1.757] human.pedestrian.adult\n",
            "[2.753, 12.145, 4.364] vehicle.bus.rigid\n",
            "[2.908, 10.909, 4.454] vehicle.bus.rigid\n",
            "[0.408, 0.858, 1.713] human.pedestrian.adult\n",
            "[0.555, 0.744, 1.739] human.pedestrian.adult\n",
            "[1.762, 4.181, 1.48] vehicle.car\n",
            "[1.872, 4.327, 1.444] vehicle.car\n",
            "[1.711, 4.047, 1.637] vehicle.car\n",
            "[1.745, 4.736, 1.84] vehicle.car\n",
            "[1.869, 4.4, 1.632] vehicle.car\n",
            "[0.517, 1.284, 1.633] vehicle.motorcycle\n",
            "[1.739, 4.302, 1.566] vehicle.car\n",
            "[1.65, 4.25, 1.529] vehicle.car\n",
            "[0.566, 0.436, 1.69] human.pedestrian.adult\n",
            "[1.865, 4.204, 1.749] vehicle.car\n",
            "[0.585, 0.409, 1.717] human.pedestrian.adult\n",
            "[0.786, 0.765, 1.794] human.pedestrian.adult\n",
            "[1.836, 4.416, 1.43] vehicle.car\n",
            "[(0.621, 0.669, 1.642), (0.775, 0.769, 1.711), (2.011, 4.633, 1.573), (0.752, 0.819, 1.637), (0.427, 0.359, 0.794), (0.689, 1.77, 1.709), (0.661, 0.703, 1.839), (1.837, 4.32, 1.631), (0.648, 0.709, 1.609), (1.977, 0.703, 1.149), (1.91, 0.555, 1.055), (1.019, 0.915, 1.67), (0.934, 0.891, 1.835), (0.8, 0.908, 1.835), (0.872, 0.903, 1.719), (1.964, 0.694, 1.131), (1.708, 4.01, 1.631), (0.79, 0.741, 1.725), (2.877, 10.201, 3.595), (2.135, 4.956, 2.17), (0.767, 0.951, 1.835), (1.967, 0.704, 0.962), (2.06, 0.759, 1.1), (1.993, 0.744, 1.245), (0.476, 0.461, 0.72), (1.969, 0.716, 1.092), (2.909, 6.908, 3.558), (0.803, 0.87, 1.78), (0.842, 0.884, 1.749), (1.99, 0.726, 0.921), (0.708, 0.863, 1.616), (0.734, 0.775, 1.821), (2.069, 0.712, 1.088), (0.733, 0.746, 1.695), (0.913, 0.873, 1.697), (2.05, 0.693, 1.081), (1.847, 4.115, 1.526), (1.977, 0.764, 1.144), (1.842, 0.677, 0.885), (0.793, 1.0, 1.604), (1.939, 4.819, 1.736), (2.073, 0.633, 1.078), (1.945, 0.649, 1.11), (3.016, 3.992, 2.916), (1.964, 0.72, 1.104), (1.972, 4.698, 1.581), (0.759, 0.837, 1.916), (0.739, 0.771, 1.766), (0.694, 0.902, 1.807), (0.336, 0.332, 0.693), (0.751, 0.807, 1.706), (0.777, 0.958, 1.757), (1.787, 4.535, 2.059), (0.942, 1.04, 1.937), (0.687, 0.716, 1.73), (0.9, 0.956, 1.827), (0.728, 0.858, 2.0), (0.767, 0.872, 1.809), (0.634, 0.618, 1.752), (0.599, 0.835, 1.265), (1.908, 0.579, 1.051), (2.042, 0.714, 1.073), (0.971, 0.937, 1.568), (2.126, 0.716, 1.031), (2.037, 0.731, 1.1), (1.907, 4.727, 1.957), (2.034, 0.683, 1.127), (1.908, 0.721, 1.106), (1.99, 0.651, 1.107), (0.621, 0.647, 1.778), (0.688, 0.944, 1.904), (0.578, 0.613, 1.752), (0.909, 1.105, 2.0), (0.751, 1.03, 1.975), (2.001, 4.734, 1.481), (0.631, 0.61, 1.929), (0.697, 0.498, 1.761), (0.665, 0.736, 1.89), (1.871, 4.488, 1.515), (0.546, 0.439, 1.622), (0.64, 0.395, 1.807), (0.489, 0.491, 1.851), (0.612, 0.736, 1.877), (1.803, 4.495, 1.56), (0.585, 0.681, 1.711), (0.908, 1.109, 2.211), (0.712, 0.601, 1.891), (0.755, 1.235, 2.083), (2.037, 4.958, 1.639), (0.724, 0.828, 1.835), (0.738, 0.783, 1.52), (0.699, 0.738, 1.95), (0.552, 0.918, 1.739), (0.677, 0.834, 1.658), (0.525, 1.622, 1.696), (0.547, 0.718, 1.325), (2.016, 4.752, 1.758), (0.612, 0.798, 1.56), (2.905, 0.44, 0.92), (3.025, 0.396, 1.021), (3.586, 0.413, 0.973), (0.466, 0.689, 0.842), (1.971, 4.574, 1.499), (3.034, 0.395, 0.94), (3.277, 0.533, 0.957), (2.725, 9.584, 3.172), (1.979, 4.782, 1.954), (2.01, 4.529, 1.704), (2.029, 4.686, 1.569), (2.17, 4.756, 1.917), (0.673, 0.639, 1.821), (2.33, 14.01, 3.889), (3.277, 0.535, 0.909), (3.062, 0.416, 0.979), (2.339, 6.418, 3.964), (2.02, 4.59, 1.687), (0.692, 0.756, 1.752), (3.28, 0.533, 0.91), (2.902, 0.488, 0.944), (3.118, 0.413, 0.916), (3.284, 0.522, 0.91), (0.567, 0.882, 1.627), (2.176, 4.746, 1.748), (1.991, 4.562, 1.494), (2.03, 4.717, 1.387), (2.557, 7.407, 2.811), (0.715, 0.935, 1.682), (2.217, 4.734, 1.981), (0.681, 0.708, 1.986), (0.921, 1.027, 1.909), (2.884, 0.422, 0.972), (1.861, 4.554, 1.473), (2.065, 4.893, 1.938), (2.06, 5.295, 1.927), (1.943, 4.959, 1.499), (1.872, 4.791, 1.698), (1.924, 4.782, 1.481), (1.933, 5.006, 1.673), (2.078, 5.765, 2.301), (1.869, 4.73, 1.456), (1.941, 5.375, 1.715), (0.791, 0.642, 1.911), (1.907, 4.621, 1.561), (2.026, 4.617, 1.743), (2.045, 4.942, 1.829), (1.886, 4.493, 1.473), (1.998, 5.33, 1.914), (2.061, 4.433, 1.65), (2.107, 4.086, 1.485), (2.009, 4.306, 1.72), (1.996, 4.572, 1.712), (1.944, 4.622, 1.921), (1.993, 6.049, 2.0), (2.038, 4.468, 1.758), (2.012, 4.787, 1.831), (1.956, 4.496, 1.766), (2.014, 4.946, 1.692), (2.107, 4.793, 1.744), (2.592, 7.42, 2.558), (2.185, 5.069, 1.875), (2.167, 5.091, 2.083), (1.891, 4.81, 1.873), (2.525, 7.556, 2.252), (1.872, 4.495, 1.587), (1.984, 5.291, 1.865), (1.966, 4.668, 1.851), (2.749, 8.702, 3.078), (0.558, 0.576, 1.017), (0.467, 0.555, 1.221), (0.859, 0.644, 1.135), (2.06, 4.512, 1.723), (2.09, 4.795, 2.0), (2.003, 4.204, 1.563), (3.132, 13.818, 3.606), (2.111, 4.549, 2.347), (1.874, 3.885, 1.555), (2.094, 5.567, 1.996), (2.073, 4.456, 1.617), (2.115, 4.659, 1.756), (2.052, 5.751, 1.998), (0.809, 0.737, 1.715), (0.809, 0.737, 1.658), (1.834, 4.455, 1.578), (0.809, 0.737, 1.658), (1.813, 0.636, 0.994), (2.932, 6.855, 2.217), (2.932, 6.855, 2.217), (2.846, 12.9, 4.581), (2.06, 4.398, 1.754), (1.615, 4.448, 1.474), (1.876, 4.319, 1.704), (2.129, 4.584, 1.591), (1.879, 4.496, 1.527), (2.066, 4.502, 1.865), (1.883, 4.398, 1.627), (0.809, 0.737, 1.658), (0.809, 0.737, 1.658), (2.732, 5.837, 2.0), (1.862, 4.923, 1.588), (1.743, 4.98, 1.689), (1.955, 5.104, 1.645), (0.583, 0.485, 1.68), (2.011, 5.159, 1.979), (1.694, 4.594, 1.489), (0.636, 0.58, 1.697), (1.696, 4.983, 1.604), (0.55, 1.833, 1.21), (0.636, 0.58, 1.281), (4.739, 1.338, 1.401), (1.854, 5.019, 2.0), (2.168, 5.001, 1.831), (2.006, 4.765, 1.548), (1.598, 4.304, 1.485), (2.291, 5.791, 2.981), (0.636, 0.58, 1.785), (0.834, 1.128, 1.632), (0.734, 0.817, 1.807), (0.636, 0.864, 1.837), (0.636, 0.58, 1.281), (0.55, 1.833, 1.137), (0.636, 0.58, 1.785), (0.636, 0.58, 1.826), (0.451, 0.894, 1.695), (1.935, 4.494, 1.537), (0.646, 0.553, 1.737), (0.636, 0.58, 1.697), (0.636, 0.58, 1.697), (0.674, 0.883, 1.78), (0.636, 0.58, 1.697), (1.891, 5.048, 1.513), (1.54, 4.031, 1.568), (0.87, 1.189, 1.889), (0.674, 0.883, 1.829), (0.509, 0.466, 1.725), (0.49, 0.768, 1.846), (1.771, 4.268, 1.643), (2.883, 12.086, 3.419), (1.672, 4.478, 1.597), (1.928, 4.916, 1.673), (2.056, 4.49, 1.636), (2.2, 5.02, 1.749), (2.2, 4.545, 1.679), (2.0, 5.093, 1.595), (2.2, 5.257, 2.121), (1.937, 4.419, 1.564), (2.126, 4.583, 1.57), (2.154, 4.582, 1.65), (1.974, 4.623, 1.638), (1.797, 4.099, 1.544), (1.8, 4.4, 1.553), (2.126, 4.592, 1.641), (2.0, 4.32, 1.49), (0.819, 0.675, 1.855), (0.826, 1.284, 1.869), (1.819, 4.727, 2.112), (0.643, 0.548, 1.979), (0.643, 0.589, 1.752), (0.643, 0.548, 1.603), (0.643, 0.548, 1.714), (0.61, 1.785, 0.953), (2.001, 5.249, 2.037), (0.643, 0.565, 1.879), (1.821, 4.475, 1.622), (0.643, 0.748, 1.714), (0.652, 0.638, 1.876), (0.643, 0.548, 1.714), (0.643, 0.548, 1.643), (0.718, 0.804, 1.883), (3.165, 13.124, 4.593), (0.693, 0.716, 1.876), (1.822, 4.288, 1.85), (1.913, 4.805, 1.577), (0.643, 0.548, 1.714), (0.643, 0.548, 1.656), (0.643, 0.548, 1.784), (0.811, 0.737, 2.043), (0.643, 0.565, 1.776), (1.72, 4.614, 1.525), (1.81, 4.519, 1.526), (0.643, 0.548, 1.643), (0.869, 0.686, 1.745), (0.643, 0.548, 1.74), (1.645, 3.96, 1.492), (0.643, 0.548, 1.643), (0.811, 0.737, 1.752), (0.747, 0.71, 1.844), (0.643, 0.548, 1.714), (0.595, 0.617, 1.73), (0.643, 0.548, 1.855), (0.693, 0.716, 1.876), (0.672, 2.025, 1.223), (0.643, 0.61, 1.888), (0.643, 0.589, 1.752), (1.913, 4.805, 1.607), (1.916, 4.886, 1.554), (2.424, 6.524, 3.065), (0.95, 0.844, 1.699), (0.643, 0.548, 1.97), (0.643, 0.548, 1.891), (0.643, 0.548, 1.583), (0.646, 1.807, 1.082), (0.643, 0.975, 1.943), (0.643, 0.548, 1.714), (0.878, 0.879, 1.876), (0.732, 0.641, 1.632), (1.803, 4.486, 1.513), (0.556, 0.965, 1.598), (0.47, 1.268, 1.706), (1.711, 4.047, 1.637), (0.475, 0.438, 1.796), (0.592, 0.622, 1.757), (2.753, 12.145, 4.364), (2.908, 10.909, 4.454), (0.408, 0.858, 1.713), (0.555, 0.744, 1.739), (1.762, 4.181, 1.48), (1.872, 4.327, 1.444), (1.711, 4.047, 1.637), (1.745, 4.736, 1.84), (1.869, 4.4, 1.632), (0.517, 1.284, 1.633), (1.739, 4.302, 1.566), (1.65, 4.25, 1.529), (0.566, 0.436, 1.69), (1.865, 4.204, 1.749), (0.585, 0.409, 1.717), (0.786, 0.765, 1.794), (1.836, 4.416, 1.43)]\n",
            "Counter({'human.pedestrian.adult': 130, 'vehicle.car': 117, 'movable_object.barrier': 35, 'vehicle.truck': 14, 'vehicle.bus.rigid': 9, 'vehicle.bicycle': 7, 'movable_object.trafficcone': 6, 'vehicle.construction': 3, 'movable_object.pushable_pullable': 2, 'vehicle.motorcycle': 2, 'vehicle.trailer': 1, 'static_object.bicycle_rack': 1, 'human.pedestrian.personal_mobility': 1})\n",
            "(0.775, 0.769, 1.711)\n",
            "4.739\n",
            "14.01\n",
            "4.593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLnS-Foc5Zav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e06e3494-1f1b-4a33-e56d-ac9ba7edc124"
      },
      "source": [
        "%matplotlib inline\n",
        "from nuscenes.nuscenes import NuScenes \n",
        "\n",
        "nusc = NuScenes(version='v1.0-trainval', dataroot='data', verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======\n",
            "Loading NuScenes tables for version v1.0-trainval...\n",
            "23 category,\n",
            "8 attribute,\n",
            "4 visibility,\n",
            "64386 instance,\n",
            "12 sensor,\n",
            "10200 calibrated_sensor,\n",
            "2631083 ego_pose,\n",
            "68 log,\n",
            "850 scene,\n",
            "34149 sample,\n",
            "2631083 sample_data,\n",
            "1166187 sample_annotation,\n",
            "4 map,\n",
            "Done loading in 36.819 seconds.\n",
            "======\n",
            "Reverse indexing ...\n",
            "Done reverse indexing in 9.3 seconds.\n",
            "======\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNulh2XvM748"
      },
      "source": [
        "#Start off"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5rdnxJVl4LZ",
        "outputId": "e893b766-4b66-4051-b11f-5c096f5faebd"
      },
      "source": [
        "!pip3 install terminaltables\n",
        "!pip install nuscenes-devkit\n",
        "!pip install turfpy\n",
        "!pip install wandb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Building wheels for collected packages: terminaltables\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15358 sha256=0c65552980a5256b232c88fab4f4b9cc9fc1def14fd46d288db0b43d78cc7373\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built terminaltables\n",
            "Installing collected packages: terminaltables\n",
            "Successfully installed terminaltables-3.1.0\n",
            "Collecting nuscenes-devkit\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/bc/02061d53f60ee63a53d714c5adffbe70ed835dde7b916082f224230d49c4/nuscenes_devkit-1.1.1-py3-none-any.whl (265kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nuscenes-devkit) (1.19.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from nuscenes-devkit) (3.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from nuscenes-devkit) (4.1.2.30)\n",
            "Collecting fire\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from nuscenes-devkit) (1.0.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from nuscenes-devkit) (7.0.0)\n",
            "Collecting pyquaternion>=0.9.5\n",
            "  Downloading https://files.pythonhosted.org/packages/49/b3/d8482e8cacc8ea15a356efea13d22ce1c5914a9ee36622ba250523240bf2/pyquaternion-0.9.9-py3-none-any.whl\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from nuscenes-devkit) (1.7.1)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.6/dist-packages (from nuscenes-devkit) (1.1.5)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.6/dist-packages (from nuscenes-devkit) (1.7.0+cu101)\n",
            "Requirement already satisfied: pycocotools>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from nuscenes-devkit) (2.0.2)\n",
            "Collecting motmetrics<=1.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/a6/1e430ce6a3c67996bc0346e9a30f73518f7d44d17c26125a1833a7b2838c/motmetrics-1.1.3-py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nuscenes-devkit) (4.41.1)\n",
            "Requirement already satisfied: descartes in /usr/local/lib/python3.6/dist-packages (from nuscenes-devkit) (1.1.0)\n",
            "Requirement already satisfied: torchvision>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from nuscenes-devkit) (0.8.1+cu101)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from nuscenes-devkit) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from nuscenes-devkit) (1.4.1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.6/dist-packages (from nuscenes-devkit) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nuscenes-devkit) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nuscenes-devkit) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nuscenes-devkit) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nuscenes-devkit) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire->nuscenes-devkit) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire->nuscenes-devkit) (1.1.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->nuscenes-devkit) (5.3.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->nuscenes-devkit) (4.10.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->nuscenes-devkit) (5.0.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->nuscenes-devkit) (5.2.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->nuscenes-devkit) (5.6.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->nuscenes-devkit) (7.5.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->nuscenes-devkit) (2018.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.1->nuscenes-devkit) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.1->nuscenes-devkit) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.1->nuscenes-devkit) (0.16.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.1->nuscenes-devkit) (0.29.21)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.1->nuscenes-devkit) (51.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->nuscenes-devkit) (1.0.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->nuscenes-devkit) (4.7.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->nuscenes-devkit) (4.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->nuscenes-devkit) (2.11.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->nuscenes-devkit) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->nuscenes-devkit) (5.0.8)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->nuscenes-devkit) (1.5.0)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->nuscenes-devkit) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->nuscenes-devkit) (5.3.5)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->nuscenes-devkit) (0.9.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->nuscenes-devkit) (5.5.0)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->nuscenes-devkit) (20.0.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->nuscenes-devkit) (2.6.1)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->nuscenes-devkit) (1.9.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->nuscenes-devkit) (1.0.18)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nuscenes-devkit) (0.6.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nuscenes-devkit) (0.4.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nuscenes-devkit) (1.4.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nuscenes-devkit) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nuscenes-devkit) (3.2.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nuscenes-devkit) (0.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->nuscenes-devkit) (3.5.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook->jupyter->nuscenes-devkit) (4.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->jupyter->nuscenes-devkit) (1.1.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->jupyter->nuscenes-devkit) (2.6.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter->nuscenes-devkit) (0.6.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nuscenes-devkit) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nuscenes-devkit) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nuscenes-devkit) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->nuscenes-devkit) (0.2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->nuscenes-devkit) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->nuscenes-devkit) (20.8)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111006 sha256=02a89500f96df9bfe6890fe1838a65c2193f2ea293469d6be8a3b7a7a95a8617\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, pyquaternion, motmetrics, nuscenes-devkit\n",
            "Successfully installed fire-0.3.1 motmetrics-1.1.3 nuscenes-devkit-1.1.1 pyquaternion-0.9.9\n",
            "Collecting turfpy\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/bb/a33df98337909ad69111b8afc9fb5ef5f7b9b1516282a8aeeb33a5a47394/turfpy-0.0.5.tar.gz\n",
            "Collecting geojson\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/8d/9e28e9af95739e6d2d2f8d4bef0b3432da40b7c3588fbad4298c1be09e48/geojson-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from turfpy) (1.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from turfpy) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from turfpy) (1.19.4)\n",
            "Building wheels for collected packages: turfpy\n",
            "  Building wheel for turfpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for turfpy: filename=turfpy-0.0.5-cp36-none-any.whl size=35769 sha256=f288ea187b05a233d1b68cee6affafeade1a841b5b5c4b895eacb53afb4de667\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/bc/f1/08b44fd3724a9c07109aba1dcae130ec547d4e1dc5aa364ac8\n",
            "Successfully built turfpy\n",
            "Installing collected packages: geojson, turfpy\n",
            "Successfully installed geojson-2.5.0 turfpy-0.0.5\n",
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/5e/9df94df3bfee51b92b54a5e6fa277d6e1fcdf1f27b1872214b98f55ec0f7/wandb-0.10.12-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Collecting watchdog>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/d9/3d1f46b428fd7b646725896b58d2eddb84f79fd76912773e6193cf74263d/watchdog-1.0.2-py3-none-manylinux2014_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/08/b2/ef713e0e67f6e7ec7d59aea3ee78d05b39c15930057e724cc6d362a8c3bb/configparser-5.0.1-py3-none-any.whl\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/d1/a7f8fe3df258549b303415157328bfcc63e9b11d06a7ad7a3327f3d32606/GitPython-3.1.11-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 15.0MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/5c/018bf9a5c24343a664deaea70e61f33f53bb1bd3caf193110f827bfd07e2/sentry_sdk-0.19.5-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 19.9MB/s \n",
            "\u001b[?25hCollecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.0->wandb) (51.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.9MB/s \n",
            "\u001b[?25hCollecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: subprocess32\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6490 sha256=5f805facb6cb2cb4b0d30d102483cafa09b6e3b405adca0afd05a5603a907241\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "Successfully built subprocess32\n",
            "Installing collected packages: watchdog, docker-pycreds, configparser, shortuuid, smmap, gitdb, GitPython, sentry-sdk, subprocess32, wandb\n",
            "Successfully installed GitPython-3.1.11 configparser-5.0.1 docker-pycreds-0.4.0 gitdb-4.0.5 sentry-sdk-0.19.5 shortuuid-1.0.1 smmap-3.0.4 subprocess32-3.5.4 wandb-0.10.12 watchdog-1.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTQzGTHQ0FfF"
      },
      "source": [
        "#import wandb\n",
        "#wandb.init()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9xA9XuX-UvJ",
        "outputId": "7ba73b35-cc04-4eb8-e609-c1fc32d426cd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH_zIRd2IP1j"
      },
      "source": [
        "\n",
        "from __future__ import division\n",
        "\n",
        "from terminaltables import AsciiTable\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5crs6F9brpwq"
      },
      "source": [
        "#Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q0mYRDmhNzp"
      },
      "source": [
        "#Angle Decoder\n",
        "\n",
        "def angle_decoder(r):\n",
        "  teta1 = torch.asin(2*r[0] - 1)\n",
        "  teta2 = torch.acos(2*r[1] - 1)\n",
        "  teta = 0\n",
        "  if 2*r[0] - 1 >= 0 and 2*r[1] - 1 >= 0:\n",
        "    teta = (teta1+teta2)/2\n",
        "  elif 2*r[0] - 1 >= 0 and 2*r[1] - 1 < 0:\n",
        "    teta = (math.pi-teta1+teta2)/2\n",
        "  elif 2*r[0] - 1 < 0 and 2*r[1] - 1 <= 0:\n",
        "    teta = (math.pi - teta1+2*math.pi -teta2)/2\n",
        "  elif 2*r[0] - 1 < 0 and 2*r[1] - 1 > 0:\n",
        "    teta = (2*math.pi + teta1+2*math.pi - teta2)/2\n",
        "  #print(teta)\n",
        "  return teta"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8QQyIXmraeD"
      },
      "source": [
        "#Utils\n",
        "\n",
        "from __future__ import division\n",
        "import math\n",
        "import time\n",
        "import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from turfpy.transformation import intersect\n",
        "from turfpy.measurement import area\n",
        "from geojson import Feature\n",
        "\n",
        "\n",
        "def to_cpu(tensor):\n",
        "    return tensor.detach().cpu()\n",
        "\n",
        "def rotate_around_point(point, radians, origin=(0, 0)):\n",
        "  \"\"\"Rotate a point around a given point.\n",
        "  \n",
        "  I call this the \"low performance\" version since it's recalculating\n",
        "  the same values more than once [cos(radians), sin(radians), x-ox, y-oy).\n",
        "  It's more readable than the next function, though.\n",
        "  \"\"\"\n",
        "  x, y = point\n",
        "  ox, oy = origin\n",
        "\n",
        "  qx = ox + math.cos(radians) * (x - ox) + math.sin(radians) * (y - oy)\n",
        "  qy = oy + -math.sin(radians) * (x - ox) + math.cos(radians) * (y - oy)\n",
        "\n",
        "  return qx, qy\n",
        "\n",
        "def load_classes(path):\n",
        "    \"\"\"\n",
        "    Loads class labels at 'path'\n",
        "    \"\"\"\n",
        "    fp = open(path, \"r\")\n",
        "    names = fp.read().split(\"\\n\")[:-1]\n",
        "    return names\n",
        "\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "def rescale_boxes(boxes, current_dim, original_shape):\n",
        "    \"\"\" Rescales bounding boxes to the original shape \"\"\"\n",
        "    orig_h, orig_w = original_shape\n",
        "    # The amount of padding that was added\n",
        "    pad_x = max(orig_h - orig_w, 0) * (current_dim / max(original_shape))\n",
        "    pad_y = max(orig_w - orig_h, 0) * (current_dim / max(original_shape))\n",
        "    # Image height and width after padding is removed\n",
        "    unpad_h = current_dim - pad_y\n",
        "    unpad_w = current_dim - pad_x\n",
        "    # Rescale bounding boxes to dimension of original image\n",
        "    boxes[:, 0] = ((boxes[:, 0] - pad_x // 2) / unpad_w) * orig_w\n",
        "    boxes[:, 1] = ((boxes[:, 1] - pad_y // 2) / unpad_h) * orig_h\n",
        "    boxes[:, 2] = ((boxes[:, 2] - pad_x // 2) / unpad_w) * orig_w\n",
        "    boxes[:, 3] = ((boxes[:, 3] - pad_y // 2) / unpad_h) * orig_h\n",
        "    return boxes\n",
        "\n",
        "\n",
        "def xywh2xyxy(x):\n",
        "    y = x.new(x.shape)\n",
        "    y[..., 0] = x[..., 0] - x[..., 3] / 2\n",
        "    y[..., 1] = x[..., 1] - x[..., 4] / 2\n",
        "    y[..., 2] = x[..., 2] - x[..., 5] / 2\n",
        "    y[..., 3] = x[..., 0] + x[..., 3] / 2\n",
        "    y[..., 4] = x[..., 1] + x[..., 4] / 2\n",
        "    y[..., 5] = x[..., 2] + x[..., 5] / 2\n",
        "    return y\n",
        "\n",
        "\n",
        "def ap_per_class(tp, conf, pred_cls, target_cls):\n",
        "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
        "    Source: https://github.com/rafaelpadilla/Object-Detection-Metrics.\n",
        "    # Arguments\n",
        "        tp:    True positives (list).\n",
        "        conf:  Objectness value from 0-1 (list).\n",
        "        pred_cls: Predicted object classes (list).\n",
        "        target_cls: True object classes (list).\n",
        "    # Returns\n",
        "        The average precision as computed in py-faster-rcnn.\n",
        "    \"\"\"\n",
        "\n",
        "    # Sort by objectness\n",
        "    i = np.argsort(-conf)\n",
        "    tp, conf, pred_cls = tp[i], conf[i], pred_cls[i]\n",
        "\n",
        "    # Find unique classes\n",
        "    unique_classes = np.unique(target_cls)\n",
        "\n",
        "    # Create Precision-Recall curve and compute AP for each class\n",
        "    ap, p, r = [], [], []\n",
        "    for c in tqdm.tqdm(unique_classes, desc=\"Computing AP\"):\n",
        "        i = pred_cls == c\n",
        "        n_gt = (target_cls == c).sum()  # Number of ground truth objects\n",
        "        n_p = i.sum()  # Number of predicted objects\n",
        "\n",
        "        if n_p == 0 and n_gt == 0:\n",
        "            continue\n",
        "        elif n_p == 0 or n_gt == 0:\n",
        "            ap.append(0)\n",
        "            r.append(0)\n",
        "            p.append(0)\n",
        "        else:\n",
        "            # Accumulate FPs and TPs\n",
        "            fpc = (1 - tp[i]).cumsum()\n",
        "            tpc = (tp[i]).cumsum()\n",
        "\n",
        "            # Recall\n",
        "            recall_curve = tpc / (n_gt + 1e-16)\n",
        "            r.append(recall_curve[-1])\n",
        "\n",
        "            # Precision\n",
        "            precision_curve = tpc / (tpc + fpc)\n",
        "            p.append(precision_curve[-1])\n",
        "\n",
        "            # AP from recall-precision curve\n",
        "            ap.append(compute_ap(recall_curve, precision_curve))\n",
        "\n",
        "    # Compute F1 score (harmonic mean of precision and recall)\n",
        "    p, r, ap = np.array(p), np.array(r), np.array(ap)\n",
        "    f1 = 2 * p * r / (p + r + 1e-16)\n",
        "\n",
        "    return p, r, ap, f1, unique_classes.astype(\"int32\")\n",
        "\n",
        "\n",
        "def compute_ap(recall, precision):\n",
        "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
        "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
        "\n",
        "    # Arguments\n",
        "        recall:    The recall curve (list).\n",
        "        precision: The precision curve (list).\n",
        "    # Returns\n",
        "        The average precision as computed in py-faster-rcnn.\n",
        "    \"\"\"\n",
        "    # correct AP calculation\n",
        "    # first append sentinel values at the end\n",
        "    mrec = np.concatenate(([0.0], recall, [1.0]))\n",
        "    mpre = np.concatenate(([0.0], precision, [0.0]))\n",
        "\n",
        "    # compute the precision envelope\n",
        "    for i in range(mpre.size - 1, 0, -1):\n",
        "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
        "\n",
        "    # to calculate area under PR curve, look for points\n",
        "    # where X axis (recall) changes value\n",
        "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
        "\n",
        "    # and sum (\\Delta recall) * prec\n",
        "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
        "    return ap\n",
        "\n",
        "\n",
        "def get_batch_statistics(outputs, targets, iou_threshold):\n",
        "    \"\"\" Compute true positives, predicted scores and predicted labels per sample \"\"\"\n",
        "    batch_metrics = []\n",
        "    for sample_i in range(len(outputs)):\n",
        "\n",
        "        if outputs[sample_i] is None:\n",
        "            continue\n",
        "\n",
        "        output = outputs[sample_i]\n",
        "        pred_boxes = output[:, :8]\n",
        "        pred_scores = output[:, 8]\n",
        "        pred_labels = output[:, -1]\n",
        "\n",
        "        true_positives = np.zeros(pred_boxes.shape[0])\n",
        "\n",
        "        annotations = targets[targets[:, 0] == sample_i][:, 1:]\n",
        "        target_labels = annotations[:, 0] if len(annotations) else []\n",
        "        if len(annotations):\n",
        "            detected_boxes = []\n",
        "            target_boxes = annotations[:, 1:]\n",
        "\n",
        "            for pred_i, (pred_box, pred_label) in enumerate(zip(pred_boxes, pred_labels)):\n",
        "\n",
        "                # If targets are found break\n",
        "                if len(detected_boxes) == len(annotations):\n",
        "                    break\n",
        "\n",
        "                # Ignore if label is not one of the target labels\n",
        "                if pred_label not in target_labels:\n",
        "                    continue\n",
        "\n",
        "                iou, box_index = bbox_iou(pred_box.unsqueeze(0), target_boxes).max(0)\n",
        "                if iou >= iou_threshold and box_index not in detected_boxes:\n",
        "                    true_positives[pred_i] = 1\n",
        "                    detected_boxes += [box_index]\n",
        "        batch_metrics.append([true_positives, pred_scores, pred_labels])\n",
        "    return batch_metrics\n",
        "\n",
        "\n",
        "def bbox_wh_iou(wh1, wh2):\n",
        "    #print(\"wh2,wh1 =\",wh2,wh1)\n",
        "    wh2 = wh2.t()\n",
        "    w1, l1, h1 = wh1[0], wh1[1] ,wh1[2]\n",
        "    w2, l2, h2 = wh2[0], wh2[1] ,wh1[2]\n",
        "    inter_area = torch.min(w1, w2) * torch.min(l1, l2) * torch.min(h1, h2)\n",
        "    union_area = (w1 * l1 * h1 + 1e-16) + (w2 * l2 * h2) - inter_area\n",
        "    #print(\"iou scores = \", inter_area / union_area)\n",
        "    return inter_area / union_area\n",
        "\n",
        "\n",
        "def bbox_iou(boxes1, boxes2, x1y1x2y2=True):\n",
        "    \"\"\"\n",
        "    Returns the IoU of two bounding boxes\n",
        "    \"\"\"\n",
        "    #print(\"box shapes\", box1.shape)\n",
        "    iou_scores = []\n",
        "    for box1,box2 in zip(boxes1,boxes2):\n",
        "      if not x1y1x2y2:\n",
        "          # Transform from center and width to exact coordinates\n",
        "          b1_x1, b1_x3 = box1[0] - box1[3] / 2, box1[0] + box1[3] / 2\n",
        "          b1_y1, b1_y3 = box1[1] - box1[4] / 2, box1[1] + box1[4] / 2\n",
        "          b1_z1, b1_z3 = box1[2] - box1[5] / 2, box1[2] + box1[5] / 2\n",
        "          b2_x1, b2_x3 = box2[0] - box2[3] / 2, box2[0] + box2[3] / 2\n",
        "          b2_y1, b2_y3 = box2[1] - box2[4] / 2, box2[1] + box2[4] / 2\n",
        "          b2_z1, b2_z3 = box2[2] - box2[5] / 2, box2[2] + box2[5] / 2\n",
        "\n",
        "      else:\n",
        "          # Get the coordinates of bounding boxes\n",
        "          b1_x1, b1_y1, b1_z1, b1_x3, b1_y3 ,b1_z3 = box1[0], box1[1], box1[2], box1[3], box1[4], box1[5]\n",
        "          b2_x1, b2_y1, b2_z1, b2_x3, b2_y3 ,b2_z3 = box2[0], box2[1], box2[2], box2[3], box2[4], box2[5]\n",
        "\n",
        "      # finding the other 2 corners of the rectangle\n",
        "      b1_x2, b1_x4 = b1_x3, b1_x1\n",
        "      b1_y2, b1_y4 = b1_y1, b1_y3 \n",
        "      b1_z2, b1_z4 = b1_z1, b1_z3\n",
        "      b2_x2, b2_x4 = b2_x3, b2_x1\n",
        "      b2_y2, b2_y4 = b2_y1, b2_y3 \n",
        "      b2_z2, b2_z4 = b2_z1, b2_z3\n",
        "\n",
        "      #Rotating about the center\n",
        "      b1_x1, b1_y1 = rotate_around_point((b1_x1, b1_y1), angle_decoder(box1[6:8]), (box1[0], box1[1]))\n",
        "      b2_x1, b2_y1 = rotate_around_point((b2_x1, b2_y1), angle_decoder(box2[6:8]), (box2[0], box2[1]))\n",
        "      b1_x2, b1_y2 = rotate_around_point((b1_x2, b1_y2), angle_decoder(box1[6:8]), (box1[0], box1[1]))\n",
        "      b2_x2, b2_y2 = rotate_around_point((b2_x2, b2_y2), angle_decoder(box2[6:8]), (box2[0], box2[1]))\n",
        "\n",
        "      b1_x3, b1_y3 = rotate_around_point((b1_x3, b1_y3), angle_decoder(box1[6:8]), (box1[0], box1[1]))\n",
        "      b2_x3, b2_y3 = rotate_around_point((b2_x3, b2_y3), angle_decoder(box2[6:8]), (box2[0], box2[1]))\n",
        "      b1_x4, b1_y4 = rotate_around_point((b1_x4, b1_y4), angle_decoder(box1[6:8]), (box1[0], box1[1]))\n",
        "      b2_x4, b2_y4 = rotate_around_point((b2_x4, b2_y4), angle_decoder(box2[6:8]), (box2[0], box2[1]))\n",
        "\n",
        "      # Intersection area\n",
        "      if torch.abs(b2_z2 - b2_z1 + 1)< torch.abs(b1_z2 - b1_z1 + 1) :\n",
        "        z = torch.abs(b2_z2 - b2_z1 + 1).item()\n",
        "      else :\n",
        "        z = torch.abs(b1_z2 - b1_z1 + 1).item()\n",
        "\n",
        "      f = Feature(geometry={\"coordinates\": [\n",
        "      [[b1_x1.item(), b1_y1.item()], [b1_x2.item(), b1_y2.item()],\n",
        "      [b1_x3.item(), b1_y3.item()], [b1_x4.item(), b1_y4.item()]]], \"type\": \"Polygon\"})\n",
        "      b = Feature(geometry={\"coordinates\": [\n",
        "      [[b2_x1.item(), b2_y1.item()], [b2_x2.item(), b2_y2.item()],\n",
        "      [b2_x3.item(), b2_y3.item()], [b2_x4.item(), b2_y4.item()]\n",
        "      ]], \"type\": \"Polygon\"})\n",
        "      try :\n",
        "        inter = intersect([f, b])\n",
        "        if inter == None :\n",
        "          #print(\"set to none!!\")\n",
        "          #print(f,b)\n",
        "          inter_area = 0\n",
        "          #exit()\n",
        "        else:\n",
        "          #print(\"inner area found!!\")\n",
        "          inter_area = area(inter) * z\n",
        "      except:\n",
        "        inter_area = 0\n",
        "        #print(\"error detected!!\")\n",
        "\n",
        "      # Union Area\n",
        "      try:\n",
        "        b1_area = area(f) * torch.abs(b1_z2 - b1_z1 + 1).item()\n",
        "      except:\n",
        "        print(f)\n",
        "        b1_area = 0\n",
        "      try:\n",
        "        b2_area = area(b) * torch.abs(b2_z2 - b2_z1 + 1).item()\n",
        "      except:\n",
        "        print(b)\n",
        "        b2_area = 0\n",
        "\n",
        "      iou = inter_area / (b1_area + b2_area - inter_area + 1e-16)\n",
        "      iou_scores.append(iou)\n",
        "\n",
        "    return torch.Tensor(iou_scores).to(device)\n",
        "\n",
        "\n",
        "def non_max_suppression(prediction, conf_thres=0.5, nms_thres=0.5):\n",
        "    \"\"\"\n",
        "    Removes detections with lower object confidence score than 'conf_thres' and performs\n",
        "    Non-Maximum Suppression to further filter detections.\n",
        "    Returns detections with shape:\n",
        "        (x1, y1, x2, y2, object_conf, class_score, class_pred)\n",
        "    \"\"\"\n",
        "\n",
        "    # From (center x, center y, width, height) to (x1, y1, x2, y2)\n",
        "    prediction[..., :6] = xywh2xyxy(prediction[..., :6])\n",
        "    output = [None for _ in range(len(prediction))]\n",
        "    for image_i, image_pred in enumerate(prediction):\n",
        "        # Filter out confidence scores below threshold\n",
        "        #print(\"Max conf_thres:\",torch.max(image_pred[:]))\n",
        "        image_pred = image_pred[image_pred[:, 8] >= conf_thres]\n",
        "        # If none are remaining => process next image\n",
        "        if not image_pred.size(0):\n",
        "            continue\n",
        "        # Object confidence times class confidence\n",
        "        score = image_pred[:, 8] * image_pred[:, 9:].max(1)[0]\n",
        "        # Sort by it\n",
        "        image_pred = image_pred[(-score).argsort()]\n",
        "        class_confs, class_preds = image_pred[:, 9:].max(1, keepdim=True)\n",
        "        detections = torch.cat((image_pred[:, :9], class_confs.float(), class_preds.float()), 1)\n",
        "        # Perform non-maximum suppression\n",
        "        keep_boxes = []\n",
        "        while detections.size(0):\n",
        "            large_overlap = bbox_iou(detections[0, :8].unsqueeze(0), detections[:, :8]) > nms_thres\n",
        "            label_match = detections[0, -1] == detections[:, -1]\n",
        "            label_match = label_match.cuda()\n",
        "            # Indices of boxes with lower confidence scores, large IOUs and matching labels\n",
        "            invalid = large_overlap & label_match\n",
        "            weights = detections[invalid, 8:9]\n",
        "            # Merge overlapping bboxes by order of confidence\n",
        "            detections[0, :8] = (weights * detections[invalid, :8]).sum(0) / weights.sum()\n",
        "            keep_boxes += [detections[0]]\n",
        "            detections = detections[~invalid]\n",
        "        if keep_boxes:\n",
        "            output[image_i] = torch.stack(keep_boxes)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def build_targets(pred_boxes, pred_cls, target, anchors, ignore_thres):\n",
        "    ByteTensor = torch.cuda.ByteTensor if pred_boxes.is_cuda else torch.ByteTensor\n",
        "    FloatTensor = torch.cuda.FloatTensor if pred_boxes.is_cuda else torch.FloatTensor\n",
        "\n",
        "    nB = pred_boxes.size(0)\n",
        "    nA = pred_boxes.size(1)\n",
        "    nC = pred_cls.size(-1)\n",
        "    nG = pred_boxes.size(2)\n",
        "    \n",
        "    obj_mask = ByteTensor(nB, nA, nG, nG).fill_(0)\n",
        "    noobj_mask = ByteTensor(nB, nA, nG, nG).fill_(1)\n",
        "    class_mask = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
        "    iou_scores = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
        "    tx = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
        "    ty = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
        "    tz = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
        "    tw = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
        "    tl = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
        "    th = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
        "    tr1 = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
        "    tr2 = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
        "    tcls = FloatTensor(nB, nA, nG, nG, nC).fill_(0)\n",
        "    \n",
        "    target_boxes = target[:, 2:10]\n",
        "    target_boxes[:, :2] = target_boxes[:, :2] * nG\n",
        "    target_boxes[:, 3:5] = target_boxes[:, 3:5] * nG\n",
        "    target_boxes[:, 5] = target_boxes[:, 5] * 5\n",
        "\n",
        "    gxy = target_boxes[:, :2]\n",
        "    gwlh = target_boxes[:, 3:6]\n",
        "\n",
        "    ious = torch.stack([bbox_wh_iou(anchor, gwlh) for anchor in anchors]) #here\n",
        "    try:\n",
        "      best_ious, best_n = ious.max(0)\n",
        "    except:\n",
        "      tconf = obj_mask.float()\n",
        "      return iou_scores, class_mask, obj_mask, noobj_mask, tx, ty, tz, tw, tl, th, tr1, tr2, tcls, tconf\n",
        "\n",
        "    b, target_labels = target[:, :2].long().t()\n",
        "    \n",
        "    gx, gy = gxy.t()\n",
        "    gw, gl, gh = gwlh.t()\n",
        "    gi, gj = gxy.long().t()\n",
        "    \n",
        "    # Set masks\n",
        "    obj_mask[b, best_n, gj, gi] = 1\n",
        "    noobj_mask[b, best_n, gj, gi] = 0\n",
        "\n",
        "    # Set noobj mask to zero where iou exceeds ignore threshold\n",
        "    for i, anchor_ious in enumerate(ious.t()):\n",
        "        noobj_mask[b[i], anchor_ious > ignore_thres, gj[i], gi[i]] = 0\n",
        "\n",
        "    # Coordinates\n",
        "    tx[b, best_n, gj, gi] = gx - gx.floor()\n",
        "    ty[b, best_n, gj, gi] = gy - gy.floor()\n",
        "    tz[b, best_n, gj, gi] = target_boxes[:,2]\n",
        "    # Width and height\n",
        "    tw[b, best_n, gj, gi] = torch.log(gw / anchors[best_n][:, 0] + 1e-16)\n",
        "    tl[b, best_n, gj, gi] = torch.log(gl / anchors[best_n][:, 1] + 1e-16)\n",
        "    th[b, best_n, gj, gi] = torch.log(gh / anchors[best_n][:, 2] + 1e-16)\n",
        "    \n",
        "    tr1[b, best_n, gj, gi] = target_boxes[:,6]\n",
        "    tr2[b, best_n, gj, gi] = target_boxes[:,7]\n",
        "    # One-hot encoding of label\n",
        "    tcls[b, best_n, gj, gi, target_labels] = 1\n",
        "    # Compute label correctness and iou at best anchor\n",
        "    class_mask[b, best_n, gj, gi] = (pred_cls[b, best_n, gj, gi].argmax(-1) == target_labels).float()\n",
        "    iou_scores[b, best_n, gj, gi] = bbox_iou(pred_boxes[b, best_n, gj, gi], target_boxes, x1y1x2y2=False)\n",
        "    #print(\"class_mask =\")\n",
        "    #for i in class_mask[0][1]:\n",
        "    #    print(i)\n",
        "    tconf = obj_mask.float()\n",
        "    #print(\"from end of build targets\",targets[:,2].max())\n",
        "    target_boxes[:, :2] = target_boxes[:, :2] / nG\n",
        "    target_boxes[:, 3:5] = target_boxes[:, 3:5] / nG\n",
        "    target_boxes[:, 5] = target_boxes[:, 5] / 5\n",
        "    return iou_scores, class_mask, obj_mask, noobj_mask, tx, ty, tz, tw, tl, th, tr1, tr2, tcls, tconf\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfNuZWdMrK2w"
      },
      "source": [
        "#Parse_config\n",
        "\n",
        "def parse_model_config(path):\n",
        "    \"\"\"Parses the yolo-v3 layer configuration file and returns module definitions\"\"\"\n",
        "    file = open(path, 'r')\n",
        "    lines = file.read().split('\\n')\n",
        "    lines = [x for x in lines if x and not x.startswith('#')]\n",
        "    lines = [x.rstrip().lstrip() for x in lines] # get rid of fringe whitespaces\n",
        "    module_defs = []\n",
        "    for line in lines:\n",
        "        if line.startswith('['): # This marks the start of a new block\n",
        "            module_defs.append({})\n",
        "            module_defs[-1]['type'] = line[1:-1].rstrip()\n",
        "            if module_defs[-1]['type'] == 'convolutional':\n",
        "                module_defs[-1]['batch_normalize'] = 0\n",
        "        else:\n",
        "            key, value = line.split(\"=\")\n",
        "            value = value.strip()\n",
        "            module_defs[-1][key.rstrip()] = value.strip()\n",
        "\n",
        "    return module_defs\n",
        "\n",
        "def parse_data_config(path):\n",
        "    \"\"\"Parses the data configuration file\"\"\"\n",
        "    options = dict()\n",
        "    options['gpus'] = '0,1,2,3'\n",
        "    options['num_workers'] = '10'\n",
        "    with open(path, 'r') as fp:\n",
        "        lines = fp.readlines()\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line == '' or line.startswith('#'):\n",
        "            continue\n",
        "        key, value = line.split('=')\n",
        "        options[key.strip()] = value.strip()\n",
        "    return options\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xUCTALNYmpR"
      },
      "source": [
        "def draw(targets):\n",
        "  fig = plt.figure(figsize=(8,8))\n",
        "  ax = fig.add_subplot(111)\n",
        "  for target in targets:\n",
        "    rotation = angle_decoder(target[8:10])\n",
        "    height = target[6]\n",
        "    width = target[5]\n",
        "    x_temp, y_temp = rotate_around_point((target[2],-target[3]), -(rotation), origin=(target[2]-width/2, -target[3] - height/2))\n",
        "    x_offset, y_offset = x_temp - target[2], y_temp + target[3]\n",
        "    rectas = patches.Rectangle(xy=((target[2]-width/2) - x_offset, (-target[3] - height/2) - y_offset) ,width=width, height=height, angle = (rotation)*180/math.pi, linewidth=1, color='blue', fill=False)\n",
        "    ax.add_patch(rectas)\n",
        "    ax.scatter(target[2], -target[3], color = 'red', s=10)\n",
        "  ax.scatter(0.5, -0.5)\n",
        "  plt.xlim(0, 1)\n",
        "  plt.ylim(-1,0)\n",
        "  plt.show()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0phLTHEsL0P"
      },
      "source": [
        "#Dataset\n",
        "\n",
        "import glob\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from pyquaternion import Quaternion\n",
        "import math\n",
        "import json\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "def pad_to_square(img, pad_value):\n",
        "    c, h, w = img.shape\n",
        "    dim_diff = np.abs(h - w)\n",
        "    # (upper / left) padding and (lower / right) padding\n",
        "    pad1, pad2 = dim_diff // 2, dim_diff - dim_diff // 2\n",
        "    # Determine padding\n",
        "    pad = (0, 0, pad1, pad2) if h <= w else (pad1, pad2, 0, 0)\n",
        "    # Add padding\n",
        "    img = F.pad(img, pad, \"constant\", value=pad_value)\n",
        "\n",
        "    return img, pad\n",
        "\n",
        "\n",
        "def resize(image, size):\n",
        "    image = F.interpolate(image.unsqueeze(0), size=size, mode=\"nearest\").squeeze(0)\n",
        "    return image\n",
        "\n",
        "\n",
        "def random_resize(images, min_size=288, max_size=448):\n",
        "    new_size = random.sample(list(range(min_size, max_size + 1, 32)), 1)[0]\n",
        "    images = F.interpolate(images, size=new_size, mode=\"nearest\")\n",
        "    return images\n",
        "\n",
        "\n",
        "class ImageFolder(Dataset):\n",
        "    def __init__(self, folder_path, img_size=1248):\n",
        "        self.files = sorted(glob.glob(\"%s/*.*\" % folder_path))\n",
        "        self.img_size = img_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.files[index % len(self.files)]\n",
        "        # Extract image as PyTorch tensor\n",
        "        img = transforms.ToTensor()(Image.open(img_path))\n",
        "        # Pad to square resolution\n",
        "        img, _ = pad_to_square(img, 0)\n",
        "        # Resize\n",
        "        img = resize(img, self.img_size)\n",
        "\n",
        "        return img_path, img\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "\n",
        "class ListDataset(Dataset):\n",
        "    def __init__(self, sample_mapping, img_size=1248, augment=True, multiscale=False, normalized_labels=False, max_height=5, max_length=70, max_width=70):\n",
        "       \n",
        "        self.img_size = img_size\n",
        "        self.max_objects = 100\n",
        "        self.augment = augment\n",
        "        self.multiscale = multiscale\n",
        "        self.normalized_labels = normalized_labels\n",
        "        self.min_size = self.img_size - 3 * 32\n",
        "        self.max_size = self.img_size + 3 * 32\n",
        "        self.batch_count = 0\n",
        "        self.sample_mapping = sample_mapping\n",
        "        self.file_path = '/content/drive/MyDrive/data'\n",
        "        \n",
        "        #folder no:\n",
        "        self.hash = {}\n",
        "        for i in range(85):\n",
        "          with open(\"/content/drive/MyDrive/data/sample\"+str(i)+\"/sample.json\") as f:\n",
        "            samples = json.load(f)\n",
        "          for sample in samples.keys():\n",
        "            self.hash[sample] = i\n",
        "          f.close()\n",
        "\n",
        "        #get categories\n",
        "        self.categories = []\n",
        "        with open('/content/drive/MyDrive/data/v1.0-trainval/category.json') as f:\n",
        "          data = json.load(f)\n",
        "        for d in data:\n",
        "          self.categories.append(d['name'])\n",
        "        self.num_category = len(self.categories)\n",
        "        \n",
        "        #important items for tewking\n",
        "        self.max_height = max_height\n",
        "        self.max_width = max_width\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def quaternion_yaw(self, q: Quaternion) -> float:\n",
        "      \"\"\"\n",
        "      Calculate the yaw angle from a quaternion.\n",
        "      See https://en.wikipedia.org/wiki/Conversion_between_quaternions_and_Euler_angles.\n",
        "      :param q: Quaternion of interest.\n",
        "      :return: Yaw angle in radians.\n",
        "      \"\"\"\n",
        "\n",
        "      a = 2.0 * (q[0] * q[3] + q[1] * q[2])\n",
        "      b = 1.0 - 2.0 * (q[2] ** 2 + q[3] ** 2)\n",
        "\n",
        "      return np.arctan2(a, b)\n",
        "\n",
        "    def rotate_around_point_lowperf(self, point, radians, origin=(0, 0)):\n",
        "      \"\"\"Rotate a point around a given point.\n",
        "      \n",
        "      I call this the \"low performance\" version since it's recalculating\n",
        "      the same values more than once [cos(radians), sin(radians), x-ox, y-oy).\n",
        "      It's more readable than the next function, though.\n",
        "      \"\"\"\n",
        "      x, y = point\n",
        "      ox, oy = origin\n",
        "\n",
        "      qx = ox + math.cos(radians) * (x - ox) + math.sin(radians) * (y - oy)\n",
        "      qy = oy + -math.sin(radians) * (x - ox) + math.cos(radians) * (y - oy)\n",
        "\n",
        "      return qx, qy\n",
        "\n",
        "    def convert_to_top_corner(self, point):\n",
        "      point[0] = self.max_length + point[0]\n",
        "      point[1] = self.max_width - point[1]\n",
        "\n",
        "      return point\n",
        "\n",
        "    def check_cameraregion(self,coordinates,cameras,sample,folder_no):\n",
        "      \"\"\"To check if the coordinate of the object lies in blacked out camera region\n",
        "       and if so return flag as 0\"\"\"\n",
        "      #print(\"Start of Checking for the point :\",coordinates)\n",
        "      angle = 0\n",
        "      flag = False\n",
        "      self.calibrated_sensor = {}\n",
        "      with open(\"/content/drive/MyDrive/data/sample\"+str(folder_no)+\"/calibrated_sensor.json\") as f:\n",
        "          self.calibrated_sensor = json.load(f)\n",
        "      f.close()\n",
        "      for camera in cameras:\n",
        "        flag = False\n",
        "        sample_data = self.sample_data[sample['data'][camera]]\n",
        "        sensor = self.calibrated_sensor[sample_data['calibrated_sensor_token']]\n",
        "        if camera == 'CAM_BACK':\n",
        "          angle = 55/180 * math.pi\n",
        "        else :\n",
        "          angle = 35/180 * math.pi\n",
        "        #print(\"Sensor before rotation:\", sensor['translation'][0:2])\n",
        "        x, y = self.rotate_around_point_lowperf(sensor['translation'][0:2], -math.pi/2)\n",
        "        #print(\"Sensor after rotation:\", x,y)\n",
        "        rotation = self.quaternion_yaw(sensor['rotation']) +math.pi\n",
        "        vl = coordinates[1] - y - math.tan(rotation+angle) * (coordinates[0]-x)\n",
        "        vr = coordinates[1] - y - math.tan(rotation-angle) * (coordinates[0]-x)\n",
        "        #print(camera,\"Angles :\",(rotation+angle)*180/math.pi,(rotation-angle)*180/math.pi)\n",
        "        if (rotation + angle >= math.pi/2 and rotation + angle <= math.pi*3/2):\n",
        "          if vl >= 0:\n",
        "            flag = True\n",
        "            #print(\"1st in\")\n",
        "        else:\n",
        "          if vl <= 0:\n",
        "            flag = True\n",
        "            #print(\"2nd in\")\n",
        "        if flag:\n",
        "          if (rotation - angle >= math.pi/2 and rotation - angle <= math.pi*3/2):\n",
        "            if vr <= 0:\n",
        "              flag = True\n",
        "              #print(\"3rd in\")\n",
        "              break\n",
        "            else:\n",
        "              flag = False\n",
        "              #print(\"4th in\")\n",
        "          else:\n",
        "            if vr >= 0:\n",
        "              #print(\"5th in\")\n",
        "              flag = True\n",
        "              break\n",
        "            else:\n",
        "              #print(\"6th in\")\n",
        "              flag = False\n",
        "      del self.calibrated_sensor\n",
        "      return flag\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        token = self.sample_mapping[index]\n",
        "        folder_no = self.hash[token]\n",
        "        self.sample = {}\n",
        "        with open(\"/content/drive/MyDrive/data/sample\"+str(folder_no)+\"/sample.json\") as f:\n",
        "            self.sample = json.load(f)\n",
        "        f.close()\n",
        "        self.sample_data = {}\n",
        "        with open(\"/content/drive/MyDrive/data/sample\"+str(folder_no)+\"/sample_data.json\") as f:\n",
        "            self.sample_data = json.load(f)\n",
        "        f.close()\n",
        "        self.ego_poses = {}\n",
        "        with open(\"/content/drive/MyDrive/data/sample\"+str(folder_no)+\"/ego_pose.json\") as f:\n",
        "            self.ego_poses = json.load(f)\n",
        "        f.close()\n",
        "        self.visibility = {}\n",
        "        with open(\"/content/drive/MyDrive/data/sample\"+str(folder_no)+\"/visibility.json\") as f:\n",
        "            self.visibility = json.load(f)\n",
        "        f.close()\n",
        "        self.sample_annotation = {}\n",
        "        with open(\"/content/drive/MyDrive/data/sample\"+str(folder_no)+\"/sample_annotation.json\") as f:\n",
        "            self.sample_annotation = json.load(f)\n",
        "        f.close()\n",
        "        my_sample = self.sample[token]\n",
        "        \n",
        "        # ---------\n",
        "        #  Image\n",
        "        # ---------\n",
        "\n",
        "        front = ['CAM_FRONT_LEFT','CAM_FRONT','CAM_FRONT_RIGHT']\n",
        "        back = ['CAM_BACK_RIGHT','CAM_BACK','CAM_BACK_LEFT']\n",
        "\n",
        "        #Augmentation and image\n",
        "        camera = []\n",
        "        blackout_cameras = []\n",
        "        if self.augment:\n",
        "          if np.random.random() < 0.3:\n",
        "            camera = front + back\n",
        "            numbers = [1,2]\n",
        "            number = random.choice(numbers)\n",
        "            blackout_cameras = random.sample(camera,number)\n",
        "            #print(\"Cameras :\",blackout_cameras)\n",
        "\n",
        "        for f,b in zip(front,back):\n",
        "          sensorf = self.sample_data[my_sample['data'][f]]\n",
        "          sensorb = self.sample_data[my_sample['data'][b]]\n",
        "\n",
        "          if f == 'CAM_FRONT_LEFT' and b == 'CAM_BACK_RIGHT':\n",
        "            image_dataf = transforms.ToTensor()(Image.open(self.file_path +'/sample'+str(folder_no)+'/'+ sensorf['filename'].split('/')[1]+'/'+sensorf['filename'].split('/')[2]).convert('RGB'))\n",
        "            if 'CAM_FRONT_LEFT' in blackout_cameras:\n",
        "              image_dataf = torch.zeros(image_dataf.shape)\n",
        "            #plt.imshow(  image_dataf.permute(1, 2, 0)  )\n",
        "            image_datab = transforms.ToTensor()(Image.open(self.file_path +'/sample'+str(folder_no)+'/'+ sensorf['filename'].split('/')[1]+'/'+sensorf['filename'].split('/')[2]).convert('RGB'))\n",
        "            if 'CAM_BACK_RIGHT' in blackout_cameras:\n",
        "              image_datab = torch.zeros(image_dataf.shape)\n",
        "            #plt.imshow(  image_datab.permute(1, 2, 0)  )\n",
        "          else:\n",
        "            data = transforms.ToTensor()(Image.open(self.file_path +'/sample'+str(folder_no)+'/'+ sensorf['filename'].split('/')[1]+'/'+sensorf['filename'].split('/')[2]).convert('RGB'))\n",
        "            if f in blackout_cameras:\n",
        "              data = torch.zeros(data.shape)\n",
        "            image_dataf = torch.cat((image_dataf,data),2)\n",
        "            #plt.imshow(  image_dataf.permute(1, 2, 0)  )\n",
        "            data = transforms.ToTensor()(Image.open(self.file_path +'/sample'+str(folder_no)+'/'+ sensorf['filename'].split('/')[1]+'/'+sensorf['filename'].split('/')[2]).convert('RGB'))\n",
        "            if b in blackout_cameras:\n",
        "              data = torch.zeros(data.shape)\n",
        "            image_datab = torch.cat((image_datab,data),2)\n",
        "            #plt.imshow(  image_datab.permute(1, 2, 0)  )\n",
        "        image_datab = torch.flip(image_datab, [-1])\n",
        "        image_data = torch.cat((image_dataf,image_datab),1)\n",
        "        image_data, _ = pad_to_square(image_data,0)\n",
        "\n",
        "        \n",
        "        # ---------\n",
        "        #  Label\n",
        "        # ---------\n",
        "\n",
        "        l_factor, w_factor, h_factor = (self.max_length, self.max_width, self.max_height) if self.normalized_labels else (1, 1, 1)\n",
        "\n",
        "        targets = None\n",
        "\n",
        "\n",
        "\n",
        "        annos_list = my_sample['anns']\n",
        "        #nusc.render_sample_data(my_sample['data']['CAM_FRONT_LEFT'])\n",
        "        #nusc.render_sample_data(my_sample['data']['CAM_FRONT'])\n",
        "        #nusc.render_sample_data(my_sample['data']['CAM_FRONT_RIGHT'])\n",
        "        #nusc.render_sample_data(my_sample['data']['CAM_BACK_RIGHT'])\n",
        "        #nusc.render_sample_data(my_sample['data']['CAM_BACK'])\n",
        "        #nusc.render_sample_data(my_sample['data']['CAM_BACK_LEFT'])\n",
        "        #nusc.render_sample_data(my_sample['data']['LIDAR_TOP'])\n",
        "        converted_anotations = []\n",
        "        sensor = 'LIDAR_TOP'\n",
        "        lidar_top_data = self.sample_data[my_sample['data'][sensor]]\n",
        "        ego_pose = self.ego_poses[lidar_top_data['ego_pose_token']]\n",
        "        ego_yaw = self.quaternion_yaw(ego_pose['rotation']) - math.pi/2\n",
        "\n",
        "        boxes = []\n",
        "        t=[]\n",
        "        original_ego_yaw = ego_yaw + math.pi/2 #converting back to original value\n",
        "\n",
        "        for annos in annos_list:\n",
        "          annotation = self.sample_annotation[annos]\n",
        "          vis = self.visibility[annotation['visibility_token']]\n",
        "          vis = vis[1:].split(\"-\")\n",
        "          if int(vis[1]) <= 40 :\n",
        "            continue\n",
        "          #print(vis)\n",
        "          box = []\n",
        "\n",
        "          #xyz\n",
        "          flag = False\n",
        "          cordinates = [annotation['translation'][i] - ego_pose['translation'][i] for i in range(3)]\n",
        "          cordinates[0], cordinates[1] = self.rotate_around_point_lowperf(cordinates[:2], ego_yaw, origin=(0, 0))\n",
        "          if self.augment :\n",
        "            flag = self.check_cameraregion(cordinates,blackout_cameras,my_sample, folder_no)\n",
        "          cordinates = self.convert_to_top_corner(cordinates)\n",
        "          if cordinates[0] > 2*self.max_width or cordinates[0] < 0 or cordinates[1] > 2*self.max_length or cordinates[1] < 0 or flag:# or (self.augment and self.check_cameraregion() == 0):\n",
        "            continue\n",
        "\n",
        "          #whl\n",
        "          size = annotation['size']\n",
        "\n",
        "          #angle r1, r2\n",
        "            #converting to relative angle (0-360)\n",
        "          rotation_yaw = self.quaternion_yaw(annotation['rotation']) - original_ego_yaw\n",
        "          if rotation_yaw < 0:\n",
        "            rotation_yaw += math.pi*2\n",
        "          #print(rotation_yaw*180/math.pi)\n",
        "          r1 = (1 + math.sin(rotation_yaw))/2\n",
        "          r2 = (1 + math.cos(rotation_yaw))/2\n",
        "\n",
        "          #category\n",
        "          category_index = self.categories.index(annotation['category_name'])\n",
        "\n",
        "          #Appending to Box\n",
        "          box.append(category_index)\n",
        "          for i,j in zip(cordinates, [self.max_width*2, self.max_length*2, self.max_height]):\n",
        "            box.append(i/j)\n",
        "          for i,j in zip(size, [self.max_width*2, self.max_length*2, self.max_height]):\n",
        "            box.append(i/j)\n",
        "          box.append(r1)\n",
        "          box.append(r2)\n",
        "\n",
        "          #Appending to Boxes\n",
        "          boxes.append(box)\n",
        "          t.append(annos)\n",
        "\n",
        "        boxes = torch.Tensor(boxes)\n",
        "\n",
        "        targets = torch.zeros((len(boxes), 10))\n",
        "        if len(boxes)> 0:\n",
        "          targets[:, 1:] = boxes\n",
        "\n",
        "        del self.sample, self.sample_data, self.sample_annotation, self.visibility, self.ego_poses\n",
        "        # Apply augmentations\n",
        "        #if self.augment:\n",
        "        #  image_data, targets = horisontal_flip(image_data, targets, Verbose = True)\n",
        "        #    if np.random.random() < 0.5:\n",
        "        p = transforms.Compose([transforms.Scale((1024,1024))])\n",
        "        image_data = p(image_data)\n",
        "        return image_data, targets\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        imgs, targets = list(zip(*batch))\n",
        "        # Remove empty placeholder targets\n",
        "        targets = [boxes for boxes in targets if boxes is not None]\n",
        "        # Add sample index to targets\n",
        "        for i, boxes in enumerate(targets):\n",
        "            boxes[:, 0] = i\n",
        "        targets = torch.cat(targets, 0)\n",
        "        # Selects new image size every tenth batch\n",
        "        if self.multiscale and self.batch_count % 10 == 0:\n",
        "            self.img_size = random.choice(range(self.min_size, self.max_size + 1, 32))\n",
        "        # Resize images to input shape\n",
        "        imgs = torch.stack([resize(img, self.img_size) for img in imgs])\n",
        "        self.batch_count += 1\n",
        "        return imgs, targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sample_mapping)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOKpxjoY8_8i"
      },
      "source": [
        "#import matplotlib.pyplot as plt\n",
        "#i = ListDataset(train_samples)\n",
        "#img, targets = i.__getitem__(2)\n",
        "#plt.imshow(  img.permute(1, 2, 0)  )\n",
        "#print(targets)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LklsSzDNP6s8"
      },
      "source": [
        "#img, targets = i.__getitem__(1)\n",
        "#plt.imshow(  img.permute(1, 2, 0)  )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW7hvYsgsVHA"
      },
      "source": [
        "##Augmentation\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import matplotlib as mpl\n",
        "import matplotlib.patches as patches\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "def horisontal_flip(images, targets, Verbose = False):\n",
        "    if Verbose:\n",
        "      print(\"before\")\n",
        "      #image\n",
        "      plt.imshow(  images.permute(1, 2, 0)  )\n",
        "      #plot\n",
        "      fig = plt.figure(figsize=(8,8))\n",
        "      ax = fig.add_subplot(111)\n",
        "      for target in targets:\n",
        "        rotation = angle_decoder(target[8:10])\n",
        "        height = target[6]\n",
        "        width = target[5]\n",
        "        x_temp, y_temp = rotate_around_point((target[2],-target[3]), -(rotation), origin=(target[2]-width/2, -target[3] - height/2))\n",
        "        x_offset, y_offset = x_temp - target[2], y_temp + target[3]\n",
        "        rectas = patches.Rectangle(xy=((target[2]-width/2) - x_offset, (-target[3] - height/2) - y_offset) ,width=width, height=height, angle = (rotation)*180/math.pi, linewidth=1, color='blue', fill=False)\n",
        "        ax.add_patch(rectas)\n",
        "        ax.scatter(target[2], -target[3], color = 'red', s=10)\n",
        "      ax.scatter(0.5, -0.5)\n",
        "      plt.xlim(0, 1)\n",
        "      plt.ylim(-1,0)\n",
        "      plt.show()\n",
        "\n",
        "    #Augmentation Part\n",
        "    images = torch.flip(images, [-1])\n",
        "    targets[:, 2] = 1 - targets[:, 2]\n",
        "\n",
        "    t = []\n",
        "    for target in targets:\n",
        "      teta = angle_decoder(target[8:10])\n",
        "      teta = math.pi *2 - teta\n",
        "      target[8] = (1 + math.sin(teta))/2\n",
        "      target[9] = (1 + math.cos(teta))/2\n",
        "      t.append(target)\n",
        "    if len(t) !=0:\n",
        "      targets = torch.stack(t)\n",
        "\n",
        "\n",
        "    if Verbose:\n",
        "      #plot\n",
        "      print(\"after\")\n",
        "      fig = plt.figure(figsize=(8,8))\n",
        "      ax = fig.add_subplot(111)\n",
        "      for target in targets:\n",
        "        rotation = angle_decoder(target[8:10])\n",
        "        height = target[6]\n",
        "        width = target[5]\n",
        "        x_temp, y_temp = rotate_around_point((target[2],-target[3]), -(rotation), origin=(target[2]-width/2, -target[3] - height/2))\n",
        "        x_offset, y_offset = x_temp - target[2], y_temp + target[3]\n",
        "        rectas = patches.Rectangle(xy=((target[2]-width/2) - x_offset, (-target[3] - height/2) - y_offset) ,width=width, height=height, angle = (rotation)*180/math.pi, linewidth=1, color='blue', fill=False)\n",
        "        ax.add_patch(rectas)\n",
        "        ax.scatter(target[2], -target[3], color = 'red', s=10)\n",
        "      ax.scatter(0.5, -0.5)\n",
        "      plt.xlim(0, 1)\n",
        "      plt.ylim(-1,0)\n",
        "      plt.show()\n",
        "      #image\n",
        "      plt.imshow(  images.permute(1, 2, 0)  )\n",
        "    return images, targets\n",
        "\n",
        "def cam_blackout(images, targets):\n",
        "    images = torch.flip(images, [-1])\n",
        "    targets[:, 2] = 1 - targets[:, 2]\n",
        "    return images, targets\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KirxEqiiZlh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08998cfa-f5d3-4750-87d0-88c079fac6dd"
      },
      "source": [
        " a = math.pi*3/2+ math.pi/3\n",
        "print(a)\n",
        "r1 = (1 + math.sin(a))/2\n",
        "r2 = (1 + math.cos(a))/2\n",
        "print(angle_decoder(torch.Tensor([r1,r2])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.759586531581287\n",
            "tensor(5.7596)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "takpM5RvrupZ"
      },
      "source": [
        "#MODEL.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDDUlseGjmRJ"
      },
      "source": [
        "#MODEL\n",
        "\n",
        "from __future__ import division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "\n",
        "def create_modules(module_defs):\n",
        "    \"\"\"\n",
        "    Constructs module list of layer blocks from module configuration in module_defs\n",
        "    \"\"\"\n",
        "    hyperparams = module_defs.pop(0)\n",
        "    output_filters = [int(hyperparams[\"channels\"])]\n",
        "    module_list = nn.ModuleList()\n",
        "    for module_i, module_def in enumerate(module_defs):\n",
        "        modules = nn.Sequential()\n",
        "\n",
        "        if module_def[\"type\"] == \"convolutional\":\n",
        "            bn = int(module_def[\"batch_normalize\"])\n",
        "            filters = int(module_def[\"filters\"])\n",
        "            kernel_size = int(module_def[\"size\"])\n",
        "            pad = (kernel_size - 1) // 2\n",
        "            modules.add_module(\n",
        "                f\"conv_{module_i}\",\n",
        "                nn.Conv2d(\n",
        "                    in_channels=output_filters[-1],\n",
        "                    out_channels=filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    stride=int(module_def[\"stride\"]),\n",
        "                    padding=pad,\n",
        "                    bias=not bn,\n",
        "                ),\n",
        "            )\n",
        "            if bn:\n",
        "                modules.add_module(f\"batch_norm_{module_i}\", nn.BatchNorm2d(filters, momentum=0.9, eps=1e-5))\n",
        "            if module_def[\"activation\"] == \"leaky\":\n",
        "                modules.add_module(f\"leaky_{module_i}\", nn.LeakyReLU(0.1))\n",
        "\n",
        "        elif module_def[\"type\"] == \"maxpool\":\n",
        "            kernel_size = int(module_def[\"size\"])\n",
        "            stride = int(module_def[\"stride\"])\n",
        "            if kernel_size == 2 and stride == 1:\n",
        "                modules.add_module(f\"_debug_padding_{module_i}\", nn.ZeroPad2d((0, 1, 0, 1)))\n",
        "            maxpool = nn.MaxPool2d(kernel_size=kernel_size, stride=stride, padding=int((kernel_size - 1) // 2))\n",
        "            modules.add_module(f\"maxpool_{module_i}\", maxpool)\n",
        "\n",
        "        elif module_def[\"type\"] == \"upsample\":\n",
        "            upsample = Upsample(scale_factor=int(module_def[\"stride\"]), mode=\"nearest\")\n",
        "            modules.add_module(f\"upsample_{module_i}\", upsample)\n",
        "\n",
        "        elif module_def[\"type\"] == \"route\":\n",
        "            layers = [int(x) for x in module_def[\"layers\"].split(\",\")]\n",
        "            #print(\"layer = \",layers)\n",
        "            #print(\"outputfiletes = \", output_filters)\n",
        "            #print(\"\",sum([output_filters[1:][i] for i in layers]))\n",
        "            filters = sum([output_filters[1:][i] for i in layers])\n",
        "            modules.add_module(f\"route_{module_i}\", EmptyLayer())\n",
        "\n",
        "        elif module_def[\"type\"] == \"shortcut\":\n",
        "            filters = output_filters[1:][int(module_def[\"from\"])]\n",
        "            modules.add_module(f\"shortcut_{module_i}\", EmptyLayer())\n",
        "\n",
        "        elif module_def[\"type\"] == \"yolo\":\n",
        "            anchor_idxs = [int(x) for x in module_def[\"mask\"].split(\",\")]\n",
        "            # Extract anchors\n",
        "            anchors = [float(x) for x in module_def[\"anchors\"].split(\",\")]\n",
        "            anchors = [(anchors[i], anchors[i + 1], anchors[i + 2]) for i in range(0, len(anchors), 3)]\n",
        "            anchors = [anchors[i] for i in anchor_idxs]\n",
        "            num_classes = int(module_def[\"classes\"])\n",
        "            img_size = int(hyperparams[\"height\"])\n",
        "            # Define detection layer\n",
        "            yolo_layer = YOLOLayer(anchors, num_classes, img_size)\n",
        "            modules.add_module(f\"yolo_{module_i}\", yolo_layer)\n",
        "        # Register module list and number of output filters\n",
        "        module_list.append(modules)\n",
        "        output_filters.append(filters)\n",
        "\n",
        "    return hyperparams, module_list\n",
        "\n",
        "\n",
        "class Upsample(nn.Module):\n",
        "    \"\"\" nn.Upsample is deprecated \"\"\"\n",
        "\n",
        "    def __init__(self, scale_factor, mode=\"nearest\"):\n",
        "        super(Upsample, self).__init__()\n",
        "        self.scale_factor = scale_factor\n",
        "        self.mode = mode\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.interpolate(x, scale_factor=self.scale_factor, mode=self.mode)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EmptyLayer(nn.Module):\n",
        "    \"\"\"Placeholder for 'route' and 'shortcut' layers\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(EmptyLayer, self).__init__()\n",
        "\n",
        "\n",
        "class YOLOLayer(nn.Module):\n",
        "    \"\"\"Detection layer\"\"\"\n",
        "\n",
        "    def __init__(self, anchors, num_classes, img_dim=1248):\n",
        "        super(YOLOLayer, self).__init__()\n",
        "        self.anchors = anchors\n",
        "        self.num_anchors = len(anchors)\n",
        "        self.num_classes = num_classes\n",
        "        self.ignore_thres = 0.5\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "        self.bce_loss = nn.BCELoss()\n",
        "        self.obj_scale = 1\n",
        "        self.noobj_scale = 100\n",
        "        self.metrics = {}\n",
        "        self.img_dim = img_dim\n",
        "        self.grid_size = 0  # grid size\n",
        "\n",
        "    def compute_grid_offsets(self, grid_size, cuda=True):\n",
        "        self.grid_size = grid_size\n",
        "        g = self.grid_size\n",
        "        FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "        self.stride = self.img_dim / self.grid_size\n",
        "        # Calculate offsets for each grid\n",
        "        self.grid_x = torch.arange(g).repeat(g, 1).view([1, 1, g, g]).type(FloatTensor)\n",
        "        self.grid_y = torch.arange(g).repeat(g, 1).t().view([1, 1, g, g]).type(FloatTensor)\n",
        "        self.scaled_anchors = FloatTensor([(a_w / self.stride, a_l / self.stride, a_h ) for a_w, a_l, a_h in self.anchors])\n",
        "        self.anchor_w = self.scaled_anchors[:, 0:1].view((1, self.num_anchors, 1, 1))\n",
        "        self.anchor_l = self.scaled_anchors[:, 1:2].view((1, self.num_anchors, 1, 1))\n",
        "        self.anchor_h = self.scaled_anchors[:, 2:3].view((1, self.num_anchors, 1, 1))\n",
        "\n",
        "    def forward(self, x, targets=None, img_dim=None):\n",
        "\n",
        "        # Tensors for cuda support\n",
        "        #print(\"from yolo :\",targets[:,2].max())\n",
        "        FloatTensor = torch.cuda.FloatTensor if x.is_cuda else torch.FloatTensor\n",
        "        LongTensor = torch.cuda.LongTensor if x.is_cuda else torch.LongTensor\n",
        "        ByteTensor = torch.cuda.ByteTensor if x.is_cuda else torch.ByteTensor\n",
        "\n",
        "        self.img_dim = img_dim\n",
        "        num_samples = x.size(0)\n",
        "        grid_size = x.size(2)\n",
        "        #print(x.shape)\n",
        "        #print(\"yolo last layer input shape = \",x.shape)\n",
        "        prediction = (\n",
        "            x.view(num_samples, self.num_anchors, self.num_classes + 9, grid_size, grid_size)\n",
        "            .permute(0, 1, 3, 4, 2)\n",
        "            .contiguous()\n",
        "        )\n",
        "\n",
        "        # Get outputs\n",
        "        x = torch.sigmoid(prediction[..., 0])  # Center x\n",
        "        y = torch.sigmoid(prediction[..., 1])  # Center y\n",
        "        z = torch.sigmoid(prediction[..., 2])\n",
        "        l = prediction[..., 3]  # Height\n",
        "        w = prediction[..., 4]  # Width\n",
        "        h = prediction[..., 5]\n",
        "        r1 = torch.sigmoid(prediction[..., 6])\n",
        "        r2 = torch.sigmoid(prediction[..., 7])\n",
        "        pred_conf = torch.sigmoid(prediction[..., 8])  # Conf\n",
        "        pred_cls = torch.sigmoid(prediction[..., 9:])  # Cls pred.\n",
        "        \n",
        "        # If grid size does not match current we compute new offsets\n",
        "        if grid_size != self.grid_size:\n",
        "            self.compute_grid_offsets(grid_size, cuda=x.is_cuda)\n",
        "        \n",
        "        #print(\"Scaled Anchors = \", self.scaled_anchors)\n",
        "        # Add offset and scale with anchors\n",
        "        #print(\"prediction[...:4].shape = \",prediction[..., :4].shape)\n",
        "        pred_boxes = FloatTensor(prediction[..., :8].shape)\n",
        "        pred_boxes[..., 0] = x.data + self.grid_x\n",
        "        pred_boxes[..., 1] = y.data + self.grid_y\n",
        "        pred_boxes[..., 2] = z.data\n",
        "        pred_boxes[..., 3] = torch.exp(w.data) * self.anchor_w\n",
        "        pred_boxes[..., 4] = torch.exp(l.data) * self.anchor_l\n",
        "        pred_boxes[..., 5] = torch.exp(h.data) * self.anchor_h\n",
        "        pred_boxes[..., 6] = r1.data\n",
        "        pred_boxes[..., 7] = r2.data\n",
        "\n",
        "        replacement = pred_boxes.view(num_samples, -1, 8)\n",
        "        replacement[...,:2] = replacement[...,:2] * self.stride\n",
        "        replacement[...,2] = replacement[...,2] * 5\n",
        "        replacement[...,3:5] = replacement[...,3:5] * self.stride\n",
        "        replacement[...,5] = replacement[...,5]\n",
        "        replacement[...,6] = replacement[...,6]\n",
        "        replacement[...,7] = replacement[...,7]\n",
        "\n",
        "\n",
        "        output = torch.cat(\n",
        "            (\n",
        "                replacement,\n",
        "                pred_conf.view(num_samples, -1, 1),\n",
        "                pred_cls.view(num_samples, -1, self.num_classes),\n",
        "            ),\n",
        "            -1,\n",
        "        )\n",
        "\n",
        "        if targets is None:\n",
        "            return output, 0\n",
        "        else:\n",
        "            iou_scores, class_mask, obj_mask, noobj_mask, tx, ty, tz, tw, tl, th, tr1, tr2, tcls, tconf = build_targets(\n",
        "                pred_boxes=pred_boxes,\n",
        "                pred_cls=pred_cls,\n",
        "                target=targets,\n",
        "                anchors=self.scaled_anchors,\n",
        "                ignore_thres=self.ignore_thres,\n",
        "            )\n",
        "            #print(\"after build targets\",targets[:,2].max())\n",
        "            # Loss : Mask outputs to ignore non-existing objects (except with conf. loss)\n",
        "            loss_x = self.mse_loss(x[obj_mask], tx[obj_mask])\n",
        "            loss_y = self.mse_loss(y[obj_mask], ty[obj_mask])\n",
        "            loss_z = self.mse_loss(z[obj_mask], tz[obj_mask])\n",
        "            loss_w = self.mse_loss(w[obj_mask], tw[obj_mask])\n",
        "            loss_l = self.mse_loss(l[obj_mask], tl[obj_mask])\n",
        "            loss_h = self.mse_loss(h[obj_mask], th[obj_mask])\n",
        "            loss_r1 = self.mse_loss(r1[obj_mask], tr1[obj_mask])\n",
        "            loss_r2 = self.mse_loss(r2[obj_mask], tr2[obj_mask])\n",
        "            loss_conf_obj = self.bce_loss(pred_conf[obj_mask], tconf[obj_mask])\n",
        "            loss_conf_noobj = self.bce_loss(pred_conf[noobj_mask], tconf[noobj_mask])\n",
        "            loss_conf = self.obj_scale * loss_conf_obj + self.noobj_scale * loss_conf_noobj\n",
        "            loss_cls = self.bce_loss(pred_cls[obj_mask], tcls[obj_mask])\n",
        "            total_loss = loss_x + loss_y + loss_z + loss_w + loss_l + loss_h + loss_r1 + loss_r2 + loss_conf + loss_cls\n",
        "\n",
        "            # Metrics\n",
        "            cls_acc = 100 * class_mask[obj_mask].mean()\n",
        "            conf_obj = pred_conf[obj_mask].mean()\n",
        "            conf_noobj = pred_conf[noobj_mask].mean()\n",
        "            conf50 = (pred_conf > 0.5).float()\n",
        "            iou50 = (iou_scores > 0.5).float()\n",
        "            iou75 = (iou_scores > 0.75).float()\n",
        "            detected_mask = conf50 * class_mask * tconf\n",
        "            precision = torch.sum(iou50 * detected_mask) / (conf50.sum() + 1e-16)\n",
        "            recall50 = torch.sum(iou50 * detected_mask) / (obj_mask.sum() + 1e-16)\n",
        "            recall75 = torch.sum(iou75 * detected_mask) / (obj_mask.sum() + 1e-16)\n",
        "\n",
        "            self.metrics = {\n",
        "                \"loss\": to_cpu(total_loss).item(),\n",
        "                \"x\": to_cpu(loss_x).item(),\n",
        "                \"y\": to_cpu(loss_y).item(),\n",
        "                \"z\": to_cpu(loss_z).item(),\n",
        "                \"w\": to_cpu(loss_w).item(),\n",
        "                \"l\": to_cpu(loss_l).item(),\n",
        "                \"h\": to_cpu(loss_h).item(),\n",
        "                \"r1\": to_cpu(loss_r1).item(),\n",
        "                \"r2\": to_cpu(loss_r2).item(),\n",
        "                \"conf\": to_cpu(loss_conf).item(),\n",
        "                \"cls\": to_cpu(loss_cls).item(),\n",
        "                \"cls_acc\": to_cpu(cls_acc).item(),\n",
        "                \"recall50\": to_cpu(recall50).item(),\n",
        "                \"recall75\": to_cpu(recall75).item(),\n",
        "                \"precision\": to_cpu(precision).item(),\n",
        "                \"conf_obj\": to_cpu(conf_obj).item(),\n",
        "                \"conf_noobj\": to_cpu(conf_noobj).item(),\n",
        "                \"grid_size\": grid_size,\n",
        "            }\n",
        "\n",
        "            return output, total_loss\n",
        "\n",
        "\n",
        "class Darknet(nn.Module):\n",
        "    \"\"\"YOLOv3 object detection model\"\"\"\n",
        "\n",
        "    def __init__(self, config_path, img_size=1248):\n",
        "        super(Darknet, self).__init__()\n",
        "        #print(\"model def starts :\")\n",
        "        self.module_defs = parse_model_config(config_path)\n",
        "        #for i in self.module_defs:\n",
        "        #    print(i)\n",
        "        #print(\"model def ends :\")\n",
        "        self.hyperparams, self.module_list = create_modules(self.module_defs)\n",
        "        #print(\"module_list starts here :\")\n",
        "        #print(self.module_list)\n",
        "        #print(\"module_list ends here :\")\n",
        "        self.yolo_layers = [layer[0] for layer in self.module_list if hasattr(layer[0], \"metrics\")]\n",
        "        self.img_size = img_size\n",
        "        self.seen = 0\n",
        "        self.header_info = np.array([0, 0, 0, self.seen, 0], dtype=np.int32)\n",
        "\n",
        "    def forward(self, x, targets=None):\n",
        "        img_dim = x.shape[2]\n",
        "        loss = 0\n",
        "        #print(\"layer output = \",x.shape)\n",
        "        #print(\"in darknet before sending to yolo :\",targets[:,2].max())\n",
        "        layer_outputs, yolo_outputs = [], []\n",
        "        for i, (module_def, module) in enumerate(zip(self.module_defs, self.module_list)):\n",
        "            if module_def[\"type\"] in [\"convolutional\", \"upsample\", \"maxpool\"]:\n",
        "                x = module(x)\n",
        "            elif module_def[\"type\"] == \"route\":\n",
        "                x = torch.cat([layer_outputs[int(layer_i)] for layer_i in module_def[\"layers\"].split(\",\")], 1)\n",
        "            elif module_def[\"type\"] == \"shortcut\":\n",
        "                layer_i = int(module_def[\"from\"])\n",
        "                x = layer_outputs[-1] + layer_outputs[layer_i]\n",
        "            elif module_def[\"type\"] == \"yolo\":\n",
        "                #print(\"x shape = \",x.shape)\n",
        "                x, layer_loss = module[0](x, targets, img_dim)\n",
        "                loss += layer_loss\n",
        "                yolo_outputs.append(x)\n",
        "            layer_outputs.append(x)\n",
        "            #print(\"layer output = \",x.shape)\n",
        "            #print(\"from darknet after sending to yolo\",targets[:,2].max())\n",
        "        yolo_outputs = to_cpu(torch.cat(yolo_outputs, 1))\n",
        "        return yolo_outputs if targets is None else (loss, yolo_outputs)\n",
        "\n",
        "    def load_darknet_weights(self, weights_path):\n",
        "        \"\"\"Parses and loads the weights stored in 'weights_path'\"\"\"\n",
        "\n",
        "        # Open the weights file\n",
        "        with open(weights_path, \"rb\") as f:\n",
        "            header = np.fromfile(f, dtype=np.int32, count=5)  # First five are header values\n",
        "            self.header_info = header  # Needed to write header when saving weights\n",
        "            self.seen = header[3]  # number of images seen during training\n",
        "            weights = np.fromfile(f, dtype=np.float32)  # The rest are weights\n",
        "\n",
        "        # Establish cutoff for loading backbone weights\n",
        "        cutoff = None\n",
        "        if \"darknet53.conv.74\" in weights_path:\n",
        "            cutoff = 75\n",
        "\n",
        "        ptr = 0\n",
        "        for i, (module_def, module) in enumerate(zip(self.module_defs, self.module_list)):\n",
        "            if i == cutoff:\n",
        "                break\n",
        "            if module_def[\"type\"] == \"convolutional\":\n",
        "                conv_layer = module[0]\n",
        "                if module_def[\"batch_normalize\"]:\n",
        "                    # Load BN bias, weights, running mean and running variance\n",
        "                    bn_layer = module[1]\n",
        "                    num_b = bn_layer.bias.numel()  # Number of biases\n",
        "                    # Bias\n",
        "                    bn_b = torch.from_numpy(weights[ptr : ptr + num_b]).view_as(bn_layer.bias)\n",
        "                    bn_layer.bias.data.copy_(bn_b)\n",
        "                    ptr += num_b\n",
        "                    # Weight\n",
        "                    bn_w = torch.from_numpy(weights[ptr : ptr + num_b]).view_as(bn_layer.weight)\n",
        "                    bn_layer.weight.data.copy_(bn_w)\n",
        "                    ptr += num_b\n",
        "                    # Running Mean\n",
        "                    bn_rm = torch.from_numpy(weights[ptr : ptr + num_b]).view_as(bn_layer.running_mean)\n",
        "                    bn_layer.running_mean.data.copy_(bn_rm)\n",
        "                    ptr += num_b\n",
        "                    # Running Var\n",
        "                    bn_rv = torch.from_numpy(weights[ptr : ptr + num_b]).view_as(bn_layer.running_var)\n",
        "                    bn_layer.running_var.data.copy_(bn_rv)\n",
        "                    ptr += num_b\n",
        "                else:\n",
        "                    # Load conv. bias\n",
        "                    num_b = conv_layer.bias.numel()\n",
        "                    conv_b = torch.from_numpy(weights[ptr : ptr + num_b]).view_as(conv_layer.bias)\n",
        "                    conv_layer.bias.data.copy_(conv_b)\n",
        "                    ptr += num_b\n",
        "                # Load conv. weights\n",
        "                num_w = conv_layer.weight.numel()\n",
        "                conv_w = torch.from_numpy(weights[ptr : ptr + num_w]).view_as(conv_layer.weight)\n",
        "                conv_layer.weight.data.copy_(conv_w)\n",
        "                ptr += num_w\n",
        "\n",
        "    def save_darknet_weights(self, path, cutoff=-1):\n",
        "        \"\"\"\n",
        "            @:param path    - path of the new weights file\n",
        "            @:param cutoff  - save layers between 0 and cutoff (cutoff = -1 -> all are saved)\n",
        "        \"\"\"\n",
        "        fp = open(path, \"wb\")\n",
        "        self.header_info[3] = self.seen\n",
        "        self.header_info.tofile(fp)\n",
        "\n",
        "        # Iterate through layers\n",
        "        for i, (module_def, module) in enumerate(zip(self.module_defs[:cutoff], self.module_list[:cutoff])):\n",
        "            if module_def[\"type\"] == \"convolutional\":\n",
        "                conv_layer = module[0]\n",
        "                # If batch norm, load bn first\n",
        "                if module_def[\"batch_normalize\"]:\n",
        "                    bn_layer = module[1]\n",
        "                    bn_layer.bias.data.cpu().numpy().tofile(fp)\n",
        "                    bn_layer.weight.data.cpu().numpy().tofile(fp)\n",
        "                    bn_layer.running_mean.data.cpu().numpy().tofile(fp)\n",
        "                    bn_layer.running_var.data.cpu().numpy().tofile(fp)\n",
        "                # Load conv bias\n",
        "                else:\n",
        "                    conv_layer.bias.data.cpu().numpy().tofile(fp)\n",
        "                # Load conv weights\n",
        "                conv_layer.weight.data.cpu().numpy().tofile(fp)\n",
        "\n",
        "        fp.close()\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t51RsFcXEMHk"
      },
      "source": [
        "#Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUGbtD3-FLvV"
      },
      "source": [
        "from __future__ import division\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "import tqdm\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "def evaluate(model, data_samples, iou_thres, conf_thres, nms_thres, img_size, batch_size):\n",
        "    model.eval()\n",
        "\n",
        "    # Get dataloader\n",
        "    dataset = ListDataset(data_samples, img_size=img_size, augment=False, multiscale=False)\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=dataset.collate_fn\n",
        "    )\n",
        "\n",
        "    Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
        "\n",
        "    labels = []\n",
        "    sample_metrics = []  # List of tuples (TP, confs, pred)\n",
        "    for batch_i, (imgs, targets) in enumerate(tqdm.tqdm(dataloader, desc=\"Detecting objects\")):\n",
        "\n",
        "        # Extract labels\n",
        "        labels += targets[:, 1].tolist()\n",
        "        # Rescale target\n",
        "        targets[:, 2:8] = xywh2xyxy(targets[:, 2:8])\n",
        "        targets[:, 2:8] *= img_size\n",
        "\n",
        "        imgs = Variable(imgs.type(Tensor), requires_grad=False)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(imgs)\n",
        "            outputs = non_max_suppression(outputs, conf_thres=conf_thres, nms_thres=nms_thres)\n",
        "\n",
        "        sample_metrics += get_batch_statistics(outputs, targets, iou_threshold=iou_thres)\n",
        "        #print(sample_metrics)\n",
        "        del imgs,targets,outputs\n",
        "        torch.cuda.empty_cache()\n",
        "    # Concatenate sample statistics\n",
        "    if not sample_metrics :\n",
        "      precision, recall, AP, f1, ap_class = np.asarray([0]),np.asarray([0]),np.asarray([0]),np.asarray([0]),[]\n",
        "    else :\n",
        "      true_positives, pred_scores, pred_labels = [np.concatenate(x, 0) for x in list(zip(*sample_metrics))]\n",
        "      precision, recall, AP, f1, ap_class = ap_per_class(true_positives, pred_scores, pred_labels, labels)\n",
        "\n",
        "    return precision, recall, AP, f1, ap_class"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-CRslW0Xujc"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0zm8fD5ISjg"
      },
      "source": [
        "class parameters:\n",
        "  def __init__(self, pretrained_weights = \"/content/drive/MyDrive/SingleImgDepthYolo/weights/darknet53.conv.74\", epochs = 100, batch_size = 8, step_size = 4, model_def = \"/content/drive/MyDrive/SingleImgDepthYolo/config/yolov3custom.cfg\", n_cpu = 8, img_size = 416, checkpoint_interval = 1, evaluation_interval = 5, compute_map = False, multiscale_training = True):#, data_config = \"config/coco.data\"):\n",
        "    self.epochs = epochs #number of epochs\n",
        "    self.batch_size = batch_size #size of each image batch\n",
        "    self.gradient_accumulations =step_size    #number of gradient accums before step\n",
        "    self.model_def = model_def #path to model definition file\n",
        "    #self.data_config = data_config #path to data config file`\n",
        "    self.pretrained_weights = pretrained_weights #if specified starts from checkpoint model\n",
        "    self.n_cpu = n_cpu #number of cpu threads to use during batch generation\n",
        "    self.img_size = img_size #size of each image dimension\n",
        "    self.checkpoint_interval = checkpoint_interval #interval between saving model weights\n",
        "    self.evaluation_interval = evaluation_interval #interval evaluations on validation set\n",
        "    self.compute_map = compute_map #if True computes mAP every tenth batch\n",
        "    self.multiscale_training = multiscale_training #allow for multi-scale training\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oI0p5QnYyK2"
      },
      "source": [
        "opt = parameters(epochs = 3, pretrained_weights = \"/content/drive/MyDrive/SingleImgDepthYolo/checkpoints/full_data_drive-1.pth\",img_size = 1248,batch_size = 2,evaluation_interval = 5,checkpoint_interval=50,step_size=2)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPTzU1mCavSJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "066638ef-7b1f-4f71-9d62-5eccba9aee26"
      },
      "source": [
        "model = Darknet(opt.model_def).to(device)\n",
        "model.apply(weights_init_normal)\n",
        "# If specified we start from checkpoint\n",
        "if opt.pretrained_weights:\n",
        "  #print(opt.pretrained_weights)\n",
        "  if opt.pretrained_weights.endswith(\".pth\"):\n",
        "    model.load_state_dict(torch.load(opt.pretrained_weights))\n",
        "    print(\"finished\")\n",
        "  else:\n",
        "    model.load_darknet_weights(opt.pretrained_weights)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIGSAkmDK3af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d13ee4db-884f-4301-d0c5-c64d3844d7b6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sample_mapping = []\n",
        "for i in range(85):\n",
        "  with open(\"/content/drive/MyDrive/data/sample\"+str(i)+\"/sample.json\") as f:\n",
        "    samples = json.load(f)\n",
        "    for sample_token in samples.keys():\n",
        "      sample_mapping.append(sample_token)\n",
        "\n",
        "train_samples, test_samples = train_test_split(sample_mapping, test_size=0.2, random_state=42)\n",
        "print(len(train_samples),len(test_samples))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27319 6830\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tAWjHQVsV9D"
      },
      "source": [
        "dataset = ListDataset(train_samples, augment=False, multiscale=opt.multiscale_training)\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    collate_fn=dataset.collate_fn,\n",
        ")\n",
        "class_names = dataset.categories"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLdpDzAWZM0D"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr =0.00005)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tGdtKinQ-ll",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7471a85327c94be7ade9ec458ad9c2db",
            "e979c5d3a9064163a52f8b1d3e4c9e06",
            "911495f95a314edeb7991fbf8eb1f9b8",
            "8316d5b506f941ad895849c9c1267dc2",
            "71422304fd664c7eb9fe037b8747bfed",
            "e2e723bcd0f8466a867feee83964ca51",
            "9135e14591284d039d6cff7ad9ba8774",
            "14f7924c51334a348f5e837f8a38deb2"
          ]
        },
        "outputId": "84697a23-9669-4420-b8d5-e4151039e24b"
      },
      "source": [
        "import tqdm\n",
        "for epoch in tqdm.notebook.tqdm(range(opt.epochs),unit='epoch'):\n",
        "    model.train()\n",
        "    for batch_i, (imgs, targets) in enumerate(dataloader):\n",
        "        batches_done = len(dataloader) * epoch + batch_i\n",
        "\n",
        "        imgs = Variable(imgs.to(device))\n",
        "        #print(\"image shape = \",imgs.shape)\n",
        "        targets = Variable(targets.to(device), requires_grad=False)\n",
        "\n",
        "        loss, outputs = model(imgs, targets)\n",
        "        loss.backward()\n",
        "\n",
        "        if batches_done % opt.gradient_accumulations == 0 and opt.gradient_accumulations != 0:\n",
        "            # Accumulates gradient before each step\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        print(batch_i,\"batch\",loss)\n",
        "        del imgs,targets,outputs,loss\n",
        "        torch.cuda.empty_cache()\n",
        "        if batch_i % opt.checkpoint_interval == 0 and batch_i != 0:\n",
        "            torch.save(model.state_dict(), \"/content/drive/MyDrive/SingleImgDepthYolo/checkpoints/full_data_drive-1.pth\")\n",
        "            print(\"Saved\")\n",
        "        \n",
        "        \n",
        "    if epoch % opt.evaluation_interval == 0 and opt.evaluation_interval != 0:\n",
        "        print(\"\\n---- Evaluating Model ----\")\n",
        "        # Evaluate the model on the validation set\n",
        "        precision, recall, AP, f1, ap_class = evaluate(\n",
        "            model,\n",
        "            test_samples,\n",
        "            iou_thres=0.5,\n",
        "            conf_thres=0.5,\n",
        "            nms_thres=0.5,\n",
        "            img_size=opt.img_size,\n",
        "            batch_size=2,\n",
        "        )\n",
        "        evaluation_metrics = [\n",
        "            (\"val_precision\", precision.mean()),\n",
        "            (\"val_recall\", recall.mean()),\n",
        "            (\"val_mAP\", AP.mean()),\n",
        "            (\"val_f1\", f1.mean()),\n",
        "        ]\n",
        "        #logger.list_of_scalars_summary(evaluation_metrics, epoch)\n",
        "\n",
        "        # Print class APs and mAP\n",
        "        ap_table = [[\"Index\", \"Class name\", \"AP\"]]\n",
        "        for i, c in enumerate(ap_class):\n",
        "            ap_table += [[c, class_names[c], \"%.5f\" % AP[i]]]\n",
        "        print(AsciiTable(ap_table).table)\n",
        "        print(f\"---- mAP {AP.mean()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7471a85327c94be7ade9ec458ad9c2db",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:280: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:217: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:218: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:219: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:220: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:221: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:222: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:223: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:224: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:225: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:226: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:228: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:232: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:233: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:234: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "392 batch tensor(16.1568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "393 batch tensor(19.0551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "394 batch tensor(15.5699, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "395 batch tensor(13.9039, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "396 batch tensor(21.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "397 batch tensor(15.9745, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "398 batch tensor(15.4606, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "399 batch tensor(15.6898, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "400 batch tensor(17.2516, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "401 batch tensor(16.6039, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "402 batch tensor(17.4994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "403 batch tensor(16.0899, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "404 batch tensor(16.6498, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "405 batch tensor(19.9543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "406 batch tensor(17.7735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "407 batch tensor(15.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "408 batch tensor(17.3165, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "409 batch tensor(15.3653, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "410 batch tensor(16.2941, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "411 batch tensor(17.2705, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "412 batch tensor(18.8751, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "413 batch tensor(16.5149, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "414 batch tensor(17.4321, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "415 batch tensor(18.4370, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "416 batch tensor(16.3652, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "417 batch tensor(17.0487, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "418 batch tensor(17.5122, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "419 batch tensor(18.7271, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "420 batch tensor(16.7570, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "421 batch tensor(17.6688, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "422 batch tensor(18.2480, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "423 batch tensor(17.8549, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "424 batch tensor(17.6978, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "425 batch tensor(18.7186, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "426 batch tensor(16.3336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "427 batch tensor(16.6237, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "428 batch tensor(18.5175, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "429 batch tensor(20.1405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "430 batch tensor(18.1400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "431 batch tensor(17.5614, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "432 batch tensor(17.6017, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "433 batch tensor(20.0875, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "434 batch tensor(15.5911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "435 batch tensor(15.3849, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "436 batch tensor(17.4257, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "437 batch tensor(17.6249, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "438 batch tensor(17.0346, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "439 batch tensor(16.9149, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "440 batch tensor(17.2974, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "441 batch tensor(17.0549, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "442 batch tensor(19.2490, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "443 batch tensor(17.6708, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "444 batch tensor(17.8496, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "445 batch tensor(15.2101, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "446 batch tensor(16.8888, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "447 batch tensor(15.2719, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "448 batch tensor(17.9584, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "449 batch tensor(16.6890, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "450 batch tensor(18.0107, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "451 batch tensor(16.1618, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "452 batch tensor(18.7245, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "453 batch tensor(18.5551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "454 batch tensor(18.3957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "455 batch tensor(15.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "456 batch tensor(17.5899, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "457 batch tensor(17.8799, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "458 batch tensor(14.9403, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "459 batch tensor(17.1592, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "460 batch tensor(15.7683, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "461 batch tensor(18.1420, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "462 batch tensor(19.9424, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "463 batch tensor(20.7166, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "464 batch tensor(15.7631, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "465 batch tensor(17.1663, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "466 batch tensor(16.6396, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "467 batch tensor(17.4533, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "468 batch tensor(17.3280, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "469 batch tensor(17.8658, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "470 batch tensor(17.3870, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "471 batch tensor(16.7743, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "472 batch tensor(14.7179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "473 batch tensor(16.2542, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "474 batch tensor(18.3908, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "475 batch tensor(18.7930, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "476 batch tensor(18.4672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "477 batch tensor(17.0416, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "478 batch tensor(16.1472, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "479 batch tensor(15.2810, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "480 batch tensor(16.5074, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "481 batch tensor(15.6540, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "482 batch tensor(17.3412, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "483 batch tensor(20.3866, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "484 batch tensor(16.2481, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "485 batch tensor(16.6120, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "486 batch tensor(19.5754, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "487 batch tensor(18.8977, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "488 batch tensor(19.5514, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "489 batch tensor(16.5053, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "490 batch tensor(17.8020, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "491 batch tensor(17.0835, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "492 batch tensor(15.8227, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "493 batch tensor(14.6959, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "494 batch tensor(15.6341, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "495 batch tensor(17.6572, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "496 batch tensor(21.3972, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "497 batch tensor(17.9139, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "498 batch tensor(15.3314, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "499 batch tensor(15.4018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "500 batch tensor(15.4170, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "501 batch tensor(17.0443, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "502 batch tensor(17.4047, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "503 batch tensor(15.7440, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "504 batch tensor(18.7645, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "505 batch tensor(18.9963, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "506 batch tensor(16.5659, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "507 batch tensor(19.9338, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "508 batch tensor(17.1803, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "509 batch tensor(19.3372, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "510 batch tensor(18.4622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "511 batch tensor(16.7787, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "512 batch tensor(17.6206, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "513 batch tensor(15.5510, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "514 batch tensor(16.3512, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "515 batch tensor(17.2105, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "516 batch tensor(16.4285, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "517 batch tensor(14.6425, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "518 batch tensor(16.8591, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "519 batch tensor(18.3245, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "520 batch tensor(21.2751, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "521 batch tensor(17.0250, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "522 batch tensor(19.9504, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "523 batch tensor(18.7281, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "524 batch tensor(17.9768, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "525 batch tensor(20.8032, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "526 batch tensor(17.3839, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "527 batch tensor(17.5854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "528 batch tensor(15.5471, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "529 batch tensor(17.3922, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "530 batch tensor(19.3937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "531 batch tensor(15.9257, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "532 batch tensor(17.4678, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "533 batch tensor(17.6539, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "534 batch tensor(19.1038, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "535 batch tensor(19.0575, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "536 batch tensor(16.1506, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "537 batch tensor(14.8179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "538 batch tensor(17.1548, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "539 batch tensor(17.3129, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "540 batch tensor(18.0009, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "541 batch tensor(17.2530, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "542 batch tensor(15.6572, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "543 batch tensor(20.0030, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "544 batch tensor(16.5869, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "545 batch tensor(19.4333, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "546 batch tensor(17.2235, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "547 batch tensor(17.3192, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "548 batch tensor(15.9522, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "549 batch tensor(17.8419, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "550 batch tensor(17.1357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "551 batch tensor(16.1175, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "552 batch tensor(16.4659, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "553 batch tensor(17.2820, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "554 batch tensor(16.3742, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "555 batch tensor(17.7051, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "556 batch tensor(14.6732, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "557 batch tensor(15.9099, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "558 batch tensor(17.7569, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "559 batch tensor(15.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "560 batch tensor(19.4967, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "561 batch tensor(17.6261, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "562 batch tensor(19.8786, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "563 batch tensor(18.7024, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "564 batch tensor(16.8367, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "565 batch tensor(16.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "566 batch tensor(16.3725, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "567 batch tensor(15.3550, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "568 batch tensor(19.5223, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "569 batch tensor(17.1987, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "570 batch tensor(17.5562, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "571 batch tensor(17.6622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "572 batch tensor(18.5704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "573 batch tensor(15.4866, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "574 batch tensor(17.1677, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "575 batch tensor(17.6084, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "576 batch tensor(16.3224, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "577 batch tensor(19.5902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "578 batch tensor(13.3735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "579 batch tensor(17.9211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "580 batch tensor(17.3278, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "581 batch tensor(18.0033, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "582 batch tensor(20.6223, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "583 batch tensor(16.9251, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "584 batch tensor(15.7798, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "585 batch tensor(19.6427, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "586 batch tensor(18.9889, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "587 batch tensor(15.1783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "588 batch tensor(14.6096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "589 batch tensor(18.3900, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "590 batch tensor(15.1858, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "591 batch tensor(17.0030, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "592 batch tensor(14.2504, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "593 batch tensor(17.8365, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "594 batch tensor(14.7087, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "595 batch tensor(16.6516, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "596 batch tensor(16.3760, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "597 batch tensor(16.6017, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "598 batch tensor(17.7288, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "599 batch tensor(16.1577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "600 batch tensor(18.4245, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "601 batch tensor(16.9911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "602 batch tensor(18.6566, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "603 batch tensor(18.4010, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "604 batch tensor(15.7091, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "605 batch tensor(19.1206, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "606 batch tensor(16.1332, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "607 batch tensor(21.1429, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "608 batch tensor(17.3562, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "609 batch tensor(18.2334, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "610 batch tensor(15.0103, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "611 batch tensor(16.7088, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "612 batch tensor(14.9356, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "613 batch tensor(14.0236, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "614 batch tensor(16.7171, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "615 batch tensor(16.0259, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "616 batch tensor(18.6480, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "617 batch tensor(19.1726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "618 batch tensor(15.5640, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "619 batch tensor(16.7370, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "620 batch tensor(17.1134, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "621 batch tensor(18.6126, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "622 batch tensor(17.0954, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "623 batch tensor(19.2213, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "624 batch tensor(17.3519, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "625 batch tensor(19.4413, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "626 batch tensor(20.0869, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "627 batch tensor(18.6867, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "628 batch tensor(16.1400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "629 batch tensor(16.7022, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "630 batch tensor(14.3909, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "631 batch tensor(15.3072, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "632 batch tensor(15.6982, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "633 batch tensor(17.2165, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "634 batch tensor(15.1609, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "635 batch tensor(19.6211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "636 batch tensor(16.6018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "637 batch tensor(22.3233, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "638 batch tensor(20.4066, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "639 batch tensor(16.7410, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "640 batch tensor(16.1341, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "641 batch tensor(19.8026, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "642 batch tensor(16.5529, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "643 batch tensor(18.8515, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "644 batch tensor(16.6228, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "645 batch tensor(20.1675, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "646 batch tensor(16.8073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "647 batch tensor(15.5656, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "648 batch tensor(14.9081, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "649 batch tensor(17.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "650 batch tensor(15.9302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "651 batch tensor(17.5825, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "652 batch tensor(16.0522, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "653 batch tensor(19.5468, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "654 batch tensor(18.8689, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "655 batch tensor(17.3573, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "656 batch tensor(16.1888, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "657 batch tensor(21.5525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "658 batch tensor(18.4955, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "659 batch tensor(18.3020, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "660 batch tensor(18.5906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "661 batch tensor(17.6429, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "662 batch tensor(19.2427, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "663 batch tensor(17.8934, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "664 batch tensor(18.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "665 batch tensor(17.4144, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "666 batch tensor(16.9568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "667 batch tensor(17.4828, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "668 batch tensor(18.0057, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "669 batch tensor(18.3384, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "670 batch tensor(15.9674, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "671 batch tensor(19.3389, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "672 batch tensor(20.1033, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "673 batch tensor(18.0956, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "674 batch tensor(16.3584, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "675 batch tensor(15.6184, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "676 batch tensor(16.2826, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "677 batch tensor(17.7548, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "678 batch tensor(16.5334, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "679 batch tensor(15.6509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "680 batch tensor(17.2294, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "681 batch tensor(14.8024, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "682 batch tensor(18.1474, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "683 batch tensor(16.9290, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "684 batch tensor(14.9370, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "685 batch tensor(17.5819, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "686 batch tensor(18.4335, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "687 batch tensor(15.8702, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "688 batch tensor(16.6110, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "689 batch tensor(17.6626, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "690 batch tensor(18.4695, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "691 batch tensor(17.1809, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "692 batch tensor(17.6117, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "693 batch tensor(17.4691, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "694 batch tensor(17.5041, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "695 batch tensor(18.8783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "696 batch tensor(15.2339, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "697 batch tensor(17.4988, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "698 batch tensor(17.0182, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "699 batch tensor(16.1746, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "700 batch tensor(18.2997, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "701 batch tensor(18.2179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "702 batch tensor(15.7189, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "703 batch tensor(18.6996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "704 batch tensor(18.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "705 batch tensor(19.5960, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "706 batch tensor(15.3942, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "707 batch tensor(15.5165, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "708 batch tensor(18.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "709 batch tensor(16.3443, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "710 batch tensor(20.8418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "711 batch tensor(18.7521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "712 batch tensor(16.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "713 batch tensor(16.1901, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "714 batch tensor(14.4996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "715 batch tensor(17.0696, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "716 batch tensor(16.0706, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "717 batch tensor(20.3410, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "718 batch tensor(18.3613, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "719 batch tensor(19.0845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "720 batch tensor(19.5756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "721 batch tensor(19.4037, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "722 batch tensor(16.2299, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "723 batch tensor(18.3838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "724 batch tensor(16.7521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "725 batch tensor(17.9994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "726 batch tensor(16.6608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "727 batch tensor(15.8561, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "728 batch tensor(18.9549, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "729 batch tensor(16.8603, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "730 batch tensor(16.3074, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "731 batch tensor(19.1609, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "732 batch tensor(18.2575, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "733 batch tensor(16.3826, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "734 batch tensor(19.9582, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "735 batch tensor(15.2845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "736 batch tensor(16.4859, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "737 batch tensor(18.5615, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "738 batch tensor(17.5237, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "739 batch tensor(16.9772, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "740 batch tensor(16.0672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "741 batch tensor(15.1610, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "742 batch tensor(15.0763, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "743 batch tensor(15.5435, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "744 batch tensor(18.5281, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "745 batch tensor(16.6796, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "746 batch tensor(17.0216, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "747 batch tensor(14.9364, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "748 batch tensor(16.4021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "749 batch tensor(20.3757, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "750 batch tensor(17.2841, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "751 batch tensor(17.1285, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "752 batch tensor(15.6857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "753 batch tensor(18.5188, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "754 batch tensor(16.6008, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "755 batch tensor(14.1373, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "756 batch tensor(16.7269, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "757 batch tensor(16.2181, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "758 batch tensor(17.2088, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "759 batch tensor(16.0206, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "760 batch tensor(17.2719, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "761 batch tensor(17.9179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "762 batch tensor(18.2045, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "763 batch tensor(17.6105, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "764 batch tensor(17.2980, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "765 batch tensor(19.5639, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "766 batch tensor(17.8365, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "767 batch tensor(15.7960, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "768 batch tensor(18.6168, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "769 batch tensor(15.2621, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "770 batch tensor(18.4300, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "771 batch tensor(18.6184, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "772 batch tensor(15.9272, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "773 batch tensor(17.9354, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "774 batch tensor(19.6463, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "775 batch tensor(16.9263, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "776 batch tensor(17.3313, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "777 batch tensor(15.1623, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "778 batch tensor(16.0032, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "779 batch tensor(18.7259, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "780 batch tensor(20.2065, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "781 batch tensor(16.6269, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "782 batch tensor(15.3059, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "783 batch tensor(15.8361, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "784 batch tensor(19.7300, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "785 batch tensor(17.8707, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "786 batch tensor(15.8981, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "787 batch tensor(17.3680, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "788 batch tensor(18.2807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "789 batch tensor(15.5364, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "790 batch tensor(17.6318, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "791 batch tensor(14.7202, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "792 batch tensor(16.5495, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "793 batch tensor(16.6753, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "794 batch tensor(16.6218, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "795 batch tensor(15.9808, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "796 batch tensor(19.0979, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "797 batch tensor(17.6619, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "798 batch tensor(17.2457, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "799 batch tensor(18.4547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "800 batch tensor(16.5666, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "801 batch tensor(15.9289, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "802 batch tensor(14.4604, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "803 batch tensor(18.7084, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "804 batch tensor(16.8056, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "805 batch tensor(18.3644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "806 batch tensor(19.0133, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "807 batch tensor(15.8615, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "808 batch tensor(19.1136, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "809 batch tensor(16.8527, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "810 batch tensor(18.1940, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "811 batch tensor(16.6427, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "812 batch tensor(16.7085, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "813 batch tensor(17.5695, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "814 batch tensor(14.7599, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "815 batch tensor(18.6297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "816 batch tensor(16.8094, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "817 batch tensor(15.7681, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "818 batch tensor(17.7005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "819 batch tensor(18.9320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "820 batch tensor(19.6361, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "821 batch tensor(17.0550, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "822 batch tensor(16.4171, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "823 batch tensor(18.8918, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "824 batch tensor(16.5297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "825 batch tensor(18.3434, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "826 batch tensor(18.7086, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "827 batch tensor(19.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "828 batch tensor(16.7407, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "829 batch tensor(19.0087, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "830 batch tensor(15.8964, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "831 batch tensor(15.8287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "832 batch tensor(16.4602, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "833 batch tensor(17.8365, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "834 batch tensor(19.3760, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "835 batch tensor(16.8915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "836 batch tensor(17.2729, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "837 batch tensor(17.6537, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "838 batch tensor(15.9786, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "839 batch tensor(15.3282, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "840 batch tensor(18.1280, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "841 batch tensor(18.2228, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "842 batch tensor(15.2851, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "843 batch tensor(17.1907, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "844 batch tensor(16.6759, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "845 batch tensor(15.2452, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "846 batch tensor(17.3932, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "847 batch tensor(17.1420, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "848 batch tensor(17.2543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "849 batch tensor(18.9926, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "850 batch tensor(19.0758, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "851 batch tensor(18.5743, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "852 batch tensor(18.4535, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "853 batch tensor(17.2802, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "854 batch tensor(15.0670, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "855 batch tensor(17.9822, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "856 batch tensor(14.8769, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "857 batch tensor(17.4025, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "858 batch tensor(14.6693, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "859 batch tensor(17.4886, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "860 batch tensor(17.6582, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "861 batch tensor(20.1864, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "862 batch tensor(17.5833, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "863 batch tensor(17.5127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "864 batch tensor(17.6192, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "865 batch tensor(18.2030, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "866 batch tensor(17.1207, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "867 batch tensor(17.0589, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "868 batch tensor(15.5548, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "869 batch tensor(17.8119, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "870 batch tensor(16.8457, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "871 batch tensor(17.0754, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "872 batch tensor(17.9621, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "873 batch tensor(15.5336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "874 batch tensor(17.9737, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "875 batch tensor(16.0357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "876 batch tensor(18.9952, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "877 batch tensor(15.2223, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "878 batch tensor(19.4200, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "879 batch tensor(20.5370, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "880 batch tensor(17.8864, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "881 batch tensor(14.9886, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "882 batch tensor(17.1077, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "883 batch tensor(18.9170, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "884 batch tensor(16.4827, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "885 batch tensor(16.9787, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "886 batch tensor(18.1149, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "887 batch tensor(17.4320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "888 batch tensor(17.8335, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "889 batch tensor(20.0478, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "890 batch tensor(17.3251, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "891 batch tensor(17.7777, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "892 batch tensor(16.1001, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "893 batch tensor(15.0223, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "894 batch tensor(17.2579, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "895 batch tensor(18.1872, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "896 batch tensor(17.9854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "897 batch tensor(19.4083, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "898 batch tensor(16.1346, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "899 batch tensor(18.2878, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "900 batch tensor(15.4997, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "901 batch tensor(17.0375, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "902 batch tensor(17.6543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "903 batch tensor(16.6247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "904 batch tensor(18.2636, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "905 batch tensor(17.2583, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "906 batch tensor(17.0179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "907 batch tensor(19.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "908 batch tensor(16.8779, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "909 batch tensor(18.9214, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "910 batch tensor(18.9404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "911 batch tensor(18.2021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "912 batch tensor(17.0126, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "913 batch tensor(17.3070, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "914 batch tensor(17.0055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "915 batch tensor(16.0061, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "916 batch tensor(17.5522, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "917 batch tensor(16.7073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "918 batch tensor(16.1978, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "919 batch tensor(16.9402, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "920 batch tensor(16.3130, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "921 batch tensor(19.8949, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "922 batch tensor(17.4650, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "923 batch tensor(16.4836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "924 batch tensor(16.1652, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "925 batch tensor(17.8637, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "926 batch tensor(16.7550, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "927 batch tensor(18.8746, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "928 batch tensor(19.5383, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "929 batch tensor(16.6167, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "930 batch tensor(15.7374, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "931 batch tensor(16.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "932 batch tensor(16.2544, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "933 batch tensor(17.3253, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "934 batch tensor(16.6402, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "935 batch tensor(17.1677, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "936 batch tensor(17.4250, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "937 batch tensor(15.8380, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "938 batch tensor(20.1802, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "939 batch tensor(20.0229, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "940 batch tensor(18.3492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "941 batch tensor(17.5557, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "942 batch tensor(17.3654, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "943 batch tensor(17.9928, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "944 batch tensor(14.4305, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "945 batch tensor(15.7897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "946 batch tensor(15.9241, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "947 batch tensor(16.6434, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "948 batch tensor(18.0446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "949 batch tensor(18.4756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "950 batch tensor(17.6447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "951 batch tensor(17.5354, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "952 batch tensor(17.9858, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "953 batch tensor(18.9745, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "954 batch tensor(18.5705, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "955 batch tensor(16.5080, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "956 batch tensor(19.7200, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "957 batch tensor(16.5190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "958 batch tensor(19.0055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "959 batch tensor(17.1431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "960 batch tensor(20.0253, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "961 batch tensor(15.9242, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "962 batch tensor(17.4501, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "963 batch tensor(17.2161, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "964 batch tensor(17.2742, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "965 batch tensor(15.4344, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "966 batch tensor(15.7054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "967 batch tensor(14.6591, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "968 batch tensor(15.3157, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "969 batch tensor(16.6650, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "970 batch tensor(15.4372, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "971 batch tensor(16.3411, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "972 batch tensor(16.1957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "973 batch tensor(16.4237, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "974 batch tensor(19.2460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "975 batch tensor(18.4098, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "976 batch tensor(16.9665, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "977 batch tensor(17.3792, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "978 batch tensor(18.5476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "979 batch tensor(19.1866, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "980 batch tensor(16.6029, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "981 batch tensor(14.0967, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "982 batch tensor(14.8813, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "983 batch tensor(17.6739, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "984 batch tensor(17.3696, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "985 batch tensor(16.6478, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "986 batch tensor(17.2463, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "987 batch tensor(18.9382, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "988 batch tensor(19.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "989 batch tensor(18.9048, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "990 batch tensor(17.6610, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "991 batch tensor(17.9373, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "992 batch tensor(17.8679, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "993 batch tensor(17.8847, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "994 batch tensor(19.2823, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "995 batch tensor(17.6469, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "996 batch tensor(18.6469, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "997 batch tensor(17.4790, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "998 batch tensor(17.6869, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "999 batch tensor(18.0489, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1000 batch tensor(16.4130, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1001 batch tensor(15.0891, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1002 batch tensor(16.2741, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1003 batch tensor(18.5473, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1004 batch tensor(16.2157, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1005 batch tensor(17.2959, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1006 batch tensor(14.1230, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1007 batch tensor(16.6615, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1008 batch tensor(15.9289, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1009 batch tensor(18.4534, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1010 batch tensor(19.0042, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1011 batch tensor(16.8570, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1012 batch tensor(17.0775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1013 batch tensor(17.8928, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1014 batch tensor(15.7989, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1015 batch tensor(17.0027, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1016 batch tensor(16.3172, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1017 batch tensor(15.6988, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1018 batch tensor(17.7870, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1019 batch tensor(18.8049, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1020 batch tensor(16.3395, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1021 batch tensor(18.3857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1022 batch tensor(16.9777, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1023 batch tensor(14.1031, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1024 batch tensor(18.0647, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1025 batch tensor(16.7152, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1026 batch tensor(18.3533, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1027 batch tensor(16.7424, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1028 batch tensor(17.8617, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1029 batch tensor(18.1326, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1030 batch tensor(15.0564, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1031 batch tensor(15.9150, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1032 batch tensor(15.9006, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1033 batch tensor(16.9926, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1034 batch tensor(15.5192, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1035 batch tensor(18.0526, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1036 batch tensor(18.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1037 batch tensor(17.1968, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1038 batch tensor(15.0863, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1039 batch tensor(18.1487, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1040 batch tensor(18.1431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1041 batch tensor(16.3223, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1042 batch tensor(18.2036, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1043 batch tensor(19.0474, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1044 batch tensor(18.1825, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1045 batch tensor(16.8710, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1046 batch tensor(15.1907, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1047 batch tensor(19.3188, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1048 batch tensor(15.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1049 batch tensor(16.3052, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1050 batch tensor(20.6789, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1051 batch tensor(18.6957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1052 batch tensor(16.9320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1053 batch tensor(15.8912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1054 batch tensor(17.9658, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1055 batch tensor(17.6751, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1056 batch tensor(16.9897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1057 batch tensor(16.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1058 batch tensor(18.0247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1059 batch tensor(17.4544, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1060 batch tensor(17.8020, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1061 batch tensor(18.1032, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1062 batch tensor(18.9562, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1063 batch tensor(17.3036, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1064 batch tensor(18.1369, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1065 batch tensor(16.9672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1066 batch tensor(17.0172, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1067 batch tensor(15.6717, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1068 batch tensor(17.7207, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1069 batch tensor(18.2536, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1070 batch tensor(16.2248, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1071 batch tensor(18.3223, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1072 batch tensor(16.5770, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1073 batch tensor(15.7630, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1074 batch tensor(16.6823, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1075 batch tensor(16.2166, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1076 batch tensor(17.3590, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1077 batch tensor(16.9975, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1078 batch tensor(18.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1079 batch tensor(18.2611, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1080 batch tensor(17.4634, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1081 batch tensor(13.5036, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1082 batch tensor(21.3912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1083 batch tensor(15.8285, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1084 batch tensor(20.5160, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1085 batch tensor(16.5985, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1086 batch tensor(20.4639, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1087 batch tensor(15.9205, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1088 batch tensor(17.7591, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1089 batch tensor(18.0088, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1090 batch tensor(13.9096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1091 batch tensor(17.1237, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1092 batch tensor(17.8358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1093 batch tensor(17.6351, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1094 batch tensor(17.8935, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1095 batch tensor(18.1057, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1096 batch tensor(17.5292, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1097 batch tensor(15.3893, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1098 batch tensor(19.2755, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1099 batch tensor(17.2467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1100 batch tensor(18.0414, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1101 batch tensor(17.2792, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1102 batch tensor(18.8285, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1103 batch tensor(17.1850, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1104 batch tensor(14.5677, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1105 batch tensor(15.9249, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1106 batch tensor(18.0532, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1107 batch tensor(15.4292, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1108 batch tensor(14.6861, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1109 batch tensor(17.3383, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1110 batch tensor(19.0394, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1111 batch tensor(17.3727, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1112 batch tensor(17.2529, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1113 batch tensor(17.6912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1114 batch tensor(17.3813, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1115 batch tensor(15.2676, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1116 batch tensor(16.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1117 batch tensor(14.5215, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1118 batch tensor(18.8822, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1119 batch tensor(18.1331, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1120 batch tensor(15.6678, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1121 batch tensor(16.3387, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1122 batch tensor(16.1379, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1123 batch tensor(17.3883, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1124 batch tensor(17.1065, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1125 batch tensor(18.7126, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1126 batch tensor(19.2858, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1127 batch tensor(18.5672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1128 batch tensor(16.4466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1129 batch tensor(17.3435, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1130 batch tensor(18.1750, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1131 batch tensor(15.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1132 batch tensor(16.7679, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1133 batch tensor(18.0067, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1134 batch tensor(16.1499, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1135 batch tensor(16.5224, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1136 batch tensor(16.8456, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1137 batch tensor(18.3128, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1138 batch tensor(18.1559, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1139 batch tensor(17.3864, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1140 batch tensor(17.2804, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1141 batch tensor(18.9850, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1142 batch tensor(16.8179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1143 batch tensor(18.7275, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1144 batch tensor(16.3980, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1145 batch tensor(18.9901, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1146 batch tensor(15.6975, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1147 batch tensor(17.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1148 batch tensor(18.4747, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1149 batch tensor(16.9148, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1150 batch tensor(17.4238, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1151 batch tensor(17.9055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1152 batch tensor(18.6443, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1153 batch tensor(17.2016, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1154 batch tensor(18.6381, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1155 batch tensor(19.1232, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1156 batch tensor(15.5121, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1157 batch tensor(17.6684, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1158 batch tensor(19.0930, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1159 batch tensor(16.4565, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1160 batch tensor(17.7952, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1161 batch tensor(16.1439, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1162 batch tensor(17.4923, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1163 batch tensor(17.3740, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1164 batch tensor(18.8415, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1165 batch tensor(15.8010, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1166 batch tensor(17.6265, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1167 batch tensor(15.5600, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1168 batch tensor(19.3157, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1169 batch tensor(14.8788, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1170 batch tensor(15.9968, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1171 batch tensor(18.8715, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1172 batch tensor(15.0133, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1173 batch tensor(15.4322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1174 batch tensor(17.2406, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1175 batch tensor(18.9043, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1176 batch tensor(21.6147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1177 batch tensor(17.7218, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1178 batch tensor(19.0697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1179 batch tensor(18.9471, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1180 batch tensor(16.8635, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1181 batch tensor(17.6568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1182 batch tensor(15.4470, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1183 batch tensor(15.6037, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1184 batch tensor(20.5674, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1185 batch tensor(15.6711, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1186 batch tensor(18.5989, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1187 batch tensor(16.2792, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1188 batch tensor(14.1099, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1189 batch tensor(18.1796, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1190 batch tensor(17.0322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1191 batch tensor(18.3186, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1192 batch tensor(18.0277, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1193 batch tensor(18.3163, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1194 batch tensor(15.8194, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1195 batch tensor(17.5362, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1196 batch tensor(16.3488, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1197 batch tensor(18.7287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1198 batch tensor(15.7418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1199 batch tensor(14.7644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1200 batch tensor(18.1544, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1201 batch tensor(16.8629, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1202 batch tensor(15.6885, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1203 batch tensor(18.4241, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1204 batch tensor(17.5925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1205 batch tensor(15.9225, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1206 batch tensor(17.5660, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1207 batch tensor(17.2790, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1208 batch tensor(18.0761, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1209 batch tensor(18.7453, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1210 batch tensor(16.4525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1211 batch tensor(17.1723, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1212 batch tensor(16.8495, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1213 batch tensor(17.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1214 batch tensor(17.9829, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1215 batch tensor(15.7909, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1216 batch tensor(20.3609, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1217 batch tensor(19.5024, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1218 batch tensor(15.3142, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1219 batch tensor(18.1814, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1220 batch tensor(16.5160, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1221 batch tensor(15.1618, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1222 batch tensor(18.1832, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1223 batch tensor(15.0844, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1224 batch tensor(21.4202, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1225 batch tensor(15.5570, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1226 batch tensor(18.3037, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1227 batch tensor(15.8756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1228 batch tensor(18.1386, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1229 batch tensor(17.7819, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1230 batch tensor(17.3902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1231 batch tensor(15.1472, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1232 batch tensor(16.3156, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1233 batch tensor(16.8303, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1234 batch tensor(17.8667, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1235 batch tensor(15.4066, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1236 batch tensor(14.7995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1237 batch tensor(15.2298, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1238 batch tensor(19.1104, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1239 batch tensor(15.8158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1240 batch tensor(17.2349, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1241 batch tensor(16.1561, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1242 batch tensor(16.6569, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1243 batch tensor(17.3730, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1244 batch tensor(14.8853, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1245 batch tensor(17.4860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1246 batch tensor(18.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1247 batch tensor(15.6905, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1248 batch tensor(17.5434, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1249 batch tensor(18.2056, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1250 batch tensor(18.4699, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1251 batch tensor(15.9337, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1252 batch tensor(18.9995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1253 batch tensor(19.2450, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1254 batch tensor(19.7664, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1255 batch tensor(16.9243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1256 batch tensor(18.5537, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1257 batch tensor(15.3618, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1258 batch tensor(18.7347, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1259 batch tensor(18.7036, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1260 batch tensor(16.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1261 batch tensor(19.0105, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1262 batch tensor(15.9955, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1263 batch tensor(14.0580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1264 batch tensor(18.8811, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1265 batch tensor(14.7626, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1266 batch tensor(19.5671, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1267 batch tensor(17.9644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1268 batch tensor(17.0525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1269 batch tensor(20.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1270 batch tensor(16.7370, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1271 batch tensor(18.9221, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1272 batch tensor(17.8036, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1273 batch tensor(18.7751, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1274 batch tensor(18.2975, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1275 batch tensor(17.7374, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1276 batch tensor(17.8679, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1277 batch tensor(18.4975, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1278 batch tensor(16.5238, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1279 batch tensor(15.9685, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1280 batch tensor(15.8709, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1281 batch tensor(17.0734, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1282 batch tensor(18.9446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1283 batch tensor(18.5097, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1284 batch tensor(18.1360, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1285 batch tensor(16.0895, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1286 batch tensor(18.6967, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1287 batch tensor(16.3038, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1288 batch tensor(17.4982, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1289 batch tensor(13.7589, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1290 batch tensor(14.8026, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1291 batch tensor(16.2444, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1292 batch tensor(18.1651, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1293 batch tensor(21.5035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1294 batch tensor(18.5073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1295 batch tensor(15.0642, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1296 batch tensor(15.9395, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1297 batch tensor(18.1611, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1298 batch tensor(18.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1299 batch tensor(19.2252, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1300 batch tensor(15.9137, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1301 batch tensor(16.3272, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1302 batch tensor(15.6938, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1303 batch tensor(17.8886, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1304 batch tensor(17.6663, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1305 batch tensor(17.0579, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1306 batch tensor(19.5681, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1307 batch tensor(16.7486, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1308 batch tensor(15.0097, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1309 batch tensor(18.9508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1310 batch tensor(16.4077, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1311 batch tensor(18.3329, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1312 batch tensor(19.9495, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1313 batch tensor(14.0306, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1314 batch tensor(19.1564, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1315 batch tensor(14.4696, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1316 batch tensor(15.9929, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1317 batch tensor(16.3663, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1318 batch tensor(18.9555, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1319 batch tensor(16.3419, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1320 batch tensor(15.9631, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1321 batch tensor(16.5872, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1322 batch tensor(16.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1323 batch tensor(18.6548, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1324 batch tensor(20.5580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1325 batch tensor(17.2115, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1326 batch tensor(15.7376, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1327 batch tensor(15.3966, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1328 batch tensor(15.1904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1329 batch tensor(16.9249, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1330 batch tensor(16.5715, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1331 batch tensor(17.9264, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1332 batch tensor(18.6845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1333 batch tensor(17.3994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1334 batch tensor(17.5744, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1335 batch tensor(16.5384, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1336 batch tensor(15.0797, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1337 batch tensor(16.1556, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1338 batch tensor(16.2040, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1339 batch tensor(19.8765, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1340 batch tensor(17.6906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1341 batch tensor(17.5690, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1342 batch tensor(17.1284, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1343 batch tensor(16.8645, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1344 batch tensor(14.2106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1345 batch tensor(15.1862, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1346 batch tensor(19.7689, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1347 batch tensor(17.5697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1348 batch tensor(20.5788, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1349 batch tensor(14.5294, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1350 batch tensor(18.4925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1351 batch tensor(18.6541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1352 batch tensor(14.7719, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1353 batch tensor(17.6815, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1354 batch tensor(17.3082, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1355 batch tensor(16.3946, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1356 batch tensor(18.1306, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1357 batch tensor(16.4283, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1358 batch tensor(18.4171, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1359 batch tensor(16.4225, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1360 batch tensor(19.3495, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1361 batch tensor(14.5991, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1362 batch tensor(17.0878, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1363 batch tensor(18.3834, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1364 batch tensor(16.8932, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1365 batch tensor(17.3542, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1366 batch tensor(18.6177, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1367 batch tensor(19.0057, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1368 batch tensor(16.5236, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1369 batch tensor(18.5240, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1370 batch tensor(15.7667, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1371 batch tensor(15.7167, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1372 batch tensor(16.5943, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1373 batch tensor(16.4059, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1374 batch tensor(20.0123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1375 batch tensor(18.6064, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1376 batch tensor(16.7243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1377 batch tensor(16.2541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1378 batch tensor(17.6551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1379 batch tensor(16.9854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1380 batch tensor(16.6489, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1381 batch tensor(14.7801, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1382 batch tensor(20.1994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1383 batch tensor(20.3469, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1384 batch tensor(17.4195, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1385 batch tensor(16.7581, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1386 batch tensor(14.8102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1387 batch tensor(16.4546, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1388 batch tensor(18.4855, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1389 batch tensor(17.1196, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1390 batch tensor(20.2943, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1391 batch tensor(17.7606, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1392 batch tensor(16.4910, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1393 batch tensor(17.3623, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1394 batch tensor(17.7917, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1395 batch tensor(17.9001, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1396 batch tensor(16.9855, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1397 batch tensor(16.4931, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1398 batch tensor(17.8461, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1399 batch tensor(18.6817, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1400 batch tensor(17.9756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1401 batch tensor(15.7581, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1402 batch tensor(17.2354, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1403 batch tensor(14.2976, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1404 batch tensor(18.5298, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1405 batch tensor(19.9912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1406 batch tensor(17.2023, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1407 batch tensor(17.0335, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1408 batch tensor(15.7696, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1409 batch tensor(16.0381, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1410 batch tensor(18.8452, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1411 batch tensor(17.1701, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1412 batch tensor(17.9578, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1413 batch tensor(18.1084, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1414 batch tensor(16.8842, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1415 batch tensor(19.6965, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1416 batch tensor(16.9167, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1417 batch tensor(15.3840, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1418 batch tensor(19.3718, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1419 batch tensor(16.3976, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1420 batch tensor(17.7964, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1421 batch tensor(18.4548, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1422 batch tensor(18.6907, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1423 batch tensor(19.3741, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1424 batch tensor(17.1972, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1425 batch tensor(19.8941, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1426 batch tensor(16.4907, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1427 batch tensor(19.5088, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1428 batch tensor(18.2035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1429 batch tensor(17.2476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1430 batch tensor(17.9812, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1431 batch tensor(15.1782, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1432 batch tensor(16.0451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1433 batch tensor(17.7040, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1434 batch tensor(20.1764, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1435 batch tensor(15.3415, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1436 batch tensor(17.5185, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1437 batch tensor(16.1808, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1438 batch tensor(16.8167, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1439 batch tensor(17.7485, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1440 batch tensor(16.8420, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1441 batch tensor(15.6678, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1442 batch tensor(16.9302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1443 batch tensor(16.7615, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1444 batch tensor(18.8934, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1445 batch tensor(15.9791, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1446 batch tensor(14.9977, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1447 batch tensor(15.8275, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1448 batch tensor(17.5644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1449 batch tensor(18.7416, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1450 batch tensor(16.7987, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1451 batch tensor(21.0213, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1452 batch tensor(17.9478, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1453 batch tensor(16.1316, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1454 batch tensor(17.2445, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1455 batch tensor(16.3057, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1456 batch tensor(18.4009, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1457 batch tensor(15.6439, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1458 batch tensor(17.5585, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1459 batch tensor(15.6347, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1460 batch tensor(17.3159, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1461 batch tensor(16.7367, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1462 batch tensor(16.4891, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1463 batch tensor(18.5021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1464 batch tensor(14.5344, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1465 batch tensor(16.8836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1466 batch tensor(16.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1467 batch tensor(18.0538, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1468 batch tensor(16.2466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1469 batch tensor(15.8761, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1470 batch tensor(20.0239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1471 batch tensor(20.1127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1472 batch tensor(18.6151, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1473 batch tensor(18.5328, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1474 batch tensor(17.5399, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1475 batch tensor(17.4456, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1476 batch tensor(18.6394, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1477 batch tensor(18.9318, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1478 batch tensor(16.7132, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1479 batch tensor(14.6600, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1480 batch tensor(17.6336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1481 batch tensor(14.1995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1482 batch tensor(16.1738, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1483 batch tensor(16.8811, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1484 batch tensor(15.2294, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1485 batch tensor(16.5996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1486 batch tensor(17.3257, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1487 batch tensor(17.0945, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1488 batch tensor(17.6389, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1489 batch tensor(15.6778, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1490 batch tensor(17.9546, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1491 batch tensor(16.7101, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1492 batch tensor(19.0106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1493 batch tensor(15.6901, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1494 batch tensor(16.5341, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1495 batch tensor(20.7396, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1496 batch tensor(19.0950, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1497 batch tensor(17.6106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1498 batch tensor(17.5357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1499 batch tensor(16.0361, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1500 batch tensor(19.6630, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1501 batch tensor(17.3191, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1502 batch tensor(15.9030, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1503 batch tensor(17.4001, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1504 batch tensor(19.2524, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1505 batch tensor(16.4857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1506 batch tensor(18.7229, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1507 batch tensor(18.1939, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1508 batch tensor(19.3267, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1509 batch tensor(15.6883, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1510 batch tensor(18.5576, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1511 batch tensor(16.9802, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1512 batch tensor(17.6594, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1513 batch tensor(17.3913, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1514 batch tensor(15.1334, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1515 batch tensor(18.3818, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1516 batch tensor(15.9746, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1517 batch tensor(17.2868, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1518 batch tensor(16.3413, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1519 batch tensor(17.0642, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1520 batch tensor(16.8697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1521 batch tensor(19.6692, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1522 batch tensor(18.9301, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1523 batch tensor(20.2180, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1524 batch tensor(17.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1525 batch tensor(15.8262, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1526 batch tensor(21.2201, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1527 batch tensor(16.2060, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1528 batch tensor(17.5619, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1529 batch tensor(14.3318, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1530 batch tensor(17.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1531 batch tensor(18.6613, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1532 batch tensor(15.8747, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1533 batch tensor(18.3939, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1534 batch tensor(17.9746, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1535 batch tensor(21.3041, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1536 batch tensor(14.9661, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1537 batch tensor(14.3786, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1538 batch tensor(16.5431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1539 batch tensor(17.2000, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1540 batch tensor(17.1258, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1541 batch tensor(14.6323, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1542 batch tensor(18.0394, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1543 batch tensor(19.1005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1544 batch tensor(16.9662, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1545 batch tensor(18.4203, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1546 batch tensor(17.4365, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1547 batch tensor(17.2553, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1548 batch tensor(21.8235, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1549 batch tensor(15.1604, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1550 batch tensor(18.6707, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1551 batch tensor(16.7908, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1552 batch tensor(17.7099, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1553 batch tensor(16.4867, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1554 batch tensor(18.8582, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1555 batch tensor(14.8046, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1556 batch tensor(18.3324, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1557 batch tensor(17.8612, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1558 batch tensor(16.3329, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1559 batch tensor(16.7002, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1560 batch tensor(18.7596, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1561 batch tensor(17.6920, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1562 batch tensor(16.7703, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1563 batch tensor(15.6577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1564 batch tensor(16.7921, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1565 batch tensor(16.6237, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1566 batch tensor(19.9722, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1567 batch tensor(18.3137, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1568 batch tensor(20.3300, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1569 batch tensor(16.0737, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1570 batch tensor(14.8968, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1571 batch tensor(15.8353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1572 batch tensor(15.9457, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1573 batch tensor(15.4508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1574 batch tensor(15.8619, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1575 batch tensor(17.9247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1576 batch tensor(18.3073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1577 batch tensor(17.5891, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1578 batch tensor(15.6347, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1579 batch tensor(19.6195, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1580 batch tensor(15.1638, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1581 batch tensor(16.5181, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1582 batch tensor(15.7544, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1583 batch tensor(16.8836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1584 batch tensor(17.3689, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1585 batch tensor(17.7186, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1586 batch tensor(18.6309, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1587 batch tensor(15.3863, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1588 batch tensor(15.7186, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1589 batch tensor(16.8894, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1590 batch tensor(19.1347, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1591 batch tensor(17.4704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1592 batch tensor(16.2753, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1593 batch tensor(18.2201, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1594 batch tensor(16.6883, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1595 batch tensor(17.7581, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1596 batch tensor(19.4200, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1597 batch tensor(19.9867, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1598 batch tensor(15.7468, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1599 batch tensor(15.4213, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1600 batch tensor(17.7772, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1601 batch tensor(16.1638, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1602 batch tensor(19.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1603 batch tensor(15.0573, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1604 batch tensor(17.0168, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1605 batch tensor(17.1330, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1606 batch tensor(15.2760, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1607 batch tensor(17.4894, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1608 batch tensor(15.5845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1609 batch tensor(19.3591, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1610 batch tensor(19.3182, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1611 batch tensor(17.2480, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1612 batch tensor(19.6847, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1613 batch tensor(18.8076, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1614 batch tensor(16.9271, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1615 batch tensor(16.3978, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1616 batch tensor(16.0198, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1617 batch tensor(16.8084, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1618 batch tensor(18.5328, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1619 batch tensor(17.4917, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1620 batch tensor(19.4140, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1621 batch tensor(17.2059, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1622 batch tensor(16.2957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1623 batch tensor(16.6136, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1624 batch tensor(18.9999, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1625 batch tensor(17.5998, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1626 batch tensor(17.5106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1627 batch tensor(18.1749, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1628 batch tensor(17.9384, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1629 batch tensor(17.7870, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1630 batch tensor(18.1931, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1631 batch tensor(17.4848, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1632 batch tensor(15.2755, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1633 batch tensor(16.8761, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1634 batch tensor(15.0302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1635 batch tensor(16.5555, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1636 batch tensor(20.3646, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1637 batch tensor(18.5580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1638 batch tensor(15.8673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1639 batch tensor(16.5984, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1640 batch tensor(18.2401, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1641 batch tensor(21.4294, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1642 batch tensor(20.4579, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1643 batch tensor(16.6826, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1644 batch tensor(13.4892, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1645 batch tensor(17.5983, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1646 batch tensor(15.9967, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1647 batch tensor(15.3232, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1648 batch tensor(16.3872, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1649 batch tensor(16.5076, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1650 batch tensor(17.1444, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1651 batch tensor(18.2405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1652 batch tensor(17.1736, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1653 batch tensor(17.3346, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1654 batch tensor(17.8838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1655 batch tensor(16.3118, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1656 batch tensor(14.7166, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1657 batch tensor(16.4254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1658 batch tensor(17.6222, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1659 batch tensor(18.3215, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1660 batch tensor(15.5774, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1661 batch tensor(18.2790, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1662 batch tensor(14.2148, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1663 batch tensor(14.7771, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1664 batch tensor(15.4027, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1665 batch tensor(15.3257, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1666 batch tensor(16.8501, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1667 batch tensor(19.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1668 batch tensor(19.7913, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1669 batch tensor(19.2159, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1670 batch tensor(16.9169, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1671 batch tensor(17.0100, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1672 batch tensor(15.0677, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1673 batch tensor(15.3925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1674 batch tensor(17.2749, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1675 batch tensor(18.2341, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1676 batch tensor(16.9665, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1677 batch tensor(15.6428, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1678 batch tensor(18.1734, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1679 batch tensor(18.9210, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1680 batch tensor(17.2736, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1681 batch tensor(17.2000, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1682 batch tensor(15.1276, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1683 batch tensor(15.9537, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1684 batch tensor(17.5759, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1685 batch tensor(18.1290, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1686 batch tensor(15.9862, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1687 batch tensor(21.3487, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1688 batch tensor(17.8642, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1689 batch tensor(18.1583, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1690 batch tensor(16.9139, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1691 batch tensor(18.6071, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1692 batch tensor(17.9949, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1693 batch tensor(17.7320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1694 batch tensor(16.2476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1695 batch tensor(15.1303, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1696 batch tensor(17.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1697 batch tensor(18.9498, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1698 batch tensor(17.8940, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1699 batch tensor(16.2865, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1700 batch tensor(17.4718, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1701 batch tensor(16.9680, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1702 batch tensor(18.2306, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1703 batch tensor(18.5558, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1704 batch tensor(17.2263, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1705 batch tensor(20.1239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1706 batch tensor(18.1392, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1707 batch tensor(15.9646, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1708 batch tensor(17.3964, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1709 batch tensor(16.4123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1710 batch tensor(15.8371, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1711 batch tensor(15.7751, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1712 batch tensor(18.8109, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1713 batch tensor(16.2012, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1714 batch tensor(17.9577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1715 batch tensor(20.5042, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1716 batch tensor(14.4494, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1717 batch tensor(18.0611, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1718 batch tensor(16.6739, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1719 batch tensor(18.5217, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1720 batch tensor(21.5184, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1721 batch tensor(16.6465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1722 batch tensor(14.2689, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1723 batch tensor(17.2901, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1724 batch tensor(20.6376, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1725 batch tensor(16.1826, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1726 batch tensor(17.0120, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1727 batch tensor(14.9731, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1728 batch tensor(19.0569, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1729 batch tensor(16.0058, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1730 batch tensor(15.4917, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1731 batch tensor(16.6949, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1732 batch tensor(16.7474, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1733 batch tensor(17.4785, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1734 batch tensor(15.1699, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1735 batch tensor(18.8230, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1736 batch tensor(19.7912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1737 batch tensor(16.0027, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1738 batch tensor(17.5070, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1739 batch tensor(16.0202, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1740 batch tensor(15.8842, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1741 batch tensor(17.6349, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1742 batch tensor(20.2197, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1743 batch tensor(16.3097, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1744 batch tensor(19.2049, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1745 batch tensor(17.2443, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1746 batch tensor(17.7252, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1747 batch tensor(14.3684, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1748 batch tensor(20.2376, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1749 batch tensor(20.2536, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1750 batch tensor(19.7712, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1751 batch tensor(18.2692, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1752 batch tensor(15.4458, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1753 batch tensor(16.5752, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1754 batch tensor(15.4203, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1755 batch tensor(17.0974, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1756 batch tensor(19.3254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1757 batch tensor(19.5291, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1758 batch tensor(15.7787, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1759 batch tensor(18.1044, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1760 batch tensor(15.2983, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1761 batch tensor(16.6929, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1762 batch tensor(17.9381, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1763 batch tensor(16.6995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1764 batch tensor(17.2242, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1765 batch tensor(15.9058, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1766 batch tensor(18.3351, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1767 batch tensor(16.1027, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1768 batch tensor(16.6688, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1769 batch tensor(18.0019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1770 batch tensor(16.8024, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1771 batch tensor(16.8918, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1772 batch tensor(16.8628, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1773 batch tensor(16.1312, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1774 batch tensor(16.2545, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1775 batch tensor(16.9589, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1776 batch tensor(20.7135, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1777 batch tensor(16.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1778 batch tensor(16.9787, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1779 batch tensor(15.4359, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1780 batch tensor(15.4938, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1781 batch tensor(18.0676, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1782 batch tensor(14.1698, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1783 batch tensor(14.1153, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1784 batch tensor(17.1807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1785 batch tensor(19.9490, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1786 batch tensor(18.9859, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1787 batch tensor(16.9076, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1788 batch tensor(17.4976, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1789 batch tensor(19.0328, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1790 batch tensor(18.5546, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1791 batch tensor(17.5249, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1792 batch tensor(17.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1793 batch tensor(19.3206, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1794 batch tensor(17.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1795 batch tensor(15.1196, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1796 batch tensor(15.9978, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1797 batch tensor(14.8191, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1798 batch tensor(17.1727, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1799 batch tensor(15.6228, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1800 batch tensor(17.4152, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1801 batch tensor(17.1701, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1802 batch tensor(17.2532, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1803 batch tensor(19.4429, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1804 batch tensor(18.5009, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1805 batch tensor(17.6226, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1806 batch tensor(17.8162, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1807 batch tensor(16.9662, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1808 batch tensor(18.2484, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1809 batch tensor(17.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1810 batch tensor(16.7882, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1811 batch tensor(16.4983, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1812 batch tensor(20.0797, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1813 batch tensor(17.9775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1814 batch tensor(16.5892, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1815 batch tensor(14.9008, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1816 batch tensor(15.6610, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1817 batch tensor(18.9221, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1818 batch tensor(16.1848, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1819 batch tensor(14.7019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1820 batch tensor(16.5480, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1821 batch tensor(18.7567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1822 batch tensor(16.6034, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1823 batch tensor(16.0224, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1824 batch tensor(16.5214, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1825 batch tensor(17.9423, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1826 batch tensor(19.5082, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1827 batch tensor(17.6304, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1828 batch tensor(18.9640, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1829 batch tensor(18.0934, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1830 batch tensor(18.0887, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1831 batch tensor(16.5221, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1832 batch tensor(15.3313, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1833 batch tensor(15.9416, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1834 batch tensor(19.5369, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1835 batch tensor(20.5502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1836 batch tensor(15.6760, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1837 batch tensor(17.1147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1838 batch tensor(17.7968, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1839 batch tensor(18.1541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1840 batch tensor(16.2214, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1841 batch tensor(15.8142, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1842 batch tensor(16.9563, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1843 batch tensor(16.5848, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1844 batch tensor(17.4678, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1845 batch tensor(16.9186, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1846 batch tensor(17.4797, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1847 batch tensor(16.3700, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1848 batch tensor(17.7490, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1849 batch tensor(16.6498, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1850 batch tensor(16.6393, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1851 batch tensor(19.8085, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1852 batch tensor(17.4758, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1853 batch tensor(16.0475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1854 batch tensor(17.0530, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1855 batch tensor(17.0809, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1856 batch tensor(16.5739, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1857 batch tensor(17.3391, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1858 batch tensor(16.6713, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1859 batch tensor(16.3457, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1860 batch tensor(14.7623, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1861 batch tensor(17.1919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1862 batch tensor(16.8651, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1863 batch tensor(15.9644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1864 batch tensor(18.6341, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1865 batch tensor(17.2873, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1866 batch tensor(20.4055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1867 batch tensor(16.2657, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1868 batch tensor(16.9625, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1869 batch tensor(16.0289, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1870 batch tensor(16.0419, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1871 batch tensor(16.6395, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1872 batch tensor(20.1767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1873 batch tensor(17.1706, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1874 batch tensor(15.1475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1875 batch tensor(15.6233, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1876 batch tensor(20.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1877 batch tensor(16.0561, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1878 batch tensor(20.3852, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1879 batch tensor(16.7662, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1880 batch tensor(18.1102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1881 batch tensor(17.5444, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1882 batch tensor(17.4685, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1883 batch tensor(18.8705, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1884 batch tensor(15.9378, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1885 batch tensor(19.1610, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1886 batch tensor(16.0107, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1887 batch tensor(16.8293, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1888 batch tensor(16.6387, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1889 batch tensor(16.3838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1890 batch tensor(17.9020, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1891 batch tensor(18.7726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1892 batch tensor(16.0413, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1893 batch tensor(17.5510, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1894 batch tensor(17.4282, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1895 batch tensor(20.7106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1896 batch tensor(17.3980, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1897 batch tensor(17.2742, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1898 batch tensor(20.0033, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1899 batch tensor(20.6685, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1900 batch tensor(17.0611, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1901 batch tensor(15.0198, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1902 batch tensor(18.6458, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1903 batch tensor(15.4508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1904 batch tensor(18.4818, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1905 batch tensor(15.8100, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1906 batch tensor(17.9561, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1907 batch tensor(16.0762, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1908 batch tensor(17.4365, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1909 batch tensor(18.7575, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1910 batch tensor(16.1121, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1911 batch tensor(17.6667, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1912 batch tensor(16.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1913 batch tensor(17.9047, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1914 batch tensor(17.1427, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1915 batch tensor(18.6730, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1916 batch tensor(17.4736, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1917 batch tensor(18.8709, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1918 batch tensor(17.3232, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1919 batch tensor(15.7164, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1920 batch tensor(19.1203, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1921 batch tensor(17.2994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1922 batch tensor(18.0889, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1923 batch tensor(17.7066, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1924 batch tensor(16.2497, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1925 batch tensor(17.2512, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1926 batch tensor(15.6959, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1927 batch tensor(15.9696, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1928 batch tensor(19.1179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1929 batch tensor(16.0468, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1930 batch tensor(16.1986, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1931 batch tensor(16.7054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1932 batch tensor(16.9309, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1933 batch tensor(18.1767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1934 batch tensor(16.6170, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1935 batch tensor(14.1871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1936 batch tensor(16.9140, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1937 batch tensor(17.2902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1938 batch tensor(15.2405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1939 batch tensor(17.8394, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1940 batch tensor(13.6675, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1941 batch tensor(18.9545, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1942 batch tensor(16.4958, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1943 batch tensor(17.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1944 batch tensor(19.2027, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1945 batch tensor(14.6377, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1946 batch tensor(17.2869, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1947 batch tensor(17.9997, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1948 batch tensor(17.3907, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1949 batch tensor(16.6219, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1950 batch tensor(17.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "1951 batch tensor(18.2909, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1952 batch tensor(16.0932, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1953 batch tensor(17.9731, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1954 batch tensor(15.4949, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1955 batch tensor(17.7057, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1956 batch tensor(19.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1957 batch tensor(14.3076, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1958 batch tensor(16.4832, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1959 batch tensor(16.2335, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1960 batch tensor(16.2819, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1961 batch tensor(17.5818, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1962 batch tensor(17.4166, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1963 batch tensor(17.4110, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1964 batch tensor(17.9269, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1965 batch tensor(16.5711, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1966 batch tensor(15.1604, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1967 batch tensor(14.8891, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1968 batch tensor(16.4645, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1969 batch tensor(16.5521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1970 batch tensor(15.9372, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1971 batch tensor(15.6472, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1972 batch tensor(17.0744, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1973 batch tensor(16.6715, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1974 batch tensor(20.1031, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1975 batch tensor(18.1476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1976 batch tensor(15.6192, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1977 batch tensor(17.4419, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1978 batch tensor(18.8897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1979 batch tensor(17.5226, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1980 batch tensor(17.1604, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1981 batch tensor(16.0314, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1982 batch tensor(16.9853, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1983 batch tensor(15.9175, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1984 batch tensor(19.4640, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1985 batch tensor(18.2511, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1986 batch tensor(16.7016, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1987 batch tensor(18.4823, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1988 batch tensor(15.6721, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1989 batch tensor(16.7662, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1990 batch tensor(16.7114, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1991 batch tensor(16.5004, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1992 batch tensor(18.4197, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1993 batch tensor(16.2155, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1994 batch tensor(17.5388, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1995 batch tensor(14.2148, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1996 batch tensor(15.8457, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1997 batch tensor(18.6952, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1998 batch tensor(17.8741, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1999 batch tensor(17.5026, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2000 batch tensor(18.8753, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2001 batch tensor(16.4757, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2002 batch tensor(14.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2003 batch tensor(17.4229, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2004 batch tensor(17.6593, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2005 batch tensor(19.2036, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2006 batch tensor(16.4709, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2007 batch tensor(18.7449, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2008 batch tensor(14.6162, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2009 batch tensor(15.7189, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2010 batch tensor(16.7240, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2011 batch tensor(19.2770, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2012 batch tensor(17.4612, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2013 batch tensor(19.3702, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2014 batch tensor(15.2048, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2015 batch tensor(17.8366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2016 batch tensor(18.7201, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2017 batch tensor(16.5492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2018 batch tensor(17.3552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2019 batch tensor(16.6001, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2020 batch tensor(18.7998, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2021 batch tensor(15.8254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2022 batch tensor(17.8075, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2023 batch tensor(18.1690, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2024 batch tensor(16.1184, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2025 batch tensor(18.2180, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2026 batch tensor(16.2434, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2027 batch tensor(20.8497, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2028 batch tensor(14.9204, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2029 batch tensor(17.5633, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2030 batch tensor(16.6575, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2031 batch tensor(18.2029, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2032 batch tensor(17.8096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2033 batch tensor(16.6464, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2034 batch tensor(16.0911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2035 batch tensor(16.0637, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2036 batch tensor(16.0357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2037 batch tensor(19.3431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2038 batch tensor(17.2074, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2039 batch tensor(16.7702, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2040 batch tensor(19.0929, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2041 batch tensor(14.2680, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2042 batch tensor(17.1244, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2043 batch tensor(15.4313, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2044 batch tensor(15.3345, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2045 batch tensor(18.7931, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2046 batch tensor(16.0791, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2047 batch tensor(16.7687, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2048 batch tensor(18.2141, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2049 batch tensor(14.6078, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2050 batch tensor(16.7424, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2051 batch tensor(17.1843, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2052 batch tensor(17.0905, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2053 batch tensor(15.7063, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2054 batch tensor(20.8694, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2055 batch tensor(15.8159, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2056 batch tensor(17.3362, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2057 batch tensor(15.6866, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2058 batch tensor(17.4032, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2059 batch tensor(17.8814, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2060 batch tensor(16.8152, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2061 batch tensor(17.0852, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2062 batch tensor(17.4054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2063 batch tensor(18.3066, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2064 batch tensor(19.3211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2065 batch tensor(15.6234, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2066 batch tensor(17.4554, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2067 batch tensor(17.1147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2068 batch tensor(18.6904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2069 batch tensor(18.0210, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2070 batch tensor(17.3452, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2071 batch tensor(18.5127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2072 batch tensor(17.5411, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2073 batch tensor(16.2703, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2074 batch tensor(17.3692, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2075 batch tensor(20.3534, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2076 batch tensor(20.3482, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2077 batch tensor(15.3677, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2078 batch tensor(18.0162, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2079 batch tensor(18.0310, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2080 batch tensor(19.6434, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2081 batch tensor(18.4039, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2082 batch tensor(15.5480, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2083 batch tensor(19.7391, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2084 batch tensor(19.2504, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2085 batch tensor(15.0350, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2086 batch tensor(16.1881, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2087 batch tensor(19.0219, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2088 batch tensor(18.7984, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2089 batch tensor(19.3450, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2090 batch tensor(18.0374, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2091 batch tensor(15.2892, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2092 batch tensor(17.6541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2093 batch tensor(17.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2094 batch tensor(16.5001, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2095 batch tensor(16.5449, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2096 batch tensor(20.3107, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2097 batch tensor(17.2962, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2098 batch tensor(17.4911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2099 batch tensor(18.1546, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2100 batch tensor(17.1989, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2101 batch tensor(16.7784, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2102 batch tensor(15.0449, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2103 batch tensor(15.1920, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2104 batch tensor(18.3902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2105 batch tensor(16.8309, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2106 batch tensor(17.9600, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2107 batch tensor(16.9672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2108 batch tensor(21.8620, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2109 batch tensor(15.2102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2110 batch tensor(16.9475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2111 batch tensor(15.8375, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2112 batch tensor(16.2607, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2113 batch tensor(19.8144, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2114 batch tensor(16.3780, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2115 batch tensor(16.7009, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2116 batch tensor(18.7591, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2117 batch tensor(15.8446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2118 batch tensor(17.9934, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2119 batch tensor(18.8068, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2120 batch tensor(16.1604, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2121 batch tensor(18.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2122 batch tensor(19.6566, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2123 batch tensor(20.7127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2124 batch tensor(16.4054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2125 batch tensor(17.2068, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2126 batch tensor(17.3189, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2127 batch tensor(16.7843, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2128 batch tensor(14.7529, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2129 batch tensor(14.6773, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2130 batch tensor(17.2226, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2131 batch tensor(17.6723, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2132 batch tensor(16.9501, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2133 batch tensor(16.5430, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2134 batch tensor(16.3647, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2135 batch tensor(19.9127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2136 batch tensor(16.6438, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2137 batch tensor(16.9176, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2138 batch tensor(15.7239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2139 batch tensor(21.3366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2140 batch tensor(21.3580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2141 batch tensor(16.6579, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2142 batch tensor(16.4607, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2143 batch tensor(17.9870, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2144 batch tensor(16.4302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2145 batch tensor(17.7115, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2146 batch tensor(18.1960, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2147 batch tensor(20.5854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2148 batch tensor(18.5281, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2149 batch tensor(15.1175, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2150 batch tensor(16.5402, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2151 batch tensor(15.3476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2152 batch tensor(16.3542, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2153 batch tensor(17.6381, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2154 batch tensor(16.3618, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2155 batch tensor(14.5184, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2156 batch tensor(18.5650, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2157 batch tensor(16.8912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2158 batch tensor(21.0251, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2159 batch tensor(18.8070, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2160 batch tensor(17.4558, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2161 batch tensor(16.8090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2162 batch tensor(18.4459, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2163 batch tensor(16.6975, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2164 batch tensor(16.2906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2165 batch tensor(15.8985, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2166 batch tensor(16.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2167 batch tensor(19.3005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2168 batch tensor(16.6594, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2169 batch tensor(16.9661, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2170 batch tensor(16.8442, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2171 batch tensor(18.5183, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2172 batch tensor(15.8433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2173 batch tensor(17.3064, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2174 batch tensor(18.5817, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2175 batch tensor(16.9085, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2176 batch tensor(16.0962, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2177 batch tensor(16.5648, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2178 batch tensor(18.4027, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2179 batch tensor(16.4857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2180 batch tensor(14.7322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2181 batch tensor(16.5500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2182 batch tensor(16.6779, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2183 batch tensor(15.7075, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2184 batch tensor(15.1800, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2185 batch tensor(17.9929, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2186 batch tensor(17.3797, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2187 batch tensor(14.9254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2188 batch tensor(15.8259, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2189 batch tensor(15.7254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2190 batch tensor(16.6787, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2191 batch tensor(20.9106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2192 batch tensor(20.5968, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2193 batch tensor(18.2845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2194 batch tensor(17.9827, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2195 batch tensor(17.1316, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2196 batch tensor(32.3207, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2197 batch tensor(18.4038, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2198 batch tensor(19.2033, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2199 batch tensor(19.4024, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2200 batch tensor(16.6242, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2201 batch tensor(15.6095, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2202 batch tensor(18.8005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2203 batch tensor(16.4745, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2204 batch tensor(15.9073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2205 batch tensor(16.1174, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2206 batch tensor(17.5409, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2207 batch tensor(17.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2208 batch tensor(15.0041, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2209 batch tensor(16.2472, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2210 batch tensor(16.1559, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2211 batch tensor(17.7455, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2212 batch tensor(17.4205, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2213 batch tensor(16.5960, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2214 batch tensor(14.6785, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2215 batch tensor(16.1598, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2216 batch tensor(19.8285, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2217 batch tensor(13.9650, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2218 batch tensor(17.2979, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2219 batch tensor(19.1957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2220 batch tensor(17.7912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2221 batch tensor(17.0281, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2222 batch tensor(18.3993, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2223 batch tensor(17.2517, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2224 batch tensor(16.7861, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2225 batch tensor(14.6952, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2226 batch tensor(18.1943, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2227 batch tensor(14.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2228 batch tensor(16.0697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2229 batch tensor(16.7429, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2230 batch tensor(15.8381, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2231 batch tensor(17.6882, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2232 batch tensor(18.1476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2233 batch tensor(18.0345, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2234 batch tensor(18.0829, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2235 batch tensor(20.4122, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2236 batch tensor(16.3587, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2237 batch tensor(15.0242, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2238 batch tensor(15.0044, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2239 batch tensor(19.1790, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2240 batch tensor(18.9773, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2241 batch tensor(15.5748, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2242 batch tensor(16.8504, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2243 batch tensor(15.4194, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2244 batch tensor(19.5855, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2245 batch tensor(17.4399, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2246 batch tensor(17.1990, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2247 batch tensor(16.0259, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2248 batch tensor(19.6834, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2249 batch tensor(20.2555, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2250 batch tensor(16.3541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2251 batch tensor(18.3230, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2252 batch tensor(15.5616, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2253 batch tensor(16.6114, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2254 batch tensor(16.3005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2255 batch tensor(17.2122, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2256 batch tensor(16.4996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2257 batch tensor(16.2995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2258 batch tensor(16.5431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2259 batch tensor(16.0065, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2260 batch tensor(18.0355, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2261 batch tensor(14.6229, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2262 batch tensor(18.1841, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2263 batch tensor(17.3299, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2264 batch tensor(19.5511, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2265 batch tensor(20.2394, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2266 batch tensor(16.6028, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2267 batch tensor(15.8720, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2268 batch tensor(17.4243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2269 batch tensor(16.4757, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2270 batch tensor(18.7212, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2271 batch tensor(18.6462, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2272 batch tensor(16.9897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2273 batch tensor(20.5820, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2274 batch tensor(18.4516, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2275 batch tensor(16.3275, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2276 batch tensor(13.8616, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2277 batch tensor(17.0959, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2278 batch tensor(18.1236, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2279 batch tensor(16.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2280 batch tensor(17.3102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2281 batch tensor(16.3768, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2282 batch tensor(17.9664, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2283 batch tensor(17.3168, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2284 batch tensor(16.4462, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2285 batch tensor(16.5096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2286 batch tensor(16.3191, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2287 batch tensor(16.7173, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2288 batch tensor(14.9304, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2289 batch tensor(22.5334, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2290 batch tensor(15.6856, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2291 batch tensor(18.8547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2292 batch tensor(17.0923, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2293 batch tensor(20.5283, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2294 batch tensor(18.3567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2295 batch tensor(16.4008, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2296 batch tensor(21.1889, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2297 batch tensor(16.4264, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2298 batch tensor(17.9272, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2299 batch tensor(18.1637, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2300 batch tensor(17.2985, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2301 batch tensor(16.8897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2302 batch tensor(18.4030, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2303 batch tensor(15.9442, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2304 batch tensor(16.9227, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2305 batch tensor(16.9974, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2306 batch tensor(15.0782, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2307 batch tensor(17.4173, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2308 batch tensor(15.9987, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2309 batch tensor(17.7387, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2310 batch tensor(17.7353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2311 batch tensor(15.9789, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2312 batch tensor(19.0932, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2313 batch tensor(14.8577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2314 batch tensor(17.8947, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2315 batch tensor(20.2248, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2316 batch tensor(17.3560, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2317 batch tensor(19.9723, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2318 batch tensor(15.8384, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2319 batch tensor(15.3937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2320 batch tensor(18.7140, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2321 batch tensor(16.9647, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2322 batch tensor(16.7443, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2323 batch tensor(16.9442, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2324 batch tensor(14.9369, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2325 batch tensor(16.4218, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2326 batch tensor(15.4242, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2327 batch tensor(17.2037, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2328 batch tensor(18.4440, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2329 batch tensor(23.0344, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2330 batch tensor(17.3886, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2331 batch tensor(17.7750, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2332 batch tensor(16.2740, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2333 batch tensor(19.1264, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2334 batch tensor(18.7186, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2335 batch tensor(16.0734, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2336 batch tensor(20.5679, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2337 batch tensor(18.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2338 batch tensor(18.1154, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2339 batch tensor(15.1698, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2340 batch tensor(17.4510, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2341 batch tensor(19.0085, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2342 batch tensor(18.8504, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2343 batch tensor(17.9192, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2344 batch tensor(17.4466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2345 batch tensor(18.4221, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2346 batch tensor(16.8872, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2347 batch tensor(18.2492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2348 batch tensor(21.5692, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2349 batch tensor(19.3810, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2350 batch tensor(16.3904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2351 batch tensor(20.3913, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2352 batch tensor(14.4677, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2353 batch tensor(15.1951, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2354 batch tensor(19.5024, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2355 batch tensor(17.4589, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2356 batch tensor(15.0292, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2357 batch tensor(14.5337, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2358 batch tensor(18.1775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2359 batch tensor(19.8341, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2360 batch tensor(15.3697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2361 batch tensor(14.8782, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2362 batch tensor(15.5697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2363 batch tensor(18.3503, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2364 batch tensor(15.4226, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2365 batch tensor(16.2762, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2366 batch tensor(16.4874, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2367 batch tensor(16.6339, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2368 batch tensor(17.2858, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2369 batch tensor(18.6788, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2370 batch tensor(17.0429, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2371 batch tensor(15.0506, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2372 batch tensor(17.8071, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2373 batch tensor(16.0399, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2374 batch tensor(18.8963, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2375 batch tensor(16.5606, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2376 batch tensor(16.6818, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2377 batch tensor(17.3327, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2378 batch tensor(14.4954, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2379 batch tensor(16.8324, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2380 batch tensor(15.5183, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2381 batch tensor(15.8718, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2382 batch tensor(16.8755, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2383 batch tensor(17.8366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2384 batch tensor(17.5684, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2385 batch tensor(17.9716, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2386 batch tensor(15.8781, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2387 batch tensor(15.7802, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2388 batch tensor(17.0482, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2389 batch tensor(18.3429, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2390 batch tensor(16.2382, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2391 batch tensor(16.1994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2392 batch tensor(18.1867, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2393 batch tensor(18.5258, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2394 batch tensor(18.2731, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2395 batch tensor(18.3716, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2396 batch tensor(16.0763, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2397 batch tensor(13.7009, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2398 batch tensor(22.6560, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2399 batch tensor(15.1219, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2400 batch tensor(16.3080, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2401 batch tensor(15.6571, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2402 batch tensor(16.1822, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2403 batch tensor(17.3853, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2404 batch tensor(16.8833, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2405 batch tensor(16.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2406 batch tensor(20.1903, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2407 batch tensor(16.8646, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2408 batch tensor(15.2569, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2409 batch tensor(18.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2410 batch tensor(18.6527, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2411 batch tensor(16.9057, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2412 batch tensor(18.0121, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2413 batch tensor(19.2387, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2414 batch tensor(17.3060, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2415 batch tensor(20.1282, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2416 batch tensor(17.0563, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2417 batch tensor(17.8707, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2418 batch tensor(16.0172, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2419 batch tensor(18.4291, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2420 batch tensor(16.8585, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2421 batch tensor(17.7622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2422 batch tensor(16.0650, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2423 batch tensor(16.9119, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2424 batch tensor(17.9183, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2425 batch tensor(19.4857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2426 batch tensor(17.4356, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2427 batch tensor(16.6901, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2428 batch tensor(15.1631, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2429 batch tensor(16.7948, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2430 batch tensor(15.3287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2431 batch tensor(18.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2432 batch tensor(16.3065, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2433 batch tensor(15.0759, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2434 batch tensor(18.0441, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2435 batch tensor(17.2614, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2436 batch tensor(18.9225, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2437 batch tensor(16.5807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2438 batch tensor(18.3654, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2439 batch tensor(15.0597, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2440 batch tensor(20.6625, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2441 batch tensor(15.5455, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2442 batch tensor(17.7124, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2443 batch tensor(16.1510, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2444 batch tensor(17.7396, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2445 batch tensor(18.6643, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2446 batch tensor(18.1769, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2447 batch tensor(19.0540, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2448 batch tensor(18.5034, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2449 batch tensor(16.7480, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2450 batch tensor(16.3797, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2451 batch tensor(17.3683, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2452 batch tensor(16.7203, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2453 batch tensor(19.3421, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2454 batch tensor(14.4712, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2455 batch tensor(16.0993, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2456 batch tensor(17.4931, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2457 batch tensor(15.5551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2458 batch tensor(17.2391, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2459 batch tensor(15.2725, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2460 batch tensor(14.9840, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2461 batch tensor(17.0130, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2462 batch tensor(16.9024, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2463 batch tensor(15.7405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2464 batch tensor(16.5097, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2465 batch tensor(17.7046, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2466 batch tensor(17.8190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2467 batch tensor(15.9717, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2468 batch tensor(17.2507, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2469 batch tensor(17.6792, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2470 batch tensor(16.3243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2471 batch tensor(19.0638, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2472 batch tensor(17.0532, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2473 batch tensor(17.6388, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2474 batch tensor(15.8053, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2475 batch tensor(17.0645, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2476 batch tensor(16.5581, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2477 batch tensor(17.4584, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2478 batch tensor(15.1857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2479 batch tensor(19.1437, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2480 batch tensor(15.6905, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2481 batch tensor(19.7166, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2482 batch tensor(18.6063, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2483 batch tensor(17.0679, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2484 batch tensor(15.4264, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2485 batch tensor(17.7429, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2486 batch tensor(16.0471, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2487 batch tensor(13.2635, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2488 batch tensor(17.2795, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2489 batch tensor(14.0334, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2490 batch tensor(19.1564, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2491 batch tensor(18.7511, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2492 batch tensor(16.2066, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2493 batch tensor(16.7652, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2494 batch tensor(17.8727, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2495 batch tensor(16.1656, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2496 batch tensor(16.8030, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2497 batch tensor(16.7254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2498 batch tensor(18.8785, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2499 batch tensor(16.9954, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2500 batch tensor(16.6027, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2501 batch tensor(15.4808, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2502 batch tensor(16.3655, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2503 batch tensor(17.6824, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2504 batch tensor(18.0701, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2505 batch tensor(16.2341, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2506 batch tensor(18.9647, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2507 batch tensor(18.9382, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2508 batch tensor(17.4016, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2509 batch tensor(18.3587, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2510 batch tensor(17.1874, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2511 batch tensor(18.7405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2512 batch tensor(17.5281, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2513 batch tensor(17.2450, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2514 batch tensor(18.5115, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2515 batch tensor(18.3638, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2516 batch tensor(16.6997, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2517 batch tensor(17.3341, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2518 batch tensor(17.4013, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2519 batch tensor(17.7843, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2520 batch tensor(17.4288, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2521 batch tensor(16.5381, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2522 batch tensor(16.7807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2523 batch tensor(16.3697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2524 batch tensor(16.7607, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2525 batch tensor(15.2299, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2526 batch tensor(16.8379, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2527 batch tensor(17.7629, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2528 batch tensor(18.0187, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2529 batch tensor(17.3831, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2530 batch tensor(18.1993, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2531 batch tensor(15.3975, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2532 batch tensor(15.5174, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2533 batch tensor(17.8210, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2534 batch tensor(18.4035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2535 batch tensor(17.1026, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2536 batch tensor(16.5233, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2537 batch tensor(18.4505, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2538 batch tensor(16.9345, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2539 batch tensor(15.5297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2540 batch tensor(17.7382, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2541 batch tensor(16.1320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2542 batch tensor(18.6583, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2543 batch tensor(18.8307, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2544 batch tensor(16.8190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2545 batch tensor(16.4162, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2546 batch tensor(18.4895, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2547 batch tensor(18.0848, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2548 batch tensor(16.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2549 batch tensor(20.2143, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2550 batch tensor(17.9548, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2551 batch tensor(15.9104, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2552 batch tensor(18.8761, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2553 batch tensor(17.2125, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2554 batch tensor(17.8157, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2555 batch tensor(15.2987, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2556 batch tensor(19.0328, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2557 batch tensor(17.8452, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2558 batch tensor(18.0722, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2559 batch tensor(16.6237, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2560 batch tensor(17.2772, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2561 batch tensor(19.5163, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2562 batch tensor(16.7470, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2563 batch tensor(18.2194, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2564 batch tensor(15.7435, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2565 batch tensor(17.0168, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2566 batch tensor(17.7111, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2567 batch tensor(17.7466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2568 batch tensor(17.4686, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2569 batch tensor(18.3037, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2570 batch tensor(16.5347, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2571 batch tensor(16.9605, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2572 batch tensor(19.5737, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2573 batch tensor(15.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2574 batch tensor(15.7993, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2575 batch tensor(19.6049, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2576 batch tensor(17.1131, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2577 batch tensor(17.4231, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2578 batch tensor(17.2405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2579 batch tensor(17.1823, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2580 batch tensor(20.3515, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2581 batch tensor(15.4963, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2582 batch tensor(16.4279, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2583 batch tensor(15.1792, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2584 batch tensor(19.3970, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2585 batch tensor(17.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2586 batch tensor(17.7413, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2587 batch tensor(17.3404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2588 batch tensor(15.7907, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2589 batch tensor(16.5217, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2590 batch tensor(16.1920, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2591 batch tensor(15.7638, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2592 batch tensor(16.7009, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2593 batch tensor(17.3601, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2594 batch tensor(18.4028, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2595 batch tensor(19.3122, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2596 batch tensor(19.1001, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2597 batch tensor(15.5492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2598 batch tensor(14.0560, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2599 batch tensor(17.7815, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2600 batch tensor(17.2426, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2601 batch tensor(16.3994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2602 batch tensor(17.3171, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2603 batch tensor(18.2979, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2604 batch tensor(18.8924, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2605 batch tensor(18.2284, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2606 batch tensor(19.7935, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2607 batch tensor(18.1388, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2608 batch tensor(17.7861, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2609 batch tensor(19.6326, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2610 batch tensor(17.3357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2611 batch tensor(16.8181, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2612 batch tensor(16.9031, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2613 batch tensor(15.7563, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2614 batch tensor(16.0300, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2615 batch tensor(20.1144, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2616 batch tensor(16.1242, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2617 batch tensor(20.1653, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2618 batch tensor(14.9683, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2619 batch tensor(17.3039, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2620 batch tensor(18.1777, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2621 batch tensor(18.1904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2622 batch tensor(15.8496, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2623 batch tensor(17.1365, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2624 batch tensor(14.4949, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2625 batch tensor(17.9076, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2626 batch tensor(18.3842, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2627 batch tensor(15.8637, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2628 batch tensor(20.2476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2629 batch tensor(17.1940, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2630 batch tensor(16.3570, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2631 batch tensor(17.2994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2632 batch tensor(17.2680, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2633 batch tensor(20.3744, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2634 batch tensor(15.9501, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2635 batch tensor(17.1260, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2636 batch tensor(19.5090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2637 batch tensor(18.2067, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2638 batch tensor(17.5324, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2639 batch tensor(17.8893, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2640 batch tensor(18.2080, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2641 batch tensor(15.5235, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2642 batch tensor(15.6668, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2643 batch tensor(16.1244, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2644 batch tensor(19.9129, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2645 batch tensor(16.1514, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2646 batch tensor(15.8735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2647 batch tensor(16.2533, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2648 batch tensor(16.1187, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2649 batch tensor(19.9410, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2650 batch tensor(17.9112, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2651 batch tensor(18.3803, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2652 batch tensor(18.7517, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2653 batch tensor(13.8967, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2654 batch tensor(15.3971, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2655 batch tensor(17.5871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2656 batch tensor(17.6943, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2657 batch tensor(18.2604, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2658 batch tensor(19.1969, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2659 batch tensor(15.8237, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2660 batch tensor(16.1704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2661 batch tensor(17.8429, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2662 batch tensor(15.8311, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2663 batch tensor(18.2267, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2664 batch tensor(14.4669, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2665 batch tensor(14.2071, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2666 batch tensor(16.3012, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2667 batch tensor(20.3796, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2668 batch tensor(17.3702, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2669 batch tensor(18.5066, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2670 batch tensor(16.9103, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2671 batch tensor(16.8149, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2672 batch tensor(14.7775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2673 batch tensor(18.1592, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2674 batch tensor(16.5815, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2675 batch tensor(19.9770, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2676 batch tensor(14.6439, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2677 batch tensor(17.3421, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2678 batch tensor(16.1429, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2679 batch tensor(15.1015, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2680 batch tensor(14.7584, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2681 batch tensor(17.2148, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2682 batch tensor(19.8701, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2683 batch tensor(15.7595, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2684 batch tensor(16.7274, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2685 batch tensor(14.3302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2686 batch tensor(17.6944, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2687 batch tensor(17.9850, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2688 batch tensor(17.1558, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2689 batch tensor(18.8764, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2690 batch tensor(14.8091, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2691 batch tensor(15.6637, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2692 batch tensor(18.4935, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2693 batch tensor(17.6597, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2694 batch tensor(17.5189, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2695 batch tensor(17.0880, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2696 batch tensor(18.4789, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2697 batch tensor(15.4567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2698 batch tensor(15.0348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2699 batch tensor(14.9974, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2700 batch tensor(17.9333, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2701 batch tensor(17.4256, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2702 batch tensor(14.5735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2703 batch tensor(17.6639, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2704 batch tensor(16.6548, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2705 batch tensor(18.4417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2706 batch tensor(16.5067, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2707 batch tensor(18.6295, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2708 batch tensor(16.3849, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2709 batch tensor(16.6493, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2710 batch tensor(17.7917, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2711 batch tensor(18.8598, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2712 batch tensor(15.5673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2713 batch tensor(17.7833, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2714 batch tensor(15.3718, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2715 batch tensor(16.6286, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2716 batch tensor(17.7644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2717 batch tensor(19.9002, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2718 batch tensor(17.9511, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2719 batch tensor(14.4642, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2720 batch tensor(17.1428, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2721 batch tensor(17.7605, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2722 batch tensor(16.0557, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2723 batch tensor(16.4798, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2724 batch tensor(14.6502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2725 batch tensor(16.6654, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2726 batch tensor(18.4914, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2727 batch tensor(18.4054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2728 batch tensor(17.1559, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2729 batch tensor(17.4777, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2730 batch tensor(14.8141, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2731 batch tensor(16.0043, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2732 batch tensor(18.3957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2733 batch tensor(16.9025, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2734 batch tensor(15.8049, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2735 batch tensor(22.0681, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2736 batch tensor(18.0608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2737 batch tensor(18.6874, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2738 batch tensor(15.5129, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2739 batch tensor(15.9588, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2740 batch tensor(17.4975, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2741 batch tensor(15.1384, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2742 batch tensor(15.7610, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2743 batch tensor(16.0218, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2744 batch tensor(15.9952, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2745 batch tensor(18.5577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2746 batch tensor(16.6756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2747 batch tensor(16.8279, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2748 batch tensor(17.0314, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2749 batch tensor(20.5853, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2750 batch tensor(19.3960, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2751 batch tensor(16.2778, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2752 batch tensor(17.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2753 batch tensor(16.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2754 batch tensor(17.6400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2755 batch tensor(14.9668, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2756 batch tensor(15.7043, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2757 batch tensor(18.8721, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2758 batch tensor(18.9489, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2759 batch tensor(16.2296, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2760 batch tensor(16.6578, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2761 batch tensor(14.8415, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2762 batch tensor(14.6721, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2763 batch tensor(16.5460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2764 batch tensor(14.7632, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2765 batch tensor(15.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2766 batch tensor(16.3002, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2767 batch tensor(17.0006, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2768 batch tensor(16.0599, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2769 batch tensor(17.1428, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2770 batch tensor(15.0641, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2771 batch tensor(14.6620, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2772 batch tensor(18.4619, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2773 batch tensor(21.7397, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2774 batch tensor(17.9008, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2775 batch tensor(16.7982, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2776 batch tensor(17.3948, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2777 batch tensor(15.4131, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2778 batch tensor(18.3273, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2779 batch tensor(18.4693, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2780 batch tensor(17.7587, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2781 batch tensor(16.6335, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2782 batch tensor(17.5700, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2783 batch tensor(16.0377, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2784 batch tensor(16.7702, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2785 batch tensor(16.4324, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2786 batch tensor(19.1755, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2787 batch tensor(15.0636, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2788 batch tensor(16.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2789 batch tensor(18.5427, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2790 batch tensor(16.0683, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2791 batch tensor(15.8090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2792 batch tensor(17.2262, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2793 batch tensor(18.1008, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2794 batch tensor(19.4342, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2795 batch tensor(17.1745, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2796 batch tensor(17.0444, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2797 batch tensor(17.9127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2798 batch tensor(16.8641, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2799 batch tensor(19.0374, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2800 batch tensor(13.9367, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2801 batch tensor(17.0670, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2802 batch tensor(15.6372, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2803 batch tensor(16.8909, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2804 batch tensor(18.3801, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2805 batch tensor(19.7669, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2806 batch tensor(21.0177, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2807 batch tensor(17.8235, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2808 batch tensor(17.2089, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2809 batch tensor(19.4177, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2810 batch tensor(16.5028, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2811 batch tensor(15.2727, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2812 batch tensor(16.3109, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2813 batch tensor(17.2741, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2814 batch tensor(18.2453, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2815 batch tensor(15.6196, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2816 batch tensor(16.5202, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2817 batch tensor(15.9978, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2818 batch tensor(18.5714, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2819 batch tensor(19.0492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2820 batch tensor(16.2877, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2821 batch tensor(18.5252, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2822 batch tensor(17.5937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2823 batch tensor(16.5726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2824 batch tensor(17.3388, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2825 batch tensor(19.0477, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2826 batch tensor(17.6222, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2827 batch tensor(20.0263, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2828 batch tensor(16.6495, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2829 batch tensor(16.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2830 batch tensor(19.3111, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2831 batch tensor(18.5216, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2832 batch tensor(18.5840, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2833 batch tensor(17.9084, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2834 batch tensor(17.3095, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2835 batch tensor(17.4893, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2836 batch tensor(21.6696, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2837 batch tensor(17.2875, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2838 batch tensor(16.2320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2839 batch tensor(15.7478, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2840 batch tensor(19.1123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2841 batch tensor(17.6225, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2842 batch tensor(16.5462, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2843 batch tensor(18.2921, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2844 batch tensor(18.2215, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2845 batch tensor(16.4837, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2846 batch tensor(17.0548, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2847 batch tensor(18.7095, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2848 batch tensor(18.2113, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2849 batch tensor(19.5562, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2850 batch tensor(16.1531, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2851 batch tensor(21.7457, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2852 batch tensor(14.5418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2853 batch tensor(18.9447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2854 batch tensor(17.6240, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2855 batch tensor(17.4410, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2856 batch tensor(17.8046, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2857 batch tensor(16.4892, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2858 batch tensor(14.5838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2859 batch tensor(18.2131, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2860 batch tensor(16.2957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2861 batch tensor(16.8119, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2862 batch tensor(18.3792, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2863 batch tensor(15.1078, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2864 batch tensor(16.0739, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2865 batch tensor(16.8043, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2866 batch tensor(15.3576, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2867 batch tensor(17.8017, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2868 batch tensor(18.1051, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2869 batch tensor(16.2713, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2870 batch tensor(18.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2871 batch tensor(18.3519, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2872 batch tensor(16.7599, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2873 batch tensor(19.9830, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2874 batch tensor(18.6054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2875 batch tensor(14.2490, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2876 batch tensor(16.2160, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2877 batch tensor(18.6639, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2878 batch tensor(17.8329, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2879 batch tensor(15.9196, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2880 batch tensor(15.3329, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2881 batch tensor(16.0711, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2882 batch tensor(16.6123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2883 batch tensor(16.8507, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2884 batch tensor(18.6118, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2885 batch tensor(21.2187, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2886 batch tensor(18.0446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2887 batch tensor(13.8367, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2888 batch tensor(14.9861, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2889 batch tensor(15.8266, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2890 batch tensor(17.2551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2891 batch tensor(17.4712, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2892 batch tensor(15.8536, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2893 batch tensor(16.1377, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2894 batch tensor(19.8208, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2895 batch tensor(16.3218, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2896 batch tensor(21.7037, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2897 batch tensor(15.4357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2898 batch tensor(17.0702, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2899 batch tensor(15.4776, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2900 batch tensor(19.0173, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2901 batch tensor(16.4388, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2902 batch tensor(17.4737, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2903 batch tensor(14.9602, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2904 batch tensor(16.4271, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2905 batch tensor(14.7936, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2906 batch tensor(19.6537, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2907 batch tensor(19.9477, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2908 batch tensor(15.1190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2909 batch tensor(18.9011, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2910 batch tensor(16.5617, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2911 batch tensor(17.2536, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2912 batch tensor(19.7586, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2913 batch tensor(19.3830, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2914 batch tensor(17.1734, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2915 batch tensor(17.0278, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2916 batch tensor(16.6775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2917 batch tensor(19.6798, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2918 batch tensor(15.3278, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2919 batch tensor(17.6585, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2920 batch tensor(20.3950, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2921 batch tensor(17.2335, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2922 batch tensor(17.2687, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2923 batch tensor(16.3301, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2924 batch tensor(15.5133, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2925 batch tensor(17.6494, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2926 batch tensor(17.0067, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2927 batch tensor(16.3147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2928 batch tensor(15.2265, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2929 batch tensor(16.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2930 batch tensor(15.5973, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2931 batch tensor(17.9082, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2932 batch tensor(21.3845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2933 batch tensor(14.7080, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2934 batch tensor(14.9548, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2935 batch tensor(15.3882, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2936 batch tensor(16.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2937 batch tensor(13.9053, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2938 batch tensor(16.7855, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2939 batch tensor(17.6767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2940 batch tensor(16.0648, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2941 batch tensor(16.9599, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2942 batch tensor(18.2737, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2943 batch tensor(20.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2944 batch tensor(16.5997, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2945 batch tensor(22.7005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2946 batch tensor(18.1671, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2947 batch tensor(15.6966, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2948 batch tensor(21.3636, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2949 batch tensor(18.4761, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2950 batch tensor(15.5962, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "2951 batch tensor(16.0561, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2952 batch tensor(16.1245, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2953 batch tensor(18.7770, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2954 batch tensor(14.5371, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2955 batch tensor(16.0906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2956 batch tensor(18.2976, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2957 batch tensor(16.8821, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2958 batch tensor(16.4871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2959 batch tensor(16.3269, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2960 batch tensor(17.8136, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2961 batch tensor(16.4461, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2962 batch tensor(18.5975, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2963 batch tensor(17.2570, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2964 batch tensor(16.9218, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2965 batch tensor(18.4098, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2966 batch tensor(15.1440, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2967 batch tensor(18.4232, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2968 batch tensor(14.6698, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2969 batch tensor(14.8624, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2970 batch tensor(18.3210, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2971 batch tensor(14.2649, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2972 batch tensor(17.0870, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2973 batch tensor(18.8040, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2974 batch tensor(16.7634, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2975 batch tensor(18.4073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2976 batch tensor(18.7572, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2977 batch tensor(15.1995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2978 batch tensor(14.0223, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2979 batch tensor(17.3913, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2980 batch tensor(16.2286, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2981 batch tensor(17.2782, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2982 batch tensor(17.7463, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2983 batch tensor(16.7451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2984 batch tensor(17.1121, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2985 batch tensor(20.0109, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2986 batch tensor(15.9328, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2987 batch tensor(17.7824, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2988 batch tensor(16.6404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2989 batch tensor(16.6358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2990 batch tensor(19.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2991 batch tensor(16.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2992 batch tensor(20.5968, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2993 batch tensor(18.0628, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2994 batch tensor(17.4633, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2995 batch tensor(16.0681, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2996 batch tensor(18.8187, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2997 batch tensor(16.4287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2998 batch tensor(18.7257, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2999 batch tensor(16.3585, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3000 batch tensor(16.7391, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3001 batch tensor(18.0436, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3002 batch tensor(18.7077, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3003 batch tensor(18.5896, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3004 batch tensor(16.6130, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3005 batch tensor(17.0821, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3006 batch tensor(19.1299, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3007 batch tensor(19.1141, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3008 batch tensor(15.9423, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3009 batch tensor(18.3044, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3010 batch tensor(20.5218, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3011 batch tensor(16.3792, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3012 batch tensor(19.0486, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3013 batch tensor(15.3293, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3014 batch tensor(16.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3015 batch tensor(16.6606, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3016 batch tensor(15.1911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3017 batch tensor(17.2874, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3018 batch tensor(20.9193, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3019 batch tensor(19.7286, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3020 batch tensor(16.0608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3021 batch tensor(19.5026, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3022 batch tensor(16.7373, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3023 batch tensor(17.8271, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3024 batch tensor(16.8909, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3025 batch tensor(14.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3026 batch tensor(18.0716, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3027 batch tensor(18.9077, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3028 batch tensor(16.2931, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3029 batch tensor(16.7655, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3030 batch tensor(17.7627, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3031 batch tensor(18.4216, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3032 batch tensor(15.1674, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3033 batch tensor(16.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3034 batch tensor(18.7126, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3035 batch tensor(14.6621, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3036 batch tensor(16.0875, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3037 batch tensor(15.0543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3038 batch tensor(15.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3039 batch tensor(15.9583, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3040 batch tensor(14.9076, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3041 batch tensor(19.2107, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3042 batch tensor(19.7797, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3043 batch tensor(14.7696, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3044 batch tensor(17.6463, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3045 batch tensor(19.8290, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3046 batch tensor(17.9026, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3047 batch tensor(20.2999, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3048 batch tensor(17.1683, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3049 batch tensor(19.1407, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3050 batch tensor(17.8267, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3051 batch tensor(14.9496, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3052 batch tensor(17.1480, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3053 batch tensor(18.9556, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3054 batch tensor(15.8268, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3055 batch tensor(18.9535, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3056 batch tensor(17.1415, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3057 batch tensor(16.1747, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3058 batch tensor(17.5290, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3059 batch tensor(16.3349, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3060 batch tensor(17.1557, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3061 batch tensor(19.9161, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3062 batch tensor(18.8522, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3063 batch tensor(18.5622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3064 batch tensor(17.4037, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3065 batch tensor(16.6378, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3066 batch tensor(14.5554, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3067 batch tensor(14.5525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3068 batch tensor(16.5878, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3069 batch tensor(16.2560, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3070 batch tensor(16.1220, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3071 batch tensor(16.8695, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3072 batch tensor(17.0552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3073 batch tensor(16.7557, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3074 batch tensor(16.1695, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3075 batch tensor(18.0516, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3076 batch tensor(16.5006, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3077 batch tensor(14.9166, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3078 batch tensor(15.9077, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3079 batch tensor(19.1412, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3080 batch tensor(17.6612, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3081 batch tensor(18.6626, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3082 batch tensor(16.8070, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3083 batch tensor(14.2585, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3084 batch tensor(17.8567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3085 batch tensor(17.5239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3086 batch tensor(18.4697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3087 batch tensor(15.0175, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3088 batch tensor(17.6240, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3089 batch tensor(16.8838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3090 batch tensor(17.8084, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3091 batch tensor(16.0308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3092 batch tensor(16.3321, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3093 batch tensor(17.1599, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3094 batch tensor(15.8042, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3095 batch tensor(16.0778, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3096 batch tensor(17.0649, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3097 batch tensor(19.7475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3098 batch tensor(16.0596, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3099 batch tensor(15.2154, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3100 batch tensor(17.0099, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3101 batch tensor(16.5748, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3102 batch tensor(18.2547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3103 batch tensor(15.1117, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3104 batch tensor(16.9444, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3105 batch tensor(16.5355, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3106 batch tensor(17.2248, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3107 batch tensor(16.5146, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3108 batch tensor(19.0291, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3109 batch tensor(18.0926, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3110 batch tensor(18.5159, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3111 batch tensor(17.0661, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3112 batch tensor(16.2349, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3113 batch tensor(14.4948, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3114 batch tensor(18.4526, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3115 batch tensor(18.0644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3116 batch tensor(21.1979, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3117 batch tensor(17.1261, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3118 batch tensor(18.9086, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3119 batch tensor(15.7350, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3120 batch tensor(17.8101, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3121 batch tensor(19.8882, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3122 batch tensor(17.8239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3123 batch tensor(15.9159, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3124 batch tensor(17.3964, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3125 batch tensor(16.5834, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3126 batch tensor(17.4442, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3127 batch tensor(18.6853, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3128 batch tensor(17.4204, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3129 batch tensor(17.7538, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3130 batch tensor(17.7283, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3131 batch tensor(15.5421, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3132 batch tensor(20.9484, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3133 batch tensor(17.2394, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3134 batch tensor(17.8396, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3135 batch tensor(14.8876, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3136 batch tensor(18.4470, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3137 batch tensor(16.1423, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3138 batch tensor(20.0582, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3139 batch tensor(16.7254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3140 batch tensor(15.7565, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3141 batch tensor(16.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3142 batch tensor(15.1195, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3143 batch tensor(17.1140, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3144 batch tensor(14.5483, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3145 batch tensor(17.2680, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3146 batch tensor(17.8017, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3147 batch tensor(17.0578, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3148 batch tensor(13.9229, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3149 batch tensor(14.2373, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3150 batch tensor(12.7605, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3151 batch tensor(17.6856, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3152 batch tensor(17.7241, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3153 batch tensor(17.1288, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3154 batch tensor(20.8520, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3155 batch tensor(17.5353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3156 batch tensor(19.2124, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3157 batch tensor(15.7971, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3158 batch tensor(16.6802, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3159 batch tensor(17.6635, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3160 batch tensor(17.1697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3161 batch tensor(16.8704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3162 batch tensor(17.7000, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3163 batch tensor(20.1285, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3164 batch tensor(14.4774, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3165 batch tensor(19.4098, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3166 batch tensor(18.2238, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3167 batch tensor(21.2052, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3168 batch tensor(18.0404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3169 batch tensor(15.9408, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3170 batch tensor(18.1696, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3171 batch tensor(18.7077, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3172 batch tensor(18.0048, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3173 batch tensor(16.5746, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3174 batch tensor(16.3252, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3175 batch tensor(16.3412, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3176 batch tensor(18.1318, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3177 batch tensor(17.2139, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3178 batch tensor(19.5923, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3179 batch tensor(19.1586, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3180 batch tensor(17.0897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3181 batch tensor(15.4625, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3182 batch tensor(17.4497, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3183 batch tensor(17.3668, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3184 batch tensor(16.7253, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3185 batch tensor(21.9475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3186 batch tensor(17.7660, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3187 batch tensor(17.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3188 batch tensor(15.3335, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3189 batch tensor(13.4314, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3190 batch tensor(17.6884, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3191 batch tensor(17.6878, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3192 batch tensor(17.7792, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3193 batch tensor(17.1759, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3194 batch tensor(16.3114, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3195 batch tensor(14.3866, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3196 batch tensor(17.3894, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3197 batch tensor(15.4916, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3198 batch tensor(15.2926, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3199 batch tensor(18.1804, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3200 batch tensor(16.6138, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3201 batch tensor(16.3290, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3202 batch tensor(16.7390, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3203 batch tensor(19.0310, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3204 batch tensor(18.3695, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3205 batch tensor(17.1598, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3206 batch tensor(17.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3207 batch tensor(17.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3208 batch tensor(15.1401, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3209 batch tensor(20.5772, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3210 batch tensor(17.6467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3211 batch tensor(20.7451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3212 batch tensor(17.4568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3213 batch tensor(17.8987, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3214 batch tensor(16.7005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3215 batch tensor(16.5247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3216 batch tensor(16.8841, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3217 batch tensor(17.2096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3218 batch tensor(16.5722, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3219 batch tensor(15.9278, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3220 batch tensor(17.9128, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3221 batch tensor(14.7880, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3222 batch tensor(18.9732, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3223 batch tensor(20.0045, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3224 batch tensor(19.9804, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3225 batch tensor(19.3345, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3226 batch tensor(18.5066, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3227 batch tensor(18.6856, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3228 batch tensor(18.3874, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3229 batch tensor(15.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3230 batch tensor(15.9493, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3231 batch tensor(17.3250, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3232 batch tensor(15.3210, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3233 batch tensor(17.1399, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3234 batch tensor(17.1391, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3235 batch tensor(16.8893, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3236 batch tensor(16.3107, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3237 batch tensor(16.3760, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3238 batch tensor(19.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3239 batch tensor(18.3322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3240 batch tensor(18.1169, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3241 batch tensor(16.8264, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3242 batch tensor(21.3008, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3243 batch tensor(16.4054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3244 batch tensor(15.9476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3245 batch tensor(15.1919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3246 batch tensor(18.2394, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3247 batch tensor(14.7265, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3248 batch tensor(17.8338, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3249 batch tensor(16.7111, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3250 batch tensor(17.2955, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3251 batch tensor(17.5769, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3252 batch tensor(15.9524, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3253 batch tensor(14.6087, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3254 batch tensor(19.3977, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3255 batch tensor(17.9341, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3256 batch tensor(16.1745, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3257 batch tensor(18.7292, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3258 batch tensor(18.0505, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3259 batch tensor(15.7404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3260 batch tensor(16.2914, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3261 batch tensor(17.6225, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3262 batch tensor(21.4140, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3263 batch tensor(16.9956, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3264 batch tensor(14.5370, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3265 batch tensor(18.4990, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3266 batch tensor(16.2640, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3267 batch tensor(17.6661, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3268 batch tensor(14.1438, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3269 batch tensor(17.5710, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3270 batch tensor(17.1287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3271 batch tensor(16.4900, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3272 batch tensor(16.5531, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3273 batch tensor(16.5486, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3274 batch tensor(16.9031, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3275 batch tensor(18.1317, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3276 batch tensor(16.4097, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3277 batch tensor(14.6529, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3278 batch tensor(16.7659, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3279 batch tensor(19.3539, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3280 batch tensor(17.8785, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3281 batch tensor(17.4311, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3282 batch tensor(16.9542, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3283 batch tensor(17.1672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3284 batch tensor(17.3147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3285 batch tensor(16.2302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3286 batch tensor(17.0787, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3287 batch tensor(19.0252, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3288 batch tensor(18.7172, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3289 batch tensor(17.3437, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3290 batch tensor(18.0687, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3291 batch tensor(16.6180, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3292 batch tensor(16.7135, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3293 batch tensor(18.7486, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3294 batch tensor(17.9238, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3295 batch tensor(17.7187, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3296 batch tensor(20.1178, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3297 batch tensor(16.4106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3298 batch tensor(18.5489, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3299 batch tensor(18.3330, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3300 batch tensor(19.1218, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3301 batch tensor(16.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3302 batch tensor(17.4006, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3303 batch tensor(19.0327, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3304 batch tensor(14.0915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3305 batch tensor(15.4302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3306 batch tensor(17.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3307 batch tensor(17.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3308 batch tensor(15.5828, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3309 batch tensor(18.1828, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3310 batch tensor(15.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3311 batch tensor(17.8620, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3312 batch tensor(16.9094, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3313 batch tensor(20.0911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3314 batch tensor(15.4476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3315 batch tensor(15.6785, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3316 batch tensor(16.6808, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3317 batch tensor(17.5652, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3318 batch tensor(16.8849, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3319 batch tensor(15.1816, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3320 batch tensor(17.2155, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3321 batch tensor(19.2036, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3322 batch tensor(16.0334, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3323 batch tensor(17.4142, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3324 batch tensor(16.7187, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3325 batch tensor(17.9608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3326 batch tensor(18.6197, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3327 batch tensor(18.3841, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3328 batch tensor(18.4839, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3329 batch tensor(17.6251, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3330 batch tensor(18.4684, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3331 batch tensor(18.8358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3332 batch tensor(17.9205, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3333 batch tensor(17.7900, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3334 batch tensor(19.6659, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3335 batch tensor(16.1741, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3336 batch tensor(17.4224, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3337 batch tensor(16.5058, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3338 batch tensor(15.9987, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3339 batch tensor(15.5503, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3340 batch tensor(15.9823, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3341 batch tensor(17.8166, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3342 batch tensor(17.6550, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3343 batch tensor(19.7273, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3344 batch tensor(16.5622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3345 batch tensor(18.1454, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3346 batch tensor(18.7633, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3347 batch tensor(16.3152, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3348 batch tensor(18.2203, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3349 batch tensor(15.2753, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3350 batch tensor(18.0633, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3351 batch tensor(15.8243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3352 batch tensor(15.1664, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3353 batch tensor(18.4908, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3354 batch tensor(16.3136, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3355 batch tensor(14.0425, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3356 batch tensor(14.6895, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3357 batch tensor(17.9199, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3358 batch tensor(16.1382, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3359 batch tensor(14.4105, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3360 batch tensor(16.7472, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3361 batch tensor(16.2999, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3362 batch tensor(15.0603, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3363 batch tensor(19.9381, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3364 batch tensor(16.8249, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3365 batch tensor(17.7860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3366 batch tensor(17.1846, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3367 batch tensor(18.2334, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3368 batch tensor(16.2146, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3369 batch tensor(18.1334, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3370 batch tensor(18.1834, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3371 batch tensor(16.5443, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3372 batch tensor(16.3586, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3373 batch tensor(17.8561, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3374 batch tensor(15.5319, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3375 batch tensor(18.5939, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3376 batch tensor(14.2297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3377 batch tensor(18.4128, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3378 batch tensor(19.0611, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3379 batch tensor(16.9631, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3380 batch tensor(17.5003, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3381 batch tensor(17.9256, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3382 batch tensor(16.6220, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3383 batch tensor(17.6790, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3384 batch tensor(16.7186, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3385 batch tensor(17.3283, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3386 batch tensor(15.5939, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3387 batch tensor(17.5734, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3388 batch tensor(18.5767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3389 batch tensor(18.9663, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3390 batch tensor(16.2629, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3391 batch tensor(15.8186, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3392 batch tensor(16.0596, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3393 batch tensor(19.6938, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3394 batch tensor(15.9221, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3395 batch tensor(16.0398, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3396 batch tensor(17.5139, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3397 batch tensor(17.1713, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3398 batch tensor(18.0720, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3399 batch tensor(14.4691, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3400 batch tensor(17.4729, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3401 batch tensor(16.8576, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3402 batch tensor(16.9465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3403 batch tensor(14.5657, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3404 batch tensor(17.0766, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3405 batch tensor(17.7030, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3406 batch tensor(17.1236, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3407 batch tensor(15.9119, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3408 batch tensor(17.5081, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3409 batch tensor(15.4546, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3410 batch tensor(17.3996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3411 batch tensor(20.3723, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3412 batch tensor(17.9691, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3413 batch tensor(17.6129, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3414 batch tensor(17.4313, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3415 batch tensor(18.1063, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3416 batch tensor(16.2927, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3417 batch tensor(17.3614, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3418 batch tensor(20.2050, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3419 batch tensor(17.2418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3420 batch tensor(17.9314, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3421 batch tensor(16.9268, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3422 batch tensor(15.6248, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3423 batch tensor(22.5478, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3424 batch tensor(16.4317, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3425 batch tensor(15.6387, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3426 batch tensor(19.1688, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3427 batch tensor(17.5082, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3428 batch tensor(17.2906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3429 batch tensor(15.7318, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3430 batch tensor(17.8876, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3431 batch tensor(15.1223, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3432 batch tensor(20.1092, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3433 batch tensor(19.0277, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3434 batch tensor(16.5263, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3435 batch tensor(16.6441, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3436 batch tensor(15.2624, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3437 batch tensor(17.1773, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3438 batch tensor(17.9418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3439 batch tensor(17.5214, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3440 batch tensor(20.2444, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3441 batch tensor(15.8835, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3442 batch tensor(14.8726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3443 batch tensor(17.7190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3444 batch tensor(17.9256, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3445 batch tensor(19.0867, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3446 batch tensor(20.0541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3447 batch tensor(17.8866, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3448 batch tensor(17.7086, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3449 batch tensor(16.2878, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3450 batch tensor(18.8563, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3451 batch tensor(15.9034, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3452 batch tensor(17.3183, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3453 batch tensor(18.3527, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3454 batch tensor(16.5077, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3455 batch tensor(17.8545, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3456 batch tensor(17.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3457 batch tensor(21.3796, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3458 batch tensor(17.2008, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3459 batch tensor(18.8662, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3460 batch tensor(16.5882, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3461 batch tensor(21.1350, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3462 batch tensor(20.1082, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3463 batch tensor(18.0608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3464 batch tensor(16.4434, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3465 batch tensor(15.8181, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3466 batch tensor(17.8020, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3467 batch tensor(16.5014, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3468 batch tensor(16.5407, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3469 batch tensor(17.9244, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3470 batch tensor(20.1825, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3471 batch tensor(16.8322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3472 batch tensor(18.5031, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3473 batch tensor(17.9413, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3474 batch tensor(19.8856, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3475 batch tensor(18.4233, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3476 batch tensor(17.2971, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3477 batch tensor(16.8522, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3478 batch tensor(16.2928, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3479 batch tensor(18.7056, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3480 batch tensor(17.2222, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3481 batch tensor(16.1762, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3482 batch tensor(16.6725, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3483 batch tensor(18.9798, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3484 batch tensor(15.1338, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3485 batch tensor(16.0499, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3486 batch tensor(14.8446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3487 batch tensor(15.2860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3488 batch tensor(17.3182, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3489 batch tensor(14.8452, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3490 batch tensor(15.6111, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3491 batch tensor(16.2347, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3492 batch tensor(15.9113, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3493 batch tensor(15.9728, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3494 batch tensor(15.7465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3495 batch tensor(20.5563, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3496 batch tensor(17.0383, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3497 batch tensor(19.6869, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3498 batch tensor(16.6730, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3499 batch tensor(15.0040, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3500 batch tensor(16.0651, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3501 batch tensor(19.8217, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3502 batch tensor(19.3899, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3503 batch tensor(16.2782, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3504 batch tensor(15.7086, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3505 batch tensor(16.9604, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3506 batch tensor(16.9778, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3507 batch tensor(18.9701, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3508 batch tensor(16.3297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3509 batch tensor(18.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3510 batch tensor(17.6741, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3511 batch tensor(19.8406, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3512 batch tensor(17.9709, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3513 batch tensor(18.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3514 batch tensor(15.0816, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3515 batch tensor(18.3080, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3516 batch tensor(16.1859, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3517 batch tensor(18.0853, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3518 batch tensor(18.1024, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3519 batch tensor(16.8387, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3520 batch tensor(16.1912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3521 batch tensor(19.1179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3522 batch tensor(16.4611, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3523 batch tensor(16.9623, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3524 batch tensor(17.1041, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3525 batch tensor(18.1564, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3526 batch tensor(17.0242, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3527 batch tensor(19.9313, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3528 batch tensor(16.0725, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3529 batch tensor(17.2841, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3530 batch tensor(16.4663, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3531 batch tensor(17.3214, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3532 batch tensor(15.7402, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3533 batch tensor(15.3529, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3534 batch tensor(17.0819, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3535 batch tensor(17.4547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3536 batch tensor(19.8361, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3537 batch tensor(18.6095, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3538 batch tensor(16.6025, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3539 batch tensor(20.3868, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3540 batch tensor(15.6855, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3541 batch tensor(17.2759, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3542 batch tensor(16.3019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3543 batch tensor(16.2547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3544 batch tensor(14.8631, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3545 batch tensor(17.1655, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3546 batch tensor(16.8274, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3547 batch tensor(17.2309, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3548 batch tensor(14.7789, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3549 batch tensor(16.3747, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3550 batch tensor(15.5826, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3551 batch tensor(16.0466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3552 batch tensor(16.0358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3553 batch tensor(17.7523, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3554 batch tensor(19.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3555 batch tensor(19.7430, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3556 batch tensor(17.9215, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3557 batch tensor(17.0471, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3558 batch tensor(17.3405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3559 batch tensor(17.4274, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3560 batch tensor(21.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3561 batch tensor(16.4809, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3562 batch tensor(16.8380, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3563 batch tensor(15.2874, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3564 batch tensor(18.0253, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3565 batch tensor(19.1554, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3566 batch tensor(15.5864, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3567 batch tensor(16.4596, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3568 batch tensor(16.9733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3569 batch tensor(19.0152, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3570 batch tensor(16.6241, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3571 batch tensor(17.6198, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3572 batch tensor(17.0480, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3573 batch tensor(15.8261, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3574 batch tensor(16.2265, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3575 batch tensor(19.7682, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3576 batch tensor(17.5124, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3577 batch tensor(19.5112, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3578 batch tensor(14.2727, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3579 batch tensor(16.0347, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3580 batch tensor(16.9945, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3581 batch tensor(16.9670, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3582 batch tensor(18.0695, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3583 batch tensor(17.1000, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3584 batch tensor(16.8792, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3585 batch tensor(19.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3586 batch tensor(18.1600, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3587 batch tensor(17.4710, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3588 batch tensor(16.2177, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3589 batch tensor(17.6688, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3590 batch tensor(18.2521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3591 batch tensor(15.9653, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3592 batch tensor(15.4908, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3593 batch tensor(14.7362, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3594 batch tensor(20.7893, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3595 batch tensor(16.0934, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3596 batch tensor(19.0270, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3597 batch tensor(16.6333, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3598 batch tensor(14.5964, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3599 batch tensor(18.5159, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3600 batch tensor(15.7457, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3601 batch tensor(16.2348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3602 batch tensor(18.1530, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3603 batch tensor(17.7904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3604 batch tensor(16.4467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3605 batch tensor(17.1458, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3606 batch tensor(16.9856, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3607 batch tensor(16.4686, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3608 batch tensor(16.3675, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3609 batch tensor(21.4245, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3610 batch tensor(16.6086, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3611 batch tensor(18.6834, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3612 batch tensor(18.7638, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3613 batch tensor(18.8608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3614 batch tensor(15.7739, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3615 batch tensor(16.7002, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3616 batch tensor(16.8427, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3617 batch tensor(16.0170, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3618 batch tensor(15.7081, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3619 batch tensor(15.2220, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3620 batch tensor(17.0044, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3621 batch tensor(16.6572, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3622 batch tensor(16.3919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3623 batch tensor(17.9406, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3624 batch tensor(18.0770, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3625 batch tensor(18.1988, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3626 batch tensor(16.0462, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3627 batch tensor(18.7749, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3628 batch tensor(16.6097, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3629 batch tensor(15.4774, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3630 batch tensor(15.6740, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3631 batch tensor(16.7795, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3632 batch tensor(20.1994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3633 batch tensor(18.1383, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3634 batch tensor(17.5061, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3635 batch tensor(16.8323, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3636 batch tensor(19.7339, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3637 batch tensor(16.7940, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3638 batch tensor(16.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3639 batch tensor(18.5336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3640 batch tensor(16.3540, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3641 batch tensor(18.3296, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3642 batch tensor(20.2274, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3643 batch tensor(15.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3644 batch tensor(16.5707, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3645 batch tensor(18.8408, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3646 batch tensor(24.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3647 batch tensor(17.4504, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3648 batch tensor(14.9166, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3649 batch tensor(16.5995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3650 batch tensor(18.8189, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3651 batch tensor(18.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3652 batch tensor(15.7478, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3653 batch tensor(17.2365, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3654 batch tensor(15.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3655 batch tensor(16.1647, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3656 batch tensor(17.1564, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3657 batch tensor(16.6480, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3658 batch tensor(17.2568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3659 batch tensor(18.0106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3660 batch tensor(19.4623, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3661 batch tensor(16.2667, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3662 batch tensor(17.5085, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3663 batch tensor(16.7580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3664 batch tensor(16.4489, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3665 batch tensor(17.0466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3666 batch tensor(18.6832, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3667 batch tensor(16.8601, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3668 batch tensor(18.0293, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3669 batch tensor(17.7237, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3670 batch tensor(17.7332, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3671 batch tensor(15.3994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3672 batch tensor(19.1353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3673 batch tensor(17.9330, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3674 batch tensor(19.3115, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3675 batch tensor(16.5851, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3676 batch tensor(19.0317, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3677 batch tensor(16.0205, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3678 batch tensor(17.5252, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3679 batch tensor(16.9340, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3680 batch tensor(17.7171, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3681 batch tensor(15.8423, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3682 batch tensor(16.3725, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3683 batch tensor(14.5453, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3684 batch tensor(16.0183, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3685 batch tensor(16.4624, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3686 batch tensor(16.9186, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3687 batch tensor(16.3102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3688 batch tensor(17.6271, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3689 batch tensor(15.5017, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3690 batch tensor(16.9524, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3691 batch tensor(16.2542, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3692 batch tensor(16.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3693 batch tensor(16.2277, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3694 batch tensor(18.2971, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3695 batch tensor(15.6378, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3696 batch tensor(15.6031, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3697 batch tensor(19.2759, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3698 batch tensor(18.6378, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3699 batch tensor(18.6441, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3700 batch tensor(17.4696, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3701 batch tensor(17.0869, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3702 batch tensor(15.7711, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3703 batch tensor(16.3046, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3704 batch tensor(16.5349, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3705 batch tensor(17.7219, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3706 batch tensor(15.9342, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3707 batch tensor(18.1217, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3708 batch tensor(15.6060, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3709 batch tensor(15.9373, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3710 batch tensor(17.8852, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3711 batch tensor(18.1675, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3712 batch tensor(17.1893, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3713 batch tensor(17.4550, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3714 batch tensor(18.1228, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3715 batch tensor(15.5668, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3716 batch tensor(15.5481, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3717 batch tensor(17.1593, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3718 batch tensor(16.3907, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3719 batch tensor(15.2301, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3720 batch tensor(20.1481, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3721 batch tensor(17.8975, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3722 batch tensor(19.0568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3723 batch tensor(16.7004, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3724 batch tensor(17.5210, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3725 batch tensor(16.8844, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3726 batch tensor(15.9760, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3727 batch tensor(15.5238, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3728 batch tensor(17.9563, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3729 batch tensor(16.8347, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3730 batch tensor(16.2764, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3731 batch tensor(18.9393, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3732 batch tensor(16.2806, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3733 batch tensor(19.1920, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3734 batch tensor(17.8882, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3735 batch tensor(16.2146, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3736 batch tensor(16.9722, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3737 batch tensor(18.0289, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3738 batch tensor(16.1764, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3739 batch tensor(17.9396, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3740 batch tensor(16.9245, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3741 batch tensor(17.7118, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3742 batch tensor(19.0801, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3743 batch tensor(19.0164, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3744 batch tensor(17.3035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3745 batch tensor(17.8033, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3746 batch tensor(17.6608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3747 batch tensor(16.7346, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3748 batch tensor(16.6767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3749 batch tensor(18.8840, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3750 batch tensor(18.2939, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3751 batch tensor(16.7480, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3752 batch tensor(16.6697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3753 batch tensor(17.4352, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3754 batch tensor(18.4004, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3755 batch tensor(16.9242, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3756 batch tensor(18.1183, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3757 batch tensor(17.6740, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3758 batch tensor(15.1726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3759 batch tensor(17.2827, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3760 batch tensor(18.7791, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3761 batch tensor(16.4629, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3762 batch tensor(16.7030, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3763 batch tensor(17.9963, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3764 batch tensor(15.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3765 batch tensor(13.5741, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3766 batch tensor(18.6106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3767 batch tensor(17.3882, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3768 batch tensor(17.8895, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3769 batch tensor(16.1347, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3770 batch tensor(14.8822, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3771 batch tensor(15.1463, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3772 batch tensor(15.8958, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3773 batch tensor(16.1165, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3774 batch tensor(17.6485, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3775 batch tensor(17.8795, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3776 batch tensor(16.7243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3777 batch tensor(17.1467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3778 batch tensor(15.4513, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3779 batch tensor(18.6189, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3780 batch tensor(16.3018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3781 batch tensor(17.1388, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3782 batch tensor(15.1404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3783 batch tensor(12.2800, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3784 batch tensor(18.7005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3785 batch tensor(18.9370, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3786 batch tensor(15.2232, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3787 batch tensor(17.8196, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3788 batch tensor(17.7277, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3789 batch tensor(15.7651, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3790 batch tensor(16.6295, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3791 batch tensor(16.1904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3792 batch tensor(15.9734, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3793 batch tensor(17.4443, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3794 batch tensor(16.8525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3795 batch tensor(16.4083, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3796 batch tensor(17.8961, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3797 batch tensor(16.1237, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3798 batch tensor(16.1329, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3799 batch tensor(16.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3800 batch tensor(19.3328, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3801 batch tensor(18.1928, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3802 batch tensor(16.8735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3803 batch tensor(21.0635, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3804 batch tensor(16.1639, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3805 batch tensor(16.7202, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3806 batch tensor(16.8588, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3807 batch tensor(16.5167, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3808 batch tensor(14.9891, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3809 batch tensor(15.3460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3810 batch tensor(17.4600, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3811 batch tensor(15.7127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3812 batch tensor(17.5340, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3813 batch tensor(17.9001, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3814 batch tensor(18.0911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3815 batch tensor(18.2121, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3816 batch tensor(15.7932, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3817 batch tensor(17.2693, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3818 batch tensor(16.3248, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3819 batch tensor(15.4649, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3820 batch tensor(18.1008, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3821 batch tensor(17.2623, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3822 batch tensor(15.9909, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3823 batch tensor(15.7519, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3824 batch tensor(18.5796, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3825 batch tensor(18.8179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3826 batch tensor(18.2924, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3827 batch tensor(16.0645, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3828 batch tensor(18.4780, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3829 batch tensor(17.4424, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3830 batch tensor(16.2331, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3831 batch tensor(17.3056, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3832 batch tensor(17.8525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3833 batch tensor(18.0790, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3834 batch tensor(16.5167, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3835 batch tensor(13.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3836 batch tensor(15.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3837 batch tensor(17.0918, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3838 batch tensor(16.7786, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3839 batch tensor(20.8423, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3840 batch tensor(15.4809, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3841 batch tensor(18.0815, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3842 batch tensor(16.8652, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3843 batch tensor(16.2959, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3844 batch tensor(16.0307, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3845 batch tensor(14.6929, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3846 batch tensor(14.7833, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3847 batch tensor(16.3993, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3848 batch tensor(16.6302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3849 batch tensor(15.1366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3850 batch tensor(16.6423, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3851 batch tensor(16.0775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3852 batch tensor(16.1168, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3853 batch tensor(16.5577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3854 batch tensor(16.6088, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3855 batch tensor(17.6952, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3856 batch tensor(16.8409, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3857 batch tensor(14.0808, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3858 batch tensor(16.8787, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3859 batch tensor(14.3460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3860 batch tensor(15.5066, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3861 batch tensor(15.5192, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3862 batch tensor(17.4014, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3863 batch tensor(18.4456, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3864 batch tensor(16.6940, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3865 batch tensor(16.6305, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3866 batch tensor(16.5069, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3867 batch tensor(19.2848, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3868 batch tensor(15.4649, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3869 batch tensor(16.4328, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3870 batch tensor(18.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3871 batch tensor(16.3297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3872 batch tensor(16.2886, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3873 batch tensor(16.0088, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3874 batch tensor(19.2382, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3875 batch tensor(17.2625, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3876 batch tensor(13.0844, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3877 batch tensor(16.6746, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3878 batch tensor(17.1967, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3879 batch tensor(14.1779, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3880 batch tensor(17.9767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3881 batch tensor(17.4145, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3882 batch tensor(15.2432, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3883 batch tensor(16.0678, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3884 batch tensor(17.2451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3885 batch tensor(16.5176, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3886 batch tensor(13.5097, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3887 batch tensor(17.9466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3888 batch tensor(15.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3889 batch tensor(17.8248, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3890 batch tensor(17.8547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3891 batch tensor(17.2502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3892 batch tensor(13.9565, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3893 batch tensor(16.3714, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3894 batch tensor(15.7945, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3895 batch tensor(18.0994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3896 batch tensor(19.4429, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3897 batch tensor(18.0673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3898 batch tensor(16.7082, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3899 batch tensor(16.9828, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3900 batch tensor(17.2450, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3901 batch tensor(17.0290, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3902 batch tensor(18.5829, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3903 batch tensor(15.7559, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3904 batch tensor(18.2971, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3905 batch tensor(19.3056, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3906 batch tensor(18.0692, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3907 batch tensor(16.5693, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3908 batch tensor(16.2065, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3909 batch tensor(18.9456, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3910 batch tensor(15.4809, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3911 batch tensor(16.8871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3912 batch tensor(17.3751, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3913 batch tensor(20.2858, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3914 batch tensor(17.9557, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3915 batch tensor(16.7689, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3916 batch tensor(17.3053, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3917 batch tensor(19.9082, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3918 batch tensor(16.7308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3919 batch tensor(17.4064, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3920 batch tensor(15.9032, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3921 batch tensor(16.4090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3922 batch tensor(15.0186, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3923 batch tensor(16.7331, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3924 batch tensor(18.7564, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3925 batch tensor(18.0716, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3926 batch tensor(17.9171, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3927 batch tensor(16.6658, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3928 batch tensor(18.5073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3929 batch tensor(17.9618, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3930 batch tensor(17.6660, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3931 batch tensor(15.4954, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3932 batch tensor(16.3990, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3933 batch tensor(17.0513, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3934 batch tensor(20.2347, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3935 batch tensor(16.4628, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3936 batch tensor(18.0094, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3937 batch tensor(18.8062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3938 batch tensor(18.4185, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3939 batch tensor(15.2002, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3940 batch tensor(16.6256, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3941 batch tensor(17.3258, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3942 batch tensor(19.0116, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3943 batch tensor(16.1741, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3944 batch tensor(16.8712, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3945 batch tensor(16.3527, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3946 batch tensor(16.5953, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3947 batch tensor(18.6147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3948 batch tensor(18.2663, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3949 batch tensor(18.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3950 batch tensor(15.4334, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "3951 batch tensor(17.6817, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3952 batch tensor(16.7415, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3953 batch tensor(15.5363, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3954 batch tensor(16.3663, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3955 batch tensor(18.1135, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3956 batch tensor(16.4674, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3957 batch tensor(17.2580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3958 batch tensor(18.7897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3959 batch tensor(17.6266, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3960 batch tensor(15.1644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3961 batch tensor(17.3975, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3962 batch tensor(18.4517, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3963 batch tensor(16.7425, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3964 batch tensor(19.1404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3965 batch tensor(19.0233, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3966 batch tensor(15.6155, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3967 batch tensor(18.9722, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3968 batch tensor(18.6235, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3969 batch tensor(16.4964, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3970 batch tensor(17.8370, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3971 batch tensor(15.4449, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3972 batch tensor(16.2485, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3973 batch tensor(15.9565, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3974 batch tensor(16.4190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3975 batch tensor(16.4740, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3976 batch tensor(17.4831, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3977 batch tensor(17.8845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3978 batch tensor(16.1644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3979 batch tensor(17.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3980 batch tensor(18.5845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3981 batch tensor(17.7820, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3982 batch tensor(16.5519, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3983 batch tensor(17.0765, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3984 batch tensor(16.1327, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3985 batch tensor(16.8687, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3986 batch tensor(20.1509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3987 batch tensor(14.8874, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3988 batch tensor(19.1745, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3989 batch tensor(16.9703, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3990 batch tensor(15.4101, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3991 batch tensor(16.1654, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3992 batch tensor(15.9163, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3993 batch tensor(14.5535, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3994 batch tensor(18.5091, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3995 batch tensor(16.0847, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3996 batch tensor(15.7092, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3997 batch tensor(16.9957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3998 batch tensor(17.4619, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3999 batch tensor(17.4802, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4000 batch tensor(17.7506, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4001 batch tensor(16.8584, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4002 batch tensor(16.5228, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4003 batch tensor(18.5516, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4004 batch tensor(17.2845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4005 batch tensor(16.2823, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4006 batch tensor(17.8111, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4007 batch tensor(18.8738, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4008 batch tensor(17.0890, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4009 batch tensor(17.1961, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4010 batch tensor(17.2311, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4011 batch tensor(18.2331, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4012 batch tensor(14.1508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4013 batch tensor(16.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4014 batch tensor(18.5328, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4015 batch tensor(15.5052, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4016 batch tensor(14.3639, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4017 batch tensor(18.8058, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4018 batch tensor(18.5434, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4019 batch tensor(16.4323, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4020 batch tensor(13.7206, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4021 batch tensor(16.9847, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4022 batch tensor(18.8335, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4023 batch tensor(18.8383, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4024 batch tensor(13.5811, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4025 batch tensor(16.8333, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4026 batch tensor(16.6604, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4027 batch tensor(18.7128, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4028 batch tensor(15.6313, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4029 batch tensor(18.5289, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4030 batch tensor(16.8205, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4031 batch tensor(14.9776, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4032 batch tensor(21.1394, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4033 batch tensor(21.0413, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4034 batch tensor(13.9567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4035 batch tensor(18.9971, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4036 batch tensor(17.1938, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4037 batch tensor(18.3577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4038 batch tensor(16.7594, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4039 batch tensor(15.7083, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4040 batch tensor(16.9073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4041 batch tensor(17.7236, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4042 batch tensor(16.8624, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4043 batch tensor(19.6005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4044 batch tensor(19.0154, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4045 batch tensor(13.8441, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4046 batch tensor(16.0448, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4047 batch tensor(16.1770, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4048 batch tensor(18.7220, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4049 batch tensor(17.3825, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4050 batch tensor(19.0836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4051 batch tensor(18.0683, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4052 batch tensor(15.1884, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4053 batch tensor(15.3987, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4054 batch tensor(16.1091, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4055 batch tensor(17.8502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4056 batch tensor(18.1843, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4057 batch tensor(16.8079, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4058 batch tensor(17.5675, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4059 batch tensor(19.1492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4060 batch tensor(16.3868, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4061 batch tensor(17.9409, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4062 batch tensor(18.1760, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4063 batch tensor(17.0209, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4064 batch tensor(18.8576, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4065 batch tensor(16.1330, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4066 batch tensor(18.8589, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4067 batch tensor(14.2696, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4068 batch tensor(17.0186, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4069 batch tensor(16.7728, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4070 batch tensor(16.7522, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4071 batch tensor(18.4353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4072 batch tensor(18.7673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4073 batch tensor(16.2368, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4074 batch tensor(16.8498, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4075 batch tensor(18.8257, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4076 batch tensor(16.8367, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4077 batch tensor(17.5635, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4078 batch tensor(16.1008, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4079 batch tensor(17.2871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4080 batch tensor(23.9000, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4081 batch tensor(17.9972, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4082 batch tensor(13.4692, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4083 batch tensor(15.9610, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4084 batch tensor(16.0405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4085 batch tensor(18.1745, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4086 batch tensor(16.9404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4087 batch tensor(16.2177, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4088 batch tensor(16.0551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4089 batch tensor(18.8021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4090 batch tensor(18.2845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4091 batch tensor(16.3297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4092 batch tensor(18.2571, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4093 batch tensor(17.3198, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4094 batch tensor(16.0962, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4095 batch tensor(17.8711, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4096 batch tensor(17.6991, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4097 batch tensor(17.3977, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4098 batch tensor(17.1380, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4099 batch tensor(17.1990, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4100 batch tensor(16.9206, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4101 batch tensor(15.4459, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4102 batch tensor(20.5235, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4103 batch tensor(17.9511, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4104 batch tensor(18.1273, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4105 batch tensor(20.2146, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4106 batch tensor(17.0030, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4107 batch tensor(18.4546, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4108 batch tensor(17.7857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4109 batch tensor(16.1410, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4110 batch tensor(13.5125, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4111 batch tensor(18.0753, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4112 batch tensor(18.3120, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4113 batch tensor(19.0600, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4114 batch tensor(19.4709, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4115 batch tensor(17.0480, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4116 batch tensor(18.0981, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4117 batch tensor(17.9781, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4118 batch tensor(16.8622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4119 batch tensor(14.8935, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4120 batch tensor(19.5380, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4121 batch tensor(16.9422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4122 batch tensor(15.0151, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4123 batch tensor(15.6280, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4124 batch tensor(20.8112, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4125 batch tensor(18.4324, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4126 batch tensor(17.8357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4127 batch tensor(14.9575, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4128 batch tensor(15.6030, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4129 batch tensor(16.2576, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4130 batch tensor(18.5582, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4131 batch tensor(18.6805, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4132 batch tensor(19.0507, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4133 batch tensor(19.2822, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4134 batch tensor(17.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4135 batch tensor(15.6041, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4136 batch tensor(17.7811, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4137 batch tensor(14.9661, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4138 batch tensor(17.6294, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4139 batch tensor(17.6752, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4140 batch tensor(16.1224, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4141 batch tensor(15.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4142 batch tensor(15.2197, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4143 batch tensor(17.1363, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4144 batch tensor(20.5554, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4145 batch tensor(14.8761, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4146 batch tensor(16.1488, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4147 batch tensor(18.0303, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4148 batch tensor(18.5455, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4149 batch tensor(15.8385, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4150 batch tensor(16.3813, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4151 batch tensor(14.8318, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4152 batch tensor(15.9224, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4153 batch tensor(17.8460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4154 batch tensor(15.0096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4155 batch tensor(18.2670, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4156 batch tensor(18.8914, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4157 batch tensor(16.0679, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4158 batch tensor(15.4935, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4159 batch tensor(17.8765, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4160 batch tensor(16.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4161 batch tensor(16.6227, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4162 batch tensor(16.7841, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4163 batch tensor(20.4323, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4164 batch tensor(16.9049, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4165 batch tensor(14.0470, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4166 batch tensor(19.0366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4167 batch tensor(16.9251, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4168 batch tensor(20.8700, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4169 batch tensor(19.1469, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4170 batch tensor(18.3194, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4171 batch tensor(17.9657, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4172 batch tensor(18.3568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4173 batch tensor(19.0949, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4174 batch tensor(18.6591, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4175 batch tensor(14.0421, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4176 batch tensor(14.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4177 batch tensor(15.8786, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4178 batch tensor(16.6235, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4179 batch tensor(19.5915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4180 batch tensor(17.5051, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4181 batch tensor(18.5826, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4182 batch tensor(16.8096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4183 batch tensor(19.2841, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4184 batch tensor(15.5122, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4185 batch tensor(18.4400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4186 batch tensor(16.1342, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4187 batch tensor(18.9443, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4188 batch tensor(15.8158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4189 batch tensor(15.5291, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4190 batch tensor(18.3781, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4191 batch tensor(16.4881, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4192 batch tensor(17.9186, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4193 batch tensor(16.6741, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4194 batch tensor(15.5386, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4195 batch tensor(18.1508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4196 batch tensor(15.7374, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4197 batch tensor(18.4391, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4198 batch tensor(16.1379, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4199 batch tensor(17.7094, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4200 batch tensor(15.8343, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4201 batch tensor(18.5919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4202 batch tensor(15.1860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4203 batch tensor(15.1448, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4204 batch tensor(17.9936, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4205 batch tensor(16.9289, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4206 batch tensor(17.4508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4207 batch tensor(15.4022, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4208 batch tensor(15.3714, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4209 batch tensor(17.0098, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4210 batch tensor(14.2029, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4211 batch tensor(18.2856, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4212 batch tensor(17.4360, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4213 batch tensor(18.8254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4214 batch tensor(16.9630, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4215 batch tensor(15.5140, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4216 batch tensor(17.6609, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4217 batch tensor(16.3548, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4218 batch tensor(17.2544, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4219 batch tensor(15.2915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4220 batch tensor(17.1405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4221 batch tensor(16.7314, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4222 batch tensor(18.4444, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4223 batch tensor(15.9299, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4224 batch tensor(16.5206, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4225 batch tensor(16.4254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4226 batch tensor(19.0697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4227 batch tensor(16.8848, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4228 batch tensor(16.8939, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4229 batch tensor(18.3389, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4230 batch tensor(18.1175, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4231 batch tensor(17.1186, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4232 batch tensor(18.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4233 batch tensor(15.5489, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4234 batch tensor(15.9481, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4235 batch tensor(18.6120, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4236 batch tensor(18.9833, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4237 batch tensor(16.6674, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4238 batch tensor(15.5210, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4239 batch tensor(16.5413, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4240 batch tensor(18.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4241 batch tensor(16.8914, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4242 batch tensor(17.9316, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4243 batch tensor(16.0474, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4244 batch tensor(19.3294, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4245 batch tensor(14.1327, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4246 batch tensor(17.1991, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4247 batch tensor(18.2676, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4248 batch tensor(16.6258, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4249 batch tensor(17.1167, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4250 batch tensor(17.9737, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4251 batch tensor(18.2102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4252 batch tensor(17.4706, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4253 batch tensor(16.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4254 batch tensor(17.8353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4255 batch tensor(20.1171, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4256 batch tensor(18.2565, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4257 batch tensor(16.3615, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4258 batch tensor(16.6916, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4259 batch tensor(15.4349, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4260 batch tensor(17.3541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4261 batch tensor(17.5839, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4262 batch tensor(17.9038, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4263 batch tensor(18.2192, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4264 batch tensor(18.2576, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4265 batch tensor(16.1995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4266 batch tensor(16.8819, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4267 batch tensor(15.7333, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4268 batch tensor(16.9954, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4269 batch tensor(16.1592, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4270 batch tensor(19.8600, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4271 batch tensor(16.3308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4272 batch tensor(19.2778, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4273 batch tensor(20.3233, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4274 batch tensor(17.6275, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4275 batch tensor(14.9672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4276 batch tensor(18.8759, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4277 batch tensor(17.9339, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4278 batch tensor(20.2001, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4279 batch tensor(16.7544, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4280 batch tensor(15.6656, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4281 batch tensor(18.3714, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4282 batch tensor(17.2727, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4283 batch tensor(16.0942, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4284 batch tensor(16.0035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4285 batch tensor(17.3627, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4286 batch tensor(17.5918, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4287 batch tensor(19.8808, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4288 batch tensor(17.6681, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4289 batch tensor(15.9040, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4290 batch tensor(20.1203, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4291 batch tensor(18.9797, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4292 batch tensor(17.8423, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4293 batch tensor(15.4772, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4294 batch tensor(14.8454, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4295 batch tensor(17.6866, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4296 batch tensor(15.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4297 batch tensor(18.7270, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4298 batch tensor(15.7809, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4299 batch tensor(16.7207, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4300 batch tensor(17.4418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4301 batch tensor(16.3687, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4302 batch tensor(17.9238, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4303 batch tensor(16.4049, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4304 batch tensor(16.1642, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4305 batch tensor(19.3091, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4306 batch tensor(16.2843, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4307 batch tensor(15.8630, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4308 batch tensor(17.7859, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4309 batch tensor(15.7319, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4310 batch tensor(17.2248, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4311 batch tensor(17.7980, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4312 batch tensor(17.0618, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4313 batch tensor(17.1034, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4314 batch tensor(15.9677, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4315 batch tensor(18.4305, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4316 batch tensor(15.7932, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4317 batch tensor(15.5440, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4318 batch tensor(19.5186, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4319 batch tensor(15.3371, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4320 batch tensor(19.5027, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4321 batch tensor(16.4350, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4322 batch tensor(16.4460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4323 batch tensor(16.6360, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4324 batch tensor(18.5810, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4325 batch tensor(16.9761, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4326 batch tensor(18.6215, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4327 batch tensor(15.0697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4328 batch tensor(16.7502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4329 batch tensor(19.3721, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4330 batch tensor(17.0363, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4331 batch tensor(17.3553, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4332 batch tensor(15.2927, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4333 batch tensor(18.7834, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4334 batch tensor(15.5221, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4335 batch tensor(17.2746, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4336 batch tensor(18.5265, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4337 batch tensor(16.1771, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4338 batch tensor(17.8467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4339 batch tensor(20.6435, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4340 batch tensor(16.6767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4341 batch tensor(19.6396, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4342 batch tensor(15.3347, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4343 batch tensor(17.9323, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4344 batch tensor(17.4517, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4345 batch tensor(16.8188, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4346 batch tensor(19.6971, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4347 batch tensor(15.3151, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4348 batch tensor(15.8784, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4349 batch tensor(20.6908, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4350 batch tensor(16.2425, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4351 batch tensor(16.6407, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4352 batch tensor(17.5577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4353 batch tensor(15.7836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4354 batch tensor(16.8436, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4355 batch tensor(17.8046, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4356 batch tensor(17.4995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4357 batch tensor(17.5166, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4358 batch tensor(16.1819, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4359 batch tensor(17.2176, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4360 batch tensor(18.4099, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4361 batch tensor(17.0540, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4362 batch tensor(18.5392, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4363 batch tensor(16.5824, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4364 batch tensor(18.7093, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4365 batch tensor(17.0367, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4366 batch tensor(16.7436, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4367 batch tensor(17.2850, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4368 batch tensor(19.3834, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4369 batch tensor(15.3914, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4370 batch tensor(16.2250, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4371 batch tensor(18.5038, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4372 batch tensor(20.1057, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4373 batch tensor(17.1413, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4374 batch tensor(20.1715, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4375 batch tensor(18.6731, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4376 batch tensor(16.9938, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4377 batch tensor(16.4693, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4378 batch tensor(16.9911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4379 batch tensor(17.5378, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4380 batch tensor(18.4783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4381 batch tensor(18.1688, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4382 batch tensor(17.5330, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4383 batch tensor(16.8495, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4384 batch tensor(16.4327, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4385 batch tensor(17.8200, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4386 batch tensor(17.8093, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4387 batch tensor(19.3503, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4388 batch tensor(15.6767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4389 batch tensor(15.1833, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4390 batch tensor(16.1274, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4391 batch tensor(15.3182, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4392 batch tensor(16.9425, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4393 batch tensor(14.5447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4394 batch tensor(18.3870, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4395 batch tensor(17.0095, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4396 batch tensor(18.4599, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4397 batch tensor(17.4974, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4398 batch tensor(17.5551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4399 batch tensor(19.0122, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4400 batch tensor(17.4829, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4401 batch tensor(15.5783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4402 batch tensor(15.2978, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4403 batch tensor(18.9324, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4404 batch tensor(18.0256, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4405 batch tensor(16.4289, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4406 batch tensor(15.2813, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4407 batch tensor(17.9908, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4408 batch tensor(16.7814, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4409 batch tensor(16.2147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4410 batch tensor(15.6831, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4411 batch tensor(15.7015, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4412 batch tensor(15.0286, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4413 batch tensor(18.4836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4414 batch tensor(17.1371, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4415 batch tensor(17.4846, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4416 batch tensor(16.1267, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4417 batch tensor(17.8328, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4418 batch tensor(20.4047, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4419 batch tensor(14.6135, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4420 batch tensor(16.4379, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4421 batch tensor(20.6267, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4422 batch tensor(17.2821, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4423 batch tensor(15.0027, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4424 batch tensor(16.4855, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4425 batch tensor(16.7771, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4426 batch tensor(16.4155, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4427 batch tensor(20.3070, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4428 batch tensor(18.4482, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4429 batch tensor(18.4450, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4430 batch tensor(16.7273, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4431 batch tensor(16.3914, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4432 batch tensor(17.3158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4433 batch tensor(16.2179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4434 batch tensor(18.4581, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4435 batch tensor(18.7974, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4436 batch tensor(17.3586, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4437 batch tensor(17.8727, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4438 batch tensor(16.4672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4439 batch tensor(17.8450, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4440 batch tensor(15.4423, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4441 batch tensor(16.0912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4442 batch tensor(16.6977, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4443 batch tensor(20.3866, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4444 batch tensor(17.9990, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4445 batch tensor(14.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4446 batch tensor(16.0524, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4447 batch tensor(16.8369, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4448 batch tensor(16.0988, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4449 batch tensor(15.8296, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4450 batch tensor(17.2299, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4451 batch tensor(17.8509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4452 batch tensor(16.9703, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4453 batch tensor(16.6271, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4454 batch tensor(16.8709, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4455 batch tensor(16.5965, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4456 batch tensor(16.5211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4457 batch tensor(14.9313, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4458 batch tensor(16.2417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4459 batch tensor(18.1619, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4460 batch tensor(16.2112, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4461 batch tensor(19.0237, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4462 batch tensor(15.8294, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4463 batch tensor(15.9153, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4464 batch tensor(16.3557, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4465 batch tensor(16.4643, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4466 batch tensor(16.0366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4467 batch tensor(27.4098, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4468 batch tensor(16.9598, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4469 batch tensor(16.0132, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4470 batch tensor(20.7966, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4471 batch tensor(18.8799, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4472 batch tensor(18.0393, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4473 batch tensor(16.6342, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4474 batch tensor(17.9905, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4475 batch tensor(16.9989, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4476 batch tensor(17.2529, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4477 batch tensor(16.4859, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4478 batch tensor(17.1631, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4479 batch tensor(18.0444, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4480 batch tensor(15.9312, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4481 batch tensor(16.1411, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4482 batch tensor(16.8765, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4483 batch tensor(17.5253, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4484 batch tensor(16.0536, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4485 batch tensor(20.8726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4486 batch tensor(17.8880, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4487 batch tensor(14.8894, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4488 batch tensor(20.7573, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4489 batch tensor(17.5121, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4490 batch tensor(17.9495, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4491 batch tensor(14.7564, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4492 batch tensor(17.5256, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4493 batch tensor(16.7433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4494 batch tensor(18.2108, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4495 batch tensor(14.5264, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4496 batch tensor(18.6341, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4497 batch tensor(16.1311, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4498 batch tensor(18.0640, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4499 batch tensor(15.8797, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4500 batch tensor(18.1495, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4501 batch tensor(17.0476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4502 batch tensor(17.2054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4503 batch tensor(19.3622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4504 batch tensor(15.7930, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4505 batch tensor(15.6403, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4506 batch tensor(16.4329, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4507 batch tensor(17.3703, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4508 batch tensor(14.8075, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4509 batch tensor(17.9640, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4510 batch tensor(16.8185, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4511 batch tensor(16.9318, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4512 batch tensor(16.3348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4513 batch tensor(18.4363, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4514 batch tensor(15.4055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4515 batch tensor(16.7519, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4516 batch tensor(21.6433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4517 batch tensor(17.3583, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4518 batch tensor(18.4241, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4519 batch tensor(14.6449, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4520 batch tensor(16.6952, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4521 batch tensor(16.6800, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4522 batch tensor(15.2218, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4523 batch tensor(15.4009, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4524 batch tensor(19.6342, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4525 batch tensor(16.3219, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4526 batch tensor(15.7689, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4527 batch tensor(16.8453, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4528 batch tensor(16.3719, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4529 batch tensor(16.3932, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4530 batch tensor(17.8713, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4531 batch tensor(20.7942, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4532 batch tensor(17.9919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4533 batch tensor(18.2174, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4534 batch tensor(16.1586, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4535 batch tensor(15.5033, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4536 batch tensor(16.7538, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4537 batch tensor(19.0831, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4538 batch tensor(15.8951, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4539 batch tensor(14.5686, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4540 batch tensor(16.7516, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4541 batch tensor(17.7767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4542 batch tensor(16.8296, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4543 batch tensor(17.4528, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4544 batch tensor(16.7192, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4545 batch tensor(16.7865, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4546 batch tensor(16.5483, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4547 batch tensor(17.6380, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4548 batch tensor(15.5542, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4549 batch tensor(15.0501, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4550 batch tensor(16.8049, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4551 batch tensor(17.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4552 batch tensor(19.4579, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4553 batch tensor(15.2816, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4554 batch tensor(16.4341, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4555 batch tensor(19.1067, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4556 batch tensor(16.7154, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4557 batch tensor(19.5062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4558 batch tensor(15.6320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4559 batch tensor(17.0691, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4560 batch tensor(17.3067, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4561 batch tensor(15.6649, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4562 batch tensor(20.1342, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4563 batch tensor(16.2831, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4564 batch tensor(19.6476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4565 batch tensor(15.1865, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4566 batch tensor(17.6239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4567 batch tensor(15.6355, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4568 batch tensor(16.1905, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4569 batch tensor(16.0125, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4570 batch tensor(17.0843, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4571 batch tensor(16.6704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4572 batch tensor(17.5986, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4573 batch tensor(18.4660, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4574 batch tensor(19.4555, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4575 batch tensor(17.8755, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4576 batch tensor(17.3758, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4577 batch tensor(16.6029, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4578 batch tensor(16.2931, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4579 batch tensor(16.8988, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4580 batch tensor(14.1872, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4581 batch tensor(20.1450, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4582 batch tensor(15.1149, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4583 batch tensor(20.6370, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4584 batch tensor(16.5374, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4585 batch tensor(17.3838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4586 batch tensor(15.5548, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4587 batch tensor(18.3089, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4588 batch tensor(15.5689, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4589 batch tensor(18.7783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4590 batch tensor(19.1731, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4591 batch tensor(16.5378, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4592 batch tensor(17.1780, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4593 batch tensor(15.1344, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4594 batch tensor(18.7480, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4595 batch tensor(17.2968, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4596 batch tensor(14.7845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4597 batch tensor(18.1140, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4598 batch tensor(19.6757, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4599 batch tensor(20.6272, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4600 batch tensor(19.4584, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4601 batch tensor(19.2247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4602 batch tensor(17.6554, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4603 batch tensor(14.7743, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4604 batch tensor(18.2858, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4605 batch tensor(17.2253, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4606 batch tensor(19.0966, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4607 batch tensor(16.7647, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4608 batch tensor(17.3556, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4609 batch tensor(16.1503, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4610 batch tensor(14.9656, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4611 batch tensor(14.2353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4612 batch tensor(14.8034, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4613 batch tensor(18.5140, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4614 batch tensor(15.4857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4615 batch tensor(16.7491, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4616 batch tensor(14.1065, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4617 batch tensor(18.3408, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4618 batch tensor(17.2473, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4619 batch tensor(18.1500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4620 batch tensor(16.6051, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4621 batch tensor(16.0533, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4622 batch tensor(15.2291, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4623 batch tensor(19.1575, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4624 batch tensor(16.2492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4625 batch tensor(19.0104, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4626 batch tensor(15.7673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4627 batch tensor(15.9686, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4628 batch tensor(22.3819, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4629 batch tensor(17.3661, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4630 batch tensor(15.8238, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4631 batch tensor(17.5564, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4632 batch tensor(15.7537, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4633 batch tensor(15.4107, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4634 batch tensor(16.2717, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4635 batch tensor(14.6815, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4636 batch tensor(13.6690, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4637 batch tensor(17.8648, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4638 batch tensor(16.3880, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4639 batch tensor(18.0404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4640 batch tensor(16.1606, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4641 batch tensor(18.4334, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4642 batch tensor(16.4830, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4643 batch tensor(16.0834, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4644 batch tensor(15.0252, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4645 batch tensor(17.2549, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4646 batch tensor(15.5240, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4647 batch tensor(16.3571, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4648 batch tensor(19.6982, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4649 batch tensor(17.1971, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4650 batch tensor(15.5257, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4651 batch tensor(13.6902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4652 batch tensor(15.7190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4653 batch tensor(15.9823, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4654 batch tensor(18.0854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4655 batch tensor(17.4539, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4656 batch tensor(17.4749, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4657 batch tensor(14.8999, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4658 batch tensor(16.5263, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4659 batch tensor(19.3905, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4660 batch tensor(16.2635, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4661 batch tensor(17.0171, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4662 batch tensor(18.7185, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4663 batch tensor(19.1338, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4664 batch tensor(17.3811, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4665 batch tensor(15.2572, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4666 batch tensor(15.2560, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4667 batch tensor(18.2941, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4668 batch tensor(18.3490, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4669 batch tensor(16.9176, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4670 batch tensor(16.9717, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4671 batch tensor(17.2724, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4672 batch tensor(15.3197, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4673 batch tensor(18.6262, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4674 batch tensor(14.9607, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4675 batch tensor(14.5305, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4676 batch tensor(16.7804, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4677 batch tensor(22.9751, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4678 batch tensor(17.5756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4679 batch tensor(19.1838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4680 batch tensor(16.7184, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4681 batch tensor(17.1714, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4682 batch tensor(14.3983, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4683 batch tensor(19.0973, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4684 batch tensor(18.2030, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4685 batch tensor(18.8888, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4686 batch tensor(15.1552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4687 batch tensor(16.9638, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4688 batch tensor(18.1241, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4689 batch tensor(16.1236, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4690 batch tensor(14.4354, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4691 batch tensor(13.0651, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4692 batch tensor(19.1360, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4693 batch tensor(19.3748, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4694 batch tensor(16.4040, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4695 batch tensor(18.4552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4696 batch tensor(15.2395, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4697 batch tensor(18.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4698 batch tensor(15.3109, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4699 batch tensor(17.9787, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4700 batch tensor(20.5719, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4701 batch tensor(17.7191, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4702 batch tensor(14.8534, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4703 batch tensor(18.3264, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4704 batch tensor(17.2933, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4705 batch tensor(17.1233, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4706 batch tensor(17.2886, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4707 batch tensor(14.8570, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4708 batch tensor(18.3869, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4709 batch tensor(20.1793, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4710 batch tensor(16.0408, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4711 batch tensor(14.8261, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4712 batch tensor(18.6205, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4713 batch tensor(19.7318, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4714 batch tensor(20.1949, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4715 batch tensor(15.2033, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4716 batch tensor(17.1606, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4717 batch tensor(18.8327, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4718 batch tensor(17.1206, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4719 batch tensor(17.7972, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4720 batch tensor(15.9146, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4721 batch tensor(15.3513, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4722 batch tensor(17.5359, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4723 batch tensor(17.3330, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4724 batch tensor(17.6279, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4725 batch tensor(18.3092, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4726 batch tensor(14.8089, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4727 batch tensor(16.2425, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4728 batch tensor(16.8470, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4729 batch tensor(17.9885, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4730 batch tensor(17.3306, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4731 batch tensor(16.5868, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4732 batch tensor(18.3991, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4733 batch tensor(17.3850, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4734 batch tensor(13.8012, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4735 batch tensor(17.4902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4736 batch tensor(21.5042, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4737 batch tensor(18.9834, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4738 batch tensor(15.7940, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4739 batch tensor(15.3298, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4740 batch tensor(15.3835, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4741 batch tensor(13.7191, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4742 batch tensor(19.2547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4743 batch tensor(20.2793, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4744 batch tensor(15.9524, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4745 batch tensor(16.0517, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4746 batch tensor(17.7247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4747 batch tensor(16.0473, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4748 batch tensor(16.8337, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4749 batch tensor(16.9621, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4750 batch tensor(16.2592, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4751 batch tensor(15.9726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4752 batch tensor(16.2749, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4753 batch tensor(16.3733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4754 batch tensor(17.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4755 batch tensor(17.4967, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4756 batch tensor(18.2822, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4757 batch tensor(15.6876, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4758 batch tensor(17.8486, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4759 batch tensor(15.0794, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4760 batch tensor(18.8773, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4761 batch tensor(16.3743, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4762 batch tensor(16.9016, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4763 batch tensor(15.2447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4764 batch tensor(18.6681, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4765 batch tensor(16.5856, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4766 batch tensor(16.4594, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4767 batch tensor(19.4645, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4768 batch tensor(18.0975, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4769 batch tensor(17.4162, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4770 batch tensor(18.2790, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4771 batch tensor(17.0403, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4772 batch tensor(17.7223, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4773 batch tensor(17.2331, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4774 batch tensor(15.8827, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4775 batch tensor(15.7932, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4776 batch tensor(17.2563, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4777 batch tensor(16.5723, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4778 batch tensor(15.8999, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4779 batch tensor(16.6956, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4780 batch tensor(14.8310, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4781 batch tensor(17.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4782 batch tensor(17.4502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4783 batch tensor(14.9206, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4784 batch tensor(19.7222, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4785 batch tensor(19.2904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4786 batch tensor(18.7566, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4787 batch tensor(17.9002, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4788 batch tensor(15.1443, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4789 batch tensor(17.1638, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4790 batch tensor(17.4158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4791 batch tensor(18.3504, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4792 batch tensor(17.7405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4793 batch tensor(16.0561, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4794 batch tensor(19.2476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4795 batch tensor(17.7854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4796 batch tensor(19.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4797 batch tensor(15.7092, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4798 batch tensor(17.5219, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4799 batch tensor(18.2636, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4800 batch tensor(15.0862, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4801 batch tensor(16.8673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4802 batch tensor(14.9880, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4803 batch tensor(18.8009, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4804 batch tensor(18.3408, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4805 batch tensor(17.7819, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4806 batch tensor(19.4457, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4807 batch tensor(20.5999, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4808 batch tensor(15.8176, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4809 batch tensor(16.8447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4810 batch tensor(18.3042, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4811 batch tensor(16.5330, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4812 batch tensor(19.5672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4813 batch tensor(17.3809, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4814 batch tensor(17.5802, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4815 batch tensor(16.7285, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4816 batch tensor(17.1807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4817 batch tensor(22.5799, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4818 batch tensor(16.5053, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4819 batch tensor(17.9538, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4820 batch tensor(16.3108, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4821 batch tensor(21.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4822 batch tensor(18.8060, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4823 batch tensor(16.2262, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4824 batch tensor(17.5817, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4825 batch tensor(16.4448, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4826 batch tensor(15.8422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4827 batch tensor(17.3449, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4828 batch tensor(17.6234, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4829 batch tensor(17.8880, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4830 batch tensor(17.4190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4831 batch tensor(18.1491, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4832 batch tensor(15.8635, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4833 batch tensor(17.9720, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4834 batch tensor(15.3011, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4835 batch tensor(17.7357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4836 batch tensor(18.2671, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4837 batch tensor(15.7174, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4838 batch tensor(17.4171, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4839 batch tensor(19.0839, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4840 batch tensor(15.5907, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4841 batch tensor(18.0212, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4842 batch tensor(18.4711, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4843 batch tensor(15.5065, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4844 batch tensor(15.0467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4845 batch tensor(19.6238, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4846 batch tensor(19.5193, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4847 batch tensor(15.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4848 batch tensor(19.0717, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4849 batch tensor(13.1958, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4850 batch tensor(18.8021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4851 batch tensor(16.6545, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4852 batch tensor(17.8085, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4853 batch tensor(15.2652, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4854 batch tensor(17.9208, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4855 batch tensor(14.5995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4856 batch tensor(16.8583, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4857 batch tensor(18.1926, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4858 batch tensor(15.4239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4859 batch tensor(17.9507, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4860 batch tensor(18.4201, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4861 batch tensor(16.8355, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4862 batch tensor(15.6125, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4863 batch tensor(18.5912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4864 batch tensor(18.3879, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4865 batch tensor(15.9520, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4866 batch tensor(17.1228, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4867 batch tensor(16.3831, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4868 batch tensor(16.7802, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4869 batch tensor(17.1462, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4870 batch tensor(16.6433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4871 batch tensor(17.2133, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4872 batch tensor(15.7582, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4873 batch tensor(20.6378, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4874 batch tensor(15.7364, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4875 batch tensor(18.6304, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4876 batch tensor(21.2738, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4877 batch tensor(14.8904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4878 batch tensor(16.2707, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4879 batch tensor(20.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4880 batch tensor(16.3762, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4881 batch tensor(15.1909, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4882 batch tensor(17.5864, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4883 batch tensor(18.3317, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4884 batch tensor(19.4097, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4885 batch tensor(17.0444, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4886 batch tensor(19.0585, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4887 batch tensor(16.5742, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4888 batch tensor(18.6141, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4889 batch tensor(16.3269, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4890 batch tensor(17.8860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4891 batch tensor(16.8246, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4892 batch tensor(16.7895, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4893 batch tensor(19.5746, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4894 batch tensor(16.6770, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4895 batch tensor(17.6091, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4896 batch tensor(15.1777, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4897 batch tensor(15.0637, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4898 batch tensor(15.5207, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4899 batch tensor(17.9320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4900 batch tensor(16.9955, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4901 batch tensor(18.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4902 batch tensor(20.1838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4903 batch tensor(17.4859, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4904 batch tensor(18.5925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4905 batch tensor(10.3279, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4906 batch tensor(16.8248, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4907 batch tensor(17.8910, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4908 batch tensor(15.9890, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4909 batch tensor(17.7361, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4910 batch tensor(18.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4911 batch tensor(15.6739, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4912 batch tensor(19.7836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4913 batch tensor(16.9632, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4914 batch tensor(16.7922, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4915 batch tensor(15.4058, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4916 batch tensor(16.9897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4917 batch tensor(15.2554, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4918 batch tensor(15.4397, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4919 batch tensor(19.6870, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4920 batch tensor(13.6728, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4921 batch tensor(18.7583, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4922 batch tensor(17.0646, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4923 batch tensor(17.8107, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4924 batch tensor(16.3739, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4925 batch tensor(20.2180, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4926 batch tensor(16.4377, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4927 batch tensor(19.8185, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4928 batch tensor(18.9529, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4929 batch tensor(18.2706, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4930 batch tensor(14.9518, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4931 batch tensor(19.3581, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4932 batch tensor(16.5815, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4933 batch tensor(17.1738, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4934 batch tensor(17.1672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4935 batch tensor(16.0535, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4936 batch tensor(18.5914, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4937 batch tensor(18.6102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4938 batch tensor(15.2350, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4939 batch tensor(17.9331, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4940 batch tensor(16.2238, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4941 batch tensor(16.8632, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4942 batch tensor(15.9435, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4943 batch tensor(16.9042, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4944 batch tensor(20.6012, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4945 batch tensor(16.8556, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4946 batch tensor(15.7051, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4947 batch tensor(16.5897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4948 batch tensor(17.9868, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4949 batch tensor(16.0716, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4950 batch tensor(15.6431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "4951 batch tensor(15.9404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4952 batch tensor(18.0814, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4953 batch tensor(17.6405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4954 batch tensor(14.5249, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4955 batch tensor(15.7520, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4956 batch tensor(16.4635, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4957 batch tensor(17.1913, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4958 batch tensor(19.4705, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4959 batch tensor(16.8036, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4960 batch tensor(18.9672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4961 batch tensor(15.0617, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4962 batch tensor(16.1516, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4963 batch tensor(20.6359, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4964 batch tensor(16.0801, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4965 batch tensor(18.0364, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4966 batch tensor(16.1316, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4967 batch tensor(17.8178, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4968 batch tensor(17.9241, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4969 batch tensor(14.8117, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4970 batch tensor(18.0254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4971 batch tensor(19.4128, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4972 batch tensor(16.4985, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4973 batch tensor(18.5991, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4974 batch tensor(17.6880, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4975 batch tensor(17.2705, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4976 batch tensor(17.0783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4977 batch tensor(16.7018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4978 batch tensor(15.3351, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4979 batch tensor(18.4365, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4980 batch tensor(17.6120, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4981 batch tensor(16.4608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4982 batch tensor(18.9631, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4983 batch tensor(21.3021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4984 batch tensor(17.4026, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4985 batch tensor(14.7748, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4986 batch tensor(17.6782, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4987 batch tensor(17.5270, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4988 batch tensor(17.7711, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4989 batch tensor(19.1838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4990 batch tensor(17.4216, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4991 batch tensor(14.9721, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4992 batch tensor(17.4054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4993 batch tensor(18.4489, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4994 batch tensor(19.0776, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4995 batch tensor(15.7062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4996 batch tensor(18.1522, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4997 batch tensor(16.1644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4998 batch tensor(16.4352, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4999 batch tensor(15.8510, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5000 batch tensor(17.3931, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "5001 batch tensor(18.5139, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5002 batch tensor(14.1263, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5003 batch tensor(18.6451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5004 batch tensor(18.2489, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5005 batch tensor(18.3792, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5006 batch tensor(17.4557, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5007 batch tensor(19.2808, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5008 batch tensor(17.6277, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5009 batch tensor(19.6812, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5010 batch tensor(18.2661, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5011 batch tensor(15.1364, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5012 batch tensor(17.6691, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5013 batch tensor(17.7406, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5014 batch tensor(19.7593, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5015 batch tensor(14.6808, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5016 batch tensor(16.2421, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5017 batch tensor(15.8290, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5018 batch tensor(17.0670, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5019 batch tensor(16.0644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5020 batch tensor(17.5949, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5021 batch tensor(14.6937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5022 batch tensor(16.6569, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5023 batch tensor(16.6301, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5024 batch tensor(16.5823, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5025 batch tensor(18.0743, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5026 batch tensor(17.0974, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5027 batch tensor(18.7094, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5028 batch tensor(17.0733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5029 batch tensor(18.2544, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5030 batch tensor(17.9384, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5031 batch tensor(16.6503, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5032 batch tensor(17.2658, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5033 batch tensor(16.2111, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5034 batch tensor(15.9694, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5035 batch tensor(16.8919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5036 batch tensor(15.6971, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5037 batch tensor(17.0785, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5038 batch tensor(16.1066, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5039 batch tensor(18.1891, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5040 batch tensor(19.3467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5041 batch tensor(15.3209, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5042 batch tensor(17.6798, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5043 batch tensor(17.9957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5044 batch tensor(19.8740, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5045 batch tensor(16.4399, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5046 batch tensor(18.4637, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5047 batch tensor(15.6134, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5048 batch tensor(21.0925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5049 batch tensor(18.4998, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5050 batch tensor(19.1465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "5051 batch tensor(15.8304, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5052 batch tensor(18.6272, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5053 batch tensor(21.4743, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5054 batch tensor(16.7001, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5055 batch tensor(15.3490, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5056 batch tensor(16.8476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5057 batch tensor(16.9447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5058 batch tensor(15.8098, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5059 batch tensor(19.2495, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5060 batch tensor(18.4204, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5061 batch tensor(16.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5062 batch tensor(16.1760, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5063 batch tensor(16.3529, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5064 batch tensor(16.1062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5065 batch tensor(15.8935, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5066 batch tensor(19.3184, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5067 batch tensor(17.3078, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5068 batch tensor(15.1433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5069 batch tensor(15.6197, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5070 batch tensor(16.1394, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5071 batch tensor(13.5461, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5072 batch tensor(14.0767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5073 batch tensor(16.9207, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5074 batch tensor(16.9937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5075 batch tensor(15.7372, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5076 batch tensor(17.5835, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5077 batch tensor(14.6302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5078 batch tensor(18.7130, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5079 batch tensor(14.9595, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5080 batch tensor(17.0134, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5081 batch tensor(20.6149, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5082 batch tensor(19.6653, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5083 batch tensor(16.6667, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5084 batch tensor(17.7309, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5085 batch tensor(19.2439, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5086 batch tensor(15.2660, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5087 batch tensor(18.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5088 batch tensor(14.3336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5089 batch tensor(18.9502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5090 batch tensor(18.0165, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5091 batch tensor(18.0338, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5092 batch tensor(16.8402, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5093 batch tensor(14.8590, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5094 batch tensor(15.3744, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5095 batch tensor(16.0386, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5096 batch tensor(16.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5097 batch tensor(17.7184, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5098 batch tensor(17.1002, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5099 batch tensor(15.7966, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5100 batch tensor(14.6867, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "5101 batch tensor(16.6363, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5102 batch tensor(17.7799, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5103 batch tensor(15.6761, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5104 batch tensor(19.0366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5105 batch tensor(17.7173, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5106 batch tensor(16.6325, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5107 batch tensor(17.7018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5108 batch tensor(19.8627, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5109 batch tensor(15.0161, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5110 batch tensor(14.9210, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5111 batch tensor(15.9452, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5112 batch tensor(15.9661, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5113 batch tensor(16.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5114 batch tensor(17.0257, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5115 batch tensor(18.7223, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5116 batch tensor(16.3303, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5117 batch tensor(18.8062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5118 batch tensor(17.3792, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5119 batch tensor(18.5874, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5120 batch tensor(16.3367, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5121 batch tensor(16.0345, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5122 batch tensor(18.1922, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5123 batch tensor(18.9217, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5124 batch tensor(17.2254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5125 batch tensor(17.6312, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5126 batch tensor(16.9201, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5127 batch tensor(15.1466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5128 batch tensor(17.7822, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5129 batch tensor(16.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5130 batch tensor(18.3188, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5131 batch tensor(15.9044, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5132 batch tensor(14.9042, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5133 batch tensor(18.0393, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5134 batch tensor(18.7396, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5135 batch tensor(17.9680, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5136 batch tensor(15.2154, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5137 batch tensor(14.6226, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5138 batch tensor(18.2587, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5139 batch tensor(22.6589, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5140 batch tensor(18.0260, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5141 batch tensor(15.9152, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5142 batch tensor(14.5715, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5143 batch tensor(18.7475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5144 batch tensor(15.7465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5145 batch tensor(16.0877, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5146 batch tensor(17.2851, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5147 batch tensor(18.9996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5148 batch tensor(17.1199, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5149 batch tensor(16.2202, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5150 batch tensor(18.0947, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "5151 batch tensor(19.6407, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5152 batch tensor(17.9290, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5153 batch tensor(17.1002, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5154 batch tensor(16.6109, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5155 batch tensor(15.3441, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5156 batch tensor(16.5265, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5157 batch tensor(16.7966, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5158 batch tensor(20.4952, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5159 batch tensor(18.6308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5160 batch tensor(15.3499, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5161 batch tensor(14.8530, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5162 batch tensor(17.6622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5163 batch tensor(17.3865, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5164 batch tensor(17.4326, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5165 batch tensor(18.3147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5166 batch tensor(15.5934, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5167 batch tensor(17.3963, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5168 batch tensor(17.3004, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5169 batch tensor(16.3238, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5170 batch tensor(15.6080, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5171 batch tensor(16.8536, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5172 batch tensor(19.2753, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5173 batch tensor(17.1987, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5174 batch tensor(15.9130, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5175 batch tensor(16.1207, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5176 batch tensor(15.7766, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5177 batch tensor(17.7941, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5178 batch tensor(15.8830, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5179 batch tensor(18.5523, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5180 batch tensor(18.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5181 batch tensor(16.5804, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5182 batch tensor(17.7247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5183 batch tensor(18.2755, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5184 batch tensor(16.8288, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5185 batch tensor(17.2904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5186 batch tensor(14.7533, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5187 batch tensor(17.2132, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5188 batch tensor(17.4111, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5189 batch tensor(17.8044, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5190 batch tensor(16.3307, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5191 batch tensor(16.6839, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5192 batch tensor(15.7093, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5193 batch tensor(17.8110, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5194 batch tensor(16.7254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5195 batch tensor(16.3097, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5196 batch tensor(17.1700, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5197 batch tensor(17.1056, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5198 batch tensor(16.9815, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5199 batch tensor(19.4213, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5200 batch tensor(18.7320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "5201 batch tensor(18.8102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5202 batch tensor(19.7664, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5203 batch tensor(15.7858, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5204 batch tensor(17.6236, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5205 batch tensor(17.2263, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5206 batch tensor(16.5071, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5207 batch tensor(16.3346, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5208 batch tensor(17.7401, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5209 batch tensor(16.7810, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5210 batch tensor(16.3847, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5211 batch tensor(16.3005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5212 batch tensor(18.7776, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5213 batch tensor(14.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5214 batch tensor(17.5964, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5215 batch tensor(13.8623, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5216 batch tensor(17.5908, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5217 batch tensor(20.0603, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5218 batch tensor(15.8503, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5219 batch tensor(13.7463, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5220 batch tensor(17.2243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5221 batch tensor(16.2432, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5222 batch tensor(16.6549, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5223 batch tensor(17.7842, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5224 batch tensor(17.7528, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5225 batch tensor(18.4730, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5226 batch tensor(16.5708, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5227 batch tensor(16.6583, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5228 batch tensor(16.8955, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5229 batch tensor(17.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5230 batch tensor(16.0526, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5231 batch tensor(22.5940, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5232 batch tensor(17.2410, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5233 batch tensor(15.7949, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5234 batch tensor(16.6760, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5235 batch tensor(15.7595, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5236 batch tensor(17.2441, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5237 batch tensor(17.8107, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5238 batch tensor(16.4699, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5239 batch tensor(18.8249, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5240 batch tensor(17.7224, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5241 batch tensor(18.8839, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5242 batch tensor(16.9402, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5243 batch tensor(14.1800, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5244 batch tensor(18.7744, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5245 batch tensor(18.5506, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5246 batch tensor(14.3818, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5247 batch tensor(18.0262, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5248 batch tensor(15.2162, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5249 batch tensor(16.2111, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5250 batch tensor(15.9179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Saved\n",
            "5251 batch tensor(19.2641, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5252 batch tensor(15.5765, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5253 batch tensor(17.5957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5254 batch tensor(15.6458, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5255 batch tensor(15.4038, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5256 batch tensor(15.7980, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5257 batch tensor(15.2403, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5258 batch tensor(17.4659, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5259 batch tensor(17.3385, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5260 batch tensor(16.0108, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5261 batch tensor(16.4673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5262 batch tensor(15.4559, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5263 batch tensor(16.5930, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5264 batch tensor(16.7421, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5265 batch tensor(17.2081, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5266 batch tensor(17.9398, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5267 batch tensor(15.6261, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5268 batch tensor(18.9591, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5269 batch tensor(19.7658, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5270 batch tensor(18.2771, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5271 batch tensor(14.5760, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5272 batch tensor(17.5912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5273 batch tensor(21.7547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5274 batch tensor(16.7677, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5275 batch tensor(19.5487, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5276 batch tensor(17.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5277 batch tensor(17.4933, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5278 batch tensor(17.4519, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5279 batch tensor(16.9683, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5280 batch tensor(16.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5281 batch tensor(15.6376, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5282 batch tensor(15.5462, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5283 batch tensor(14.3593, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5284 batch tensor(17.9145, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5285 batch tensor(17.3508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5286 batch tensor(17.4387, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5287 batch tensor(17.7733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5288 batch tensor(18.6470, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5289 batch tensor(16.5202, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5290 batch tensor(19.4562, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5291 batch tensor(17.1937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5292 batch tensor(20.6929, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5293 batch tensor(17.0408, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc-2Uf6MlQiE",
        "outputId": "55e6f3e3-38e1-43ed-b6ff-a6d312769c21"
      },
      "source": [
        "precision, recall, AP, f1, ap_class = evaluate(\n",
        "    model,\n",
        "    test_samples,\n",
        "    iou_thres=0.5,\n",
        "    conf_thres=0.5,\n",
        "    nms_thres=0.5,\n",
        "    img_size=opt.img_size,\n",
        "    batch_size=2,\n",
        ")\n",
        "evaluation_metrics = [\n",
        "    (\"val_precision\", precision.mean()),\n",
        "    (\"val_recall\", recall.mean()),\n",
        "    (\"val_mAP\", AP.mean()),\n",
        "    (\"val_f1\", f1.mean()),\n",
        "]\n",
        "#logger.list_of_scalars_summary(evaluation_metrics, epoch)\n",
        "\n",
        "# Print class APs and mAP\n",
        "ap_table = [[\"Index\", \"Class name\", \"AP\"]]\n",
        "for i, c in enumerate(ap_class):\n",
        "    ap_table += [[c, class_names[c], \"%.5f\" % AP[i]]]\n",
        "print(AsciiTable(ap_table).table)\n",
        "print(f\"---- mAP {AP.mean()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rDetecting objects:   0%|          | 0/3330 [00:00<?, ?it/s]/home/ubuntu/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py:279: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n",
            "Detecting objects:  92%|█████████▏| 3055/3330 [57:04<05:06,  1.11s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eNn34W70xfj",
        "outputId": "96ffe8f9-4296-43ad-c58d-30cad4b4715c"
      },
      "source": [
        "for param_group in optimizer.param_groups:\n",
        "  print(param_group['lr'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCrpmVLrjGCn"
      },
      "source": [
        "torch.save(model.state_dict(), f\"checkpoint/yolov3_sample-6.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loApNq16LsjG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6b1cf8f-f86b-45d1-9eec-f676f2bc839c"
      },
      "source": [
        "model.load_state_dict(torch.load(f\"checkpoint/yolov3_sample.pth\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shkMUZFghdKy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a07e575-2c88-4185-9c26-a37e49bb5a00"
      },
      "source": [
        "img, tragets = next(iter(dataloader))\n",
        "out = model(img.to(device))\n",
        "out = non_max_suppression(out,conf_thres = 0.2,nms_thres=0.2)\n",
        "out[0][:,:2] /=1024\n",
        "out[0][:,3:5] /=1024\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py:279: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor([[0.5886, 0.7138, 0.1134, 0.6049, 0.7430, 1.7601, 0.5418, 0.7174, 0.2169,\n",
            "         0.7459, 8.0000]]), tensor([[6.4088e+02, 7.5941e+02, 8.0104e-02, 6.5827e+02, 7.9103e+02, 1.7214e+00,\n",
            "         5.4465e-01, 7.5558e-01, 4.4352e-01, 8.0500e-01, 8.0000e+00],\n",
            "        [6.8615e+02, 7.7087e+02, 7.6496e-02, 6.9409e+02, 7.7541e+02, 1.2501e+00,\n",
            "         6.1288e-01, 5.6992e-01, 2.0037e-01, 4.7022e-01, 1.8000e+01]])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "10RWCATMGcqG",
        "outputId": "116bd33f-4b25-4c66-ade5-2bd807eb40e6"
      },
      "source": [
        "plt.imshow(  img[0].permute(1, 2, 0)  )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2b145c5bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAD8CAYAAACLgjpEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd5hkV2Hn/e8556aKndP05KCRNEIBgRBIIKJsbIzAZNsgglcGY5LBtvAam9210SKDCS82ssBeyQs2IGMBBhsEQgEhoTBKk3NPT+eu7q5cdcM5Z/+o0iBeaC2WYCze936ep5+uG6rq9u06vzrpVglrLalUKvWTyP/sA0ilUk9eaUCkUqlVpQGRSqVWlQZEKpVaVRoQqVRqVWlApFKpVZ3ygBBC/LIQ4oAQ4rAQ4spT/fypVOqnJ07lPAghhAIOAi8CpoB7gddZa/eesoNIpVI/tVNdg7gAOGytPWqtjYAvAJed4mNIpVI/JecUP984cOJRy1PAMx69gxDiCuCK7uL5p+i4Uqn/PytZa4d+0oZTHRDiJ6z7kTaOtfZa4FoAIUQ6DzyV+vk7vtqGU93EmALWPWp5LTBzio8hlUr9lE51QNwLbBNCbBJCeMBrga+d4mNIpVI/pVPaxLDWJkKI3wO+BSjg7621e07lMaRSqZ/eKR3m/I9K+yBSqVNip7X2aT9pQzqTMpVKrSoNiFQqtao0IFKp1KrSgEilUqtKAyKVSq0qDYhUKrWqNCBSqdSq0oBIpVKrSgMilUqtKg2IVCq1qjQgUqnUqtKASKVSq0oDIpVKrSoNiFQqtao0IFKp1KrSgEilUqtKAyKVSq0qDYhUKrWqNCBSqdSq0oBIpVKrSgMilUqtKg2IVCq1qjQgUqnUqtKASKVSq3rcASGEWCeEuEUIsU8IsUcI8a7u+n4hxLeFEIe6v/u664UQ4pNCiMNCiIeFEE/9Wf0RqVTq5+OJ1CAS4L3W2jOAC4G3CyHOBK4EbrbWbgNu7i4DvBjY1v25Avj0E3juVCp1CjzugLDWzlpr7+/ergH7gHHgMuD67m7XAy/r3r4M+Afb8QOgVwgx9riPPJVK/dz9TPoghBAbgfOAu4ERa+0sdEIEGO7uNg6ceNTdprrr/t+PdYUQ4j4hxH0/i2NLpVKP3xP+dm8hRB74MvBua21VCLHqrj9h3Y99Oa+19lrg2u5jp1/em0r9J3pCNQghhEsnHD5vrf2X7ur5R5oO3d8L3fVTwLpH3X0tMPNEnj+VSv18PZFRDAH8HbDPWvtXj9r0NeDy7u3Lga8+av0buqMZFwKVR5oiqVTqyUlY+/hq8UKIi4HvAbsA0139x3T6Ib4ErAcmgVdZa5e7gfIp4JeBJvAma+1j9jOkTYxU6pTYaa192k/a8LgD4lRIAyKVOiVWDYh0JmUqlVpVGhCpVGpVaUCkUqlVpQGRSqVWlQZEKpVaVRoQqVRqVWlApFKpVaUBkUqlVpUGRCqVWlUaEKlUalVpQKRSqVWlAZFKpVaVBkQqlVpVGhCpVGpVaUCkUqlVpQGRSqVWlQZEKpVaVRoQqVRqVWlApFKpVaUBkUqlVpUGRCqVWlUaEKlUalVpQKRSqVU94YAQQighxANCiK93lzcJIe4WQhwSQnxRCOF11/vd5cPd7Ruf6HOnUqmfr59FDeJdwL5HLX8Y+Ji1dhuwArylu/4twIq1divwse5+qVTqSeyJfnnvWuBXgc92lwXwfOCfu7tcD7yse/uy7jLd7S8Qj/FV4KlU6j/fE61BfBz4Q3743ZwDQNlam3SXp4Dx7u1x4ARAd3ulu/+PEEJcIYS4TwjxmN/bmUqlfv6eyLd7vwRYsNbufPTqn7Cr/Sm2/XCFtddaa5+22ncFplKpU8d5Ave9CHipEOJXgAAo0qlR9AohnG4tYS0w091/ClgHTAkhHKAHWH4Cz59KpX7OHndAWGvfD7wfQAjxXOB91trfFELcALwS+AJwOfDV7l2+1l2+q7v9u/b/8tXiZ+54Cl/+2nfI+B6OcpBKIoRAKdX5ERKhBEpaXO+H9zPGYLRASFCqU3Fxf4reDmst1lqEEAghfmTZWgtS8Mj3jT96vyve8hZKiyWcwMVzfBIdkQgJCWgdoZQiSSKUchHCUm/X6e0doVoto6zBmM5xxnGM67okSYLWFjDs2vUAPT0jZHoK9BX6sbpNFEUcPLQHFflse/p5KJGwaf12SosnqDfbHDl6AFeD6wpim+Hcc87EdwMSCblcgVa9QaG3h7u+dyvGCl5w6S8hpaSQ7eFd7/o9ijkfL/B/5LzMzy+SC3xmlyqgLe04RFsD1sFaS5IkWGtpt9sI65CYEK01IEmShMQajDEnH1NrTZIknf+VMQghiHQCiSWhs07rbktVG4zo3OeRx9BaI4RAa43WmkdeSlprjNWcvXkMdMLxFUMu8NHWYrFI6SAECCHJZzyG8j7b1o1x7eeu5Tdf8ZtcdfUn+YMr30et3mZyfgUlBC2dYE3ntfeIH7ktLZ2ntziOA0mCVC5WSIQ0/NL5pxH4LvfsP8bsQpMLTx/FD3IUiz5e1kMFBeJ6FZUtIkSMbCdMT89xbG6ZSqtJs20wJgHHsra3h3o9ZKA3YLlSp9Yy1FsRjTgmSjTC8sNzYQ216QkKYxtIkgiQGJNgYkMiYhIjsFbzF3/w9lXLxBOpQazmj4AvCCH+HHgA+Lvu+r8D/rcQ4jCdmsNr/28PJITAdV0cx+mceMBxHIQQSClRSqCURSrBo7s7lVJ4CowAZS3G/uj2x3q+x1qen5lgcGwj6lGrLaBFQqGQ4cjkBOdf8Gwm9u8jU8hjsGhHAQlCKABarRau9GlXV3CEwcElVtHJv22utMQF5z+VxWqT6sI82Z4evHyORqVM1rUEysNxHDZsP53pyVkynkYan6npIwgNvu9z5plPo7e3yMLcPIvlZaSjCK3m7jvv5UUvehGFQo5yucx5T7+ABx98kHu+fyvPfM4LiG3Eroce4nnPf/aP/O1ho8ro6DBzs4sMFItUmi2yniTrubSaEZnAZ3SkQFtLdu052im82gUl0VojhUTEMY7jdgt+p3B7ntcJj25QOEJilMFDYYTAdINZo5HWIiUYBMZaUJ2CoJSiECiqreRkaJ++cZS43UJrzfrBPMoJKNVDLJ3Hkwi2jI4wPujjuB6NVg2tM3zwox+mvFyjkPE5NDmLciTWdMIEqZFSAhIhLGBRVqCFReAipUYJhZEgA4eXnL+F0IByIJfLU1qs4Ps5dmwpYJSgJ6dQViDCFiJTxCnkSMolSotVVlp1FpbqVOoRjcScLPBEgomFCoWMx8ximXYU0w6hUAhoVmMc03mNdYIZFNBuNIkW9tE7uAGsi1CS44cOEycrPHDvfYwN/1g34I/4mQSEtfZW4Nbu7aPABT9hnzbwqv/I40ohcVWnoAoLypW4jkQoEFYjhEI5AJ0EdyTIR3V1SAAhfqRA/0dVlufJ9A7ywT/5Aw7uPYTFMDo6zAeu+lM+fvVfc9WHPoyOLHsOHWHb9u3Mn5gkyHnE1iCFpdEIyfqgUUgsmSBA2wSTdF7gsTUYa3Bdl7Ads27NMHt278b3c0gJYwNDCKHoz4903qlQJHFEwQvYsmE90gRI2XkxJNKS8V2mZ2dolBdQvsem8RGklPiOj6PcTsFXimKxiKN8LrroIr536y0opZiZnuamW27mkuc95+Q5s9YS5HsAGB4ZQEqJXogwCWid4PmC0TVDKKUIwibPOP807tl5EGE7/4lYOtiogek+d6eQdR73kZqDUgop5cl1xpiThV9rffK3lLLz/FojjME6kpFclqVaBaUsRIYztw2QxE2+9b17WTcyxPD6M5AyZMfGIZZqddrtmP7+Il/99y9z6MBRxvMFLv/tN5PPwN9//GO8+g1vRyo4e8ta7j80jRASrxsMjxw31sUSI4TAcRTSWIQT0LaGV73wqUSVOjGasN2mHoUUmpqeIGDHun4czwUbE+SKGM9BCIVtNynNTTNbbtCsNam3NPVQozU/PC94bBjKsHWgFy8wSMcnH/jMlhb41s4JrJY4DlgrEI7mzu9+g5npw0jjUa6tMDI8xvNf8jp23nwHUzN7cT0PV/nMzh9/zNf/z6MG8bMjBI7joJRASrovEINSDq4UCET3XaXzrvDT5sAjifxYo6wW+IPffy+OKzm4bz9WQ6VZxZUCPeTxhldeTmIElz7vEkbXrqe/p4hIQpQrCUODqzReLkeSRHieh44TtLGgFAJNuVahP1/ESAPGwxqQStNqhvi+jyHGJJYgm0EbmJmYoNVO2HL6Jhyp2L/7MIWiy8BZA53qupG40gEjGB8ZR9sYJV2klJ1quZKce/7Z6CjGy3sopWi16oyv38zFFz+HiSOH2bx5K+12m49c/VH+6Mr3njxHj7wzK9V5hxoZGcHGEfVmG+WIky/ilXKZhVKds7ZuICg4GKFxpcf81AwPHjmBNQ5CGJQSWJuglHuywFtriY1Bdf8nQghMnGClPNmUe2S/ThNTMFjMsFCu0FMskksSyrUmn/nsP/Hrv/4yLn3exbTabRphnZtv+Q5fWqrwml//bVTGYzzj84ZXvopiIUAnklY7xM8HVMshgWtZmiuR7S12ginpNGkEAuFJTGzwHUli3JPHFWQFL77kfITnY5pVRNbD9X2yQchgoJDWgFZUlkqIdoSSEEcVpLGUmg0q5Sblep1GO6aZWCyQIBAKdJwghOAZZ42zdbyfVq3WOR4reGD/UQ7NrZD1XZpJgrVgtcUYaNYFyu2nUZpGWMuGLWdw203fpt2YxwqXE5OT9A8XMGH+McvKkzoghADXdVFSIqTEdSVKgeN0qqOPUD91NECC5bff9CauueYagiBYdZ+ZyWMcPXoAk2g8J0NpeYFW0qZlHVaW54mShELPMJXSLNomjIwMsWv/IZ71jPM5MTlLseARNUMAtImRjoM1MdZKCn1j9I+sYf7YMVTgYi0o4ZCgkNJB2wRHQKxj9u8+wMDoIJt2PAWBQ3llsVtTiqlVExqtEGE1YRhCAv2jg9x9653IXOdfa6zkogufjtGGrOuDgpVyBT/wkQKWFqZZWCrRVywiHEXW8WnG4clQaNZbgCGbzYLsnOeoUWW+VCWRkiiK6M03yfgBAgdjDLneLCBRGIyOaLZaBMqnbTWgkDLBGIm1P6xBGGNwrMV2axjGGHAd6NYyjDE4juz2zYC1UG1rfCdDu93mG9/4Bq++7DJe8ZrX0mq2qJSqRDph3egafuNVvwVSnXxjaDYNkTQ0ohYZR6Ctpd02PHR4EndgHX/8oU/yX97+1k4AKMlA1qccNpFRlYmpWSKtaTZajI6uY83oEIOFfkzY+T9IofACj6Qdsrxcxg8EQSZDsxmxuLyCNQ7zzQjPQoymHYNOYhJjEcbFStNtlgmE6NQKhBBkZMLE8TmiuIU0ktAaStUY5QaEUYwrHRJrsMJy17/9C9rEFHMFasuGrJuhXF5mqTSDoI2xmlzeIxPkcITHY3lSBwTQaSJ0OyUdBVJZ3Mc5v+qaT/81V/zO27juuut+4nZrNR/4r39KvVHl6NHDbNp8GkcO7GVkNMd8Kcb3fRYXlzh6PMKxgjCcQXTbtPv2H+Xy176MH9zzAPmcj9YWS0K+r0Bpbp7enkGMTbDWUFmaRicWN/CwApQ0JCZGoJibn+LCC59BHMGBA/sQ2Tz9Q2NMHj1KTzGL5wZYYVi/bSvl5QqZjE+r3iKTy3Xa80YzvGEtZ5y5g3bYIJPJEDUb6Djm1rvu4pee+3yyGQ/P86nUyriuy9q16yktL2KMoVjME7djrr76I/zhH76PIOtTrzdPhgOAm83R2y+YX1jBaEup0kCJFo6U7DhrC53quMbGLZJmRDYT4Pstkkf6AKRzsi9Cyh92OArR6dB0pcDNZmm1WhgjAAvSARvTF+TwpCRMEurNBvlilkgrXvqyl9PUCXEYESYxxnaaKcINaBvIuAIdd2ojzTAhSTQaizC2U8tyfYzIUG0t8ObfuQIBCCk5dGgPk75Ct1pkM3De2U8hdj2WKnW++Jm/pa+3yN/81V9y1d98FuVKpo+d4D2/91ZarRaNMCFMLK0wITF0a3Od/qY2P6zJguw2mUU3GJyTnbFKKaS11CoRoUiYXaxRiwFrSJKE4UKAkj6lSoNaNeSfPvcJrvyjP+LW2+7gK1/7CkHgESUxxyaOEIV1knabN1x+BV/5lxtYWqwQxs3HLDNP6oAQ3R8LSGkwFhz7+MLh3e96Fx//xCdW3X7l+6/k6OEDnH7mU8kWDOVanfLiLImOqZXrJFFCkMvR1zcKwpC0awgEURSjlGJ8vI+77nsQ55F2M4oNW7ewa9cuctkedNLGIsEmCBRKWcIowfMVWAcpLQbB8NAoRw5PYG2nR3zDumGsDhkeHUXopFNQjUT5grGRAawVBBkPKSWB6+MohedJZqankELS9Bv09/QSG4PjuQgEcaxxXUs2yJDL5Tq1gGIPleUlALSOyeUK/PWn/oY3vvEtFAq5k+fJGIPVnVB0fRcTgk0SEtsZldBGd2p8QmEaIXGSoJAoqXBEZ4RCWrDikaaJIOPLbnBYsm6BUMedmohfQBiNTjRWJugkS6I1oUkol5bwC1kqjTqFnIfrKEKtcRyn+7iGZqtMf9ZHKcVAb0Ar1CyW60hpEULhCYExnDzXkakzN7vMBz72IXYMD/O7b383a9avJYliMmsDolqTVmgR1SqnbdxAtRmysDTJm9/2HraddiaJhsRalisN2lFCrDWxdTBIrNWYR5pHWKSCKIF84NNstYhx0CbClYrEGqR0TtawpIUD8+VOh60Fuutzrk8xI1mptRnOu9zwub+l3W7z/j/7ALlsEeW6tKOEfNZBmAhlJEjF33/6UwhX0T80xvTCYw4kPrkDAjoBoZRFSIHngLCWnzzn6rFlksc+EZP7DxPk8tx37x0MFHrJSoVWPiYxLC0v0Vcs0kgiynMLjG1ay0o9ITEJxmhiHXLw4DTjawY499xzmZycxCrB4YNH8H0f5VjiSNNstnF9j3WbNqPjhKmpKeI4wpUB2miEMFg0QkqsBuFJiiJDQyRMHj6MbjZZf+bpCGM5svsYSgnOeXovUjpIBAkWYS2jo6O4wsHaTseeRWON5lnnnkOtXiPfk6enr496uUTcDmk362TzOYKeIpVKhXXr1uF4inYYUimXUHIQ33eRTqczESnJuXlyhTzllSVKy1XasUZKxYFDswz19TA0VET19qIaKwRODnex2mnHC4EU8KH/cSUvfvEruPMHNxP4WcJym0Y0T9i0nLFxM5df8TuUWlGnR15oiBwGewWxCYjaDbJjg4RxhMwo+op56vU6bm+RUnWZu+6+j3bURsaCC84+H0dKjJEUM5Le4jCLK8tUa1X27d1NuVzDas307CzzcwtoaZGew/LCPI4UFHMZsoPDVJsNhFujvDhHvtjPTHkFowXKcVipNbn1+7fzzPPP44KnncuJ+QnWbtjMrjvvZPrwHurtiEJhmFzOpx7GXPZrl4FwCMOQdhhihETIBCVUp9+tGzRKQq/nMT21n1ZYI4xcxjdsRwOOlEQm4cQKbB0pUG22eec73sGnP/tZDu3dzcLKCYR0cT1DqwGtdgUpII4syoHAEZQX55BR/Jjl4kkdEEJAZ3TT4AkHSScoHo8fzv7+cQZLz+gAx48cptjXT2FklKX5OUonJpBKMj6+loMHD6Acl2xPhkajgZSSkaFhFuZmEHh4bsCO887j+MQk0GkzK8dBxhBFEbv2HMDqkHPOPp9jR44SOC4OAqTb7c03J9v9WEFbR2SNx+333cuFz3o6p591HkIZ5mZL5HyLn81QbpfBatrtiEaS4BgYGMiz8647sH4WxwoyuTxnn7sDRwj8XBZpJflMlmZpgVtu/w6XXnopPT19zM3NMD6+jsHBfnRjhXrdZWSoh3/7t3/j8ssvxzjyJ0677ekr0psvMLe0QqMZMjZYoNJoMzE5x2h/Dtd1ODQ5S2hBKxDG8jd/fRW0W3z1y9eDkWgdc9WHP0YhV+SPrnwPv/rKX+eOu+7kK1+9gbVrO82lV132q8QJZJXHUi2iGYYUgww67oTI8ZkZjk8coxXHvPIlL2B5uU61USfjK778jX9FCYFwXALXwQDb163lNb/yQvxMkcXlFW65+wecufU0vnf3AdxazOlPPR2QhGHI3PwiGzdtYCUMaDVWqExO4zULJDpEBgEGTZDJMjAyzkKpjBu4WG3ws3my46dRdCTtlTqLywvkCkX2Hz7KmjUbkcoiZacTU0oHayzGgnEV1ekDuFGd7z60h7yXxfEtSsDcicOc/dxfRgEDnsOOjYMopZhaSHhg114WFuexgYtjNYlROErSiJqsWT/G8mIJbUMCVxHGCRLDwMgIRw4fXbVsPKkDQkpB4Dgop1Mle7zXdi0uzJH82KzuBHD40//2AT5w5QdoVtvUag0iHSFsgpaWZz/7Odzy3VtZWl5GComSgjiKMDYGq5ifniK2AqNjztg+zvzUFI7joHWMFYbRsbUc3L+PbDaPTBI2bN4IQOAKtA47czkMhMRIJFqAxaEVN1kzNsrC7AKFrIMf5Ni3dx/WCor5DDLIMbxmkOWDZaRyGRkaxihLEia0KhVkfpCtWzYztm4tjlBUV+YwBn5w+20M9Q/yzGc8kxhLoa+XRjOiXl1heHiQOKrjOA5uvkigFHse3s85557DF77wz7zhjb/5Y+dVJ21MEmOtYWSwQBJlsNYwUMwSRpq5Up0wiZG+S6O6xNSRKZTvkgkCcBza1Sb5wEdlfd797t8hmw+QVnL1X/1PejMBOozYc3AfmYzPx//6GtavGeW5z38R7VYb0e0g3bt/HwsLc/zGq36N/rzH+eeeSWl+hf5CgXYU4kh49UteTq0+x6aN21gqzXPa6acRtdrs2r0L113GC3yGBgZRUrFtQx8LC1VqtRqL83MMj/TjBhlmJk/gOB65rEN/T55s/yCFnj5q9TLlMOJFz70YL5vB2ISllRL33nkry5U29VaE4ymywicf5FhcLjOwMM2G9RuxQiIdATFoK6A7XO0h2LBmlKXZEwz05PBVgPQdbBShlWL7YJYTi22GejMcn1+mHUbUGiFGZGknVdAJcZjgugKkgzWKeqVOGMYkWtMWAj+Xo9qoIhuLj10GH1eJO0WEEPiB6k6O+o/f35qEXff8gIAQ92TvONTrdX7rDW/CmCZz01O4vsTKBBRcdNElbNt+OlprvvvdW7BY+gs9xEmMdcBxciTaxRgYGFmDsAYhFPfvPsbQ2Frq9ToASkhmT0yTzfhgY3acs4NioYcobtJqRxT7+2i1E2LlIlAYA47tzA7NuB6luRLGJGzcuoVaaZH1o8OMre2nr6eAUZKeYpbzzz0TYxMWFhaoLqxQr1ao1KoMDxSJ4pjZiaMszE6ihIPnuBjPoxUa1q4fY3FxkbPPOKdba7F861vfwvV9tIBmq4UWgLQcO3aMmbkT2PjHa2DKCXCCAC/IYIXEcV3odkRmlMT3HPIZF08K1gyN8ZSnns3/uv7TzE5O0a412Lj9NCJj+ZUX/Cp9PX287KWvRBqX0zZuoW9omA996EOsHRjg9a9/Ay976ct41nOehzSWwd4etNa4rsvmjRt5/StfRrlSYePGjRgUvhLksj4ZP0sj0izXKgz3FzFRi/mFGax1qK9U2LRxExs2rmd+toTIeGR9n75ihr/4wO+jlOLjn/oE137y45SXVtBSo00NHWmGhvsJPIfLfu1XefWrXsdrX/U68v1jJO0GMoyw2jBfanRml4qErCcoLUxTSzRWxyzMLpDPuBT9gJzn4LsOGU/Qn1P4rkKImMnpBar1FkZ6CBeSpMViK8REMRPzZayAB/ZNMltpsxIrYukyODhIX26EdqtFvpgBDK1GC6mgWq6QKeQZHx3DL2TIOB55N8CT2ccsQ0/qGsQTNTs7y7dvv5PCTo8k7gw57t17H9tPO4uwUeX3rngXf3vNNcSxZWVlCWMsd9x2C709BYwxnHbWWRzcvYdy2GZ4ZA2NagVsjNUhUkjmZ6cBSxzHOL7kwKGDFAIXKTwSE2GMpd5sELgeW7efw7Ej+zqz7kxCeanaKVA6pNGsk81mCKMQRwVgJdoaXM/D8XzajRYHD+3HRgov77NhwzpWlkKOTuzjwgsvQXanOnu+Q09PD4ODg2grsDrGVQ6hNviu4nlPu4AwDDlxdJJ8Po8QhmqtwfDgEL7v01vswWiDlC5TRw8y2NfP0OAwJ6Yn+PwXPs9vvf7yHzvHwtqToxCI7mS17pBiT94lm8vzu+/6fV5wySV8+KMfxVjLr7/k15iZW+KOO7+H6/rcdNO/8+bL38K/33YrG7dtZM+BIzTDGn/8J39CrBPe+74/AG3Ac/jEX36UUqXaralpXNdjcKifVhxijMUKQ1AsEMYxS8vzDAyuZXh4gPGRfpCC0fIwnjD0jQzRbDUw7YRtmzdweGYWIxJyGY9st9PU9RWtVkhPT4bFuWV6CkV6h/rJZPMsVZuEYUiSJIRRhLQQZBTzpSrWdqaYh5FBJzGLrTbtuIHrGCJt0RKMsei4SWxiMl4ObQVFB2yrznKjzcyJo8zNzhMZGB0eQCgwScJKu3qyI3bz2CDz9ZBWWKNSLnPzTd8A6bB1yxkMDg0xPz9Ps9lmZXkRvICk3Ub4GbIqQ6NaJ9LRyXKxmid1DeLxeOT6CWstw2sGuOIdv8ubr3gbre5ozlk7zkLGMY7I8cH/+QE0imPHJxDaUPQDtp51HpmeAlEU8dDOh9E6QRnN1MQxwriFtgm6O+ymTUyURDiuy1NO20xfPoMxhlpzCWkVZ5+zjdO3b6a0XOXQwb0oLIvzMzi+wCQJaIM1imymiLEOjgo6PdVxhFKCJNIcfGgf2d5ezrvwEp727PNx3TxxrCnmPEgiYhMT6YRms0mlsoQxhptvuYW9u/YyPT1NqVzDhhqJ4O6776K3txeNpVAoIKUCEYNIePbFFxKbhCiO8XyH0884kyRqcv/Ouzhty2ayGct3vnnjj55rYqzoXqsCP7xOItHEYYTUlrjR4tCBA3z39tt50aWXMjQwyhf+8UuEjTrvf/c7uPBpTyObGWTy6ASH9z7EmWftoNGo4Ls+Y+PjJKXYAnQAACAASURBVLElDCPWrVtPO4r4/Xe/szMaIzrT55WSTEydwHc9MrmAdqNNuxmRzwXs2L6d91z5Xo5NHAEM+/bsZePWjYRhSGVhjrm5WZbbdRzfwxhDT77A2NgYjXqrU3t1PNpJjWy2QHFglCiylOaO8/Cu3YRhC2stkenMWfB8j0i79PcWGR7sRUiB40oc3yOfL5IvZEB4BL5PvV6mVm/y0D3f5cHbbuK6667jmms+xf/z2c/wuRu+xNe/8RXmFpaQrkOctLnv/gdZKa2gtSbfO8YNX7iBaz76IXY+vJN8FnS7xfhoLyOjQxSyOY4cO8K99+/k6J7dTM9MUm82aDTqWDRTU1PU6lWqlRW0tbzjne94zPL0/5EahOHtv305H/nkJ3nvO97D1X/5FwT9YwgtWZ6e4Otf+WcS2an6l0oVenp7MUrTUxihsjjL+GAP0lqsNOy+7x56CkUSBOc//ans3/UQa9euZebEVOdCIK0Z6B2kUq/iZLLYVieFdx88zosueQbHjk2QzxYxaHbvOkIzbJIrFjh09AhWR0glWT5QZmRomJnJWTZs3Iib9TBWoIQBKzDC0qhVKQR5bDZDs15lYmIPxgvo8QSuJ4kM5PpGAUkm51MYHcJqQ63WwMv1cf5FF2ATQz6fYf/+g7h+L5Fy+MZN3+XpZ+9gbHwNQih68gMoIekfHmRxfoHhgUGE0YStKmvGx3BcRSbroUSWKOrM8XuEQIARCNmprVhrOhcLAa04IYpitDG84rJXcMvdd3LPAw/zhf/1DyTCctf37uShhx/mzgfu5plPexbf+O43CcOQL33hn3ClpFat8pzX/QYnTkwirc/k1DGElkTacuUH/iuFfC+OFoyuG+K/X/lO/HwPShuWlhcJCTl0cJ7RsTH6c73k/F4MltHRYTKZAiSGoQ0bETMzVGs1brvzLraefjqB77F+3RjNVo2VlRXiOIbYkjTLEDd4YOc9jKwbY3zTJkAiEWQdh/mleXp6Cp0OdCtptQ2ukmAFSRgTmgrIgLhVJwoTonCFr375egq9A2R8h4Q2WM2aNeOMj48juxemOcpDC8N99z+M60mq9TpxvUw7qfH6334rYRjTasbkMgHtVsILn/9ivnjD53jfu3+f667/37QCn9rSMq7v02628NwsQUai2zF+NkMUJVx7zWcfs2T9wgfE7PwMf/zH72bdyCjve+fbOXRils9f93l+8w2vYc/ew/zZn3+Yqz74fu7e+SAAg0MjfPkL/4BOInzlEHkBQbFIjMFgyWazrBkdZqW8xO7770VIxa5dDyNdB6FA2hb1VoNEW5JWjNURQii2rhnn2PHjZDI5oFNQdh3ci0P33TUKsW6BobFRrLA4rTahNuw+dITNG9eCEWRyDkI46FiT8XMk1jI21o9JNOvXjIHj4mAJWyHFYpEN60bRWtNutoibbazsTE1fP1Jg6vBxlBIEWZ/+3h6MFKwdGWN6eo58sYCJWig/S6lUIpcZZ3FxiWKxSL0dI5wQpRT1doN1a9dzdGIaR/l4gYeJYlACTGeiThx3hsmMMejEoJOEWtgk4/i0dYxN4I577mT/vt0IA+9+z1tZWF5EejmUscRtzZ7dD4NNUI6i1dYYKcg5Hv/4T9fjK5dffskzuef+w8yvtOgtelz15/+Db37nWzz97HO59h8+z94D05yzQyI8j/se2MX5Z53F2rUBSQI/uP9BfutNb+b44QeZn51DOh4HDu2mP5/DzWWIlzSve81r2XX4AE4QcPNNN3Pn9+8Fx2VsfAOBG7C4XEJaMBmXpWqV0oMPsjAzy9lnnkuchBw9dpjtWzcSR5pSpcryXIlYt9mwYRNCKFwFVmvOOWsHvpSUa2UybpZcPkA6Pnfd/QA9gz3c9r3bieOYfH6QOKwSFHpxhGbDhtMwuozrCCwJvUGWXC5HtTxDHNUZHBojjiztsEkm8NAyw9ve+h4+9emPkAjQYUhvTw9REuN7Hk4+R61Rp6c/T7iy+uge/IIFxIkTJzoJK3/YMvrIR64m7+XZvX+C0WKGwPM4cPwosU546kWX8Omrh3ECSxS3SNBUF2cwYY3IWErlFa77u49z443fxABKWKJQ82B1BccYNmzfxvTR4zz3hS/kX2/8Co4jwDhUKiFBRpDJBdSWNUJYMgWXRlNTWlrAzWY4euhwp/BK8JWLtoaLz9qEH8L0sUOsOf0MDh09SihbLC0tUswX8OICxkRYLMZ0Li/PuB5Gg1UJ5XKJ+flFtm0/g9LSAiu1OmvHMziO07lmIQGDYWBgBMcLMMbgK9m53DyK2bJ+M2PDvQRBgAaiVovhNWOUy2VcTxGaAhlX0KjWMF7AUH+R49NzbFi/honji6zfMozwHMKwjUg6fQ8LlTZxrUrfyBBGR4TGcunLXs2W0UE+9lefoNGos/e+PQQ9Hlb6VOpNtI4x1QZtYcn1urTaVdZu3ohjXe66915yuQytMCFcaVPMBnzz5jupxAaJy4Gji7z+jW8lcCw3f/sOnGCAz1z/eYSX7fT7tC3/cOMtRM06rUabNSPD5LJZLn7hZfT1DpLxsqhAoqzGU5J81ufcc8+ibCK2Da7B9Tx27NhINYSomVBpLaOkT6VSoXziOE4mh9Hg5TPc+C9fYvsZpzNx6BhTJ2bQkcXxJRJNvRmysLDM81/0fKqVOsVsjn/9+ne49JKLGBgcItYRSWKIoyobxtdw/vnnIyTk8oPMzE7geZ1mj1KKXbv3o+tV5stlnvKU01ieLzExcRSsh5KG6vIi/f39COnSjNuIZsL3d95DpVJhbLCfxeUKSItyOp2kjvQR2kA1JLHRY5a5X4CA0GiTgHVYt27dj23dvHGcL33pAZKkyvaznsv9ByfYuD7m+n/6Iv9647/x+S9+jpGRUUykaM5OkRtZR3bTFsrLX+blL30xSBcvCGhXajQRCGHZdto25k9MUq40iLH8+79+vXO5sZYkaLJZRaItjXoFIR2EsTyw7wjPuHAHtWVFtVwB5WCjGBtpCBQyMdy9aw9aCWSrQXXfQRCKXsdFKRdtJM1mHS/IkCQJC6USA309LC00OO3sddQXW5x5xjZKdYXVmozfx9z0ImFfi8RTWKtoN5cZGBpn9+6H2b51O3Ecc9b2rdx6107O2rGNO+++nf6BQc7c3ou2EY70Sdohru/RbDZpz55AG9iwbj3okJnpOaSwnVpGVhI121z94Y+DNbzr7VeAhNryMn//t5/hKeduZcumzTzlnPO4/d+/wRW/8zYu/y9vxEQhSaDZsmYDRycmqbYtgc7QUBGBguZiG+UpHrj7IbAaqxVJKwbVmRcSR4aGgCRq01PwcfsyWCNxPIdYJywvHGF+XpBoELaJUg7WgrGWjOdjraXZamJbVerVZTCKIJfBkZDNZRGO4sjkLErE3CJgOOfTboU06yE51+fSFz2Po4d3U1mq0NSa2lyJMDI4WNasXUeYxCAFxZ4sC7MLjK7byML0FOPj4zhYqstLCBRREvPSX3kBzVqdREc0620yno/vBkzMzHHg8JfwMx79AwMszJdptVvk81mMNniuw/pN4zzrzHM5PDnFQG8/Q0NDHDp4kIH+fr57261ceOGFZLJ5Cn4Pbt4hjBd47iWXcNddd+C6LjMLiwz19OF4HstLK+R6i0RRCMkvcEDMzs7w1re9h//+Z+9kpRJz003f5h3veOeP7PPGt/0e133+X1g3to5vfv3bCDzuvOc+puanWWrWefnLXslvvfqVaG3J5nt5+O47+Is//G/IwCcyFhvW6OsboGw71/gDVJYWCeOYIa9zel78ay/h61++ESEh0jH5fB7TqhFaUDYkRrNt0xjhShsjBdJRxEn3A1KEJU4MsQVZrSOESyIVR1YWEHi0W5aEChnfwwLNsIkygtGhPoT0EF6dowcmaYWa44sVwqSOpIAWLYKggBCCSnWZZrOBr3JorQmKRbZt38rU5FGCQgYtHHRsGBlew4npRdaO14jqDdxMhpnZSc4++2yCjIOUisDNMj8/T7VVZc3QWgr5DNVqlaGhLcyXVqhVWii3UytxJdxww+fYsC7Pg7sOsq6nCMBVV13FzPEJtNQ0Wm3iMGTfocO4QtCKQhIvSy5XYH1vlt0TU5hmjAgUumVAGITWSL+IaxpoE+OoPG3TJhcbXOFhM+AYl3It4swznkZom0TVFaqVJTr9pJ13XqsTegY30DvQz96H9tNX7AxJS9np4LRJjEwSEhkRC5DCYcU1tGoxvusSKsUt3/8ejThmzdAoKEnguMTtiLH14zRqJdxslq0bhmk2WmwaH0PYkAueejbHjs8Qa83hw4cRQjA4OMrOB+7Blw6nn7GDdWvXkFiL1k36cjle+MuvYKk1j7YG5yyItcFxHCaPz3BiegpXZqjX5olay8R4XP/3n+FZz7yYO++8g3wxy0MP3M/E5CT9/UN87cbPM7tSoxAUCcOExET0ulkW5pdxXEOQL7KyMEvf4DB+T+Exy+CTOiAcxyGfafGmt7yDr9z4ZZ598bP52NV/zgUXXMBN37mZLZs2c9N3vkXWkxw9MomxnYkgrlRMHJ7DEGIyioueeSHfuPkO3nD55Xz0Y3+BEhYdaxxjaVuH0nKZKIpxHIk1ipHx9bQah1BSsH7rZg4c2E9QCPC9LP2eSxJpHM/Bj1v0DPZx9PARhJKdS9KVS08hh9Rh9xJmCAKJNZq2ArQmm8sR1jSFnoBmA3SSoK1BW4mHi7QCnRiESBjoySGsYrBfYhBI2Y9BISUMDBVIrKFYGKCnONwZCjOGHi/DvTsfwvMle/cd4IzTNiCkobenB2MMnuPi9fdhEk1poc493/8Ba9asI9ebxRbA9z16RQ+tVovFxXl8P8PSvQ+wXFlm84bNlGfmWVlZopjN4RqH8596Dq94+Va+d8sd3HDDDdx88224riAKNRkvgzACbaAdhgQZFx21cOjl0MQJXnHJc/jOHfdQN5ZO4yohshZRbxInEX6Qw1rNeLGIFS6JiVGmM308yCgOHNuLxWGoNyDWCa5yeORTrJACjWZ+fhHtJGjd+SAhqRys6ba9lQQLKjLgJLRaLUJhIYkZ7R9kYupo55J0AYtzs4yPj+Nms8zNHmVwcJjKTIm+Qo5srpfFUokMEuW5KKU6Iy3dD/GxOqQ3l0dIy8rCHCZs4LouAG7gcmJ2F4kWxDYkaWlwFHEc0WyFREmL4xOHEMKjUlmhWCwSA7d+7zZKy0s8++JngjasVCr0DY4yM18jTlrMVuo04yaB8hncuIbm4aMMDvSwvFIjV+gj73kY8Qt8LcZiqUS+2M9rXn4eK8f3IOKElVqTG278KlbHXPLcC1koLXJo4gaCjEu9IbufD6EJTUwgPS555kU0201sGLKiG/zJn3yIqBFiAknUDvE8l3Y7olAoEMZtonbIwzsfYmh0kMVKmUI7w/TiPMJCs16i3GwSZHJgE/K5AtVWk7iVUCwGOLiUq0vMlxYpZLM0K3VUzqcdhigjcQgQMsaElly+n5ZeJHADjF8km+ml1a6AFxEZQAtcV4GwCEchHYkxncljsQnxPIXrujTj7mXSSQRGIhzo6c3gup2+CWTnSsFEg8AyONBDHIfdz3kQbDt9M41anXK9Rv/wEPPzixgsSRTS1zdAvpDBGoFJYGSgn+nj+9m6/TTu2/kAu3bt5m1vfTWDI+MIR3JeeZLXv+eDOK7GGNmZ4IYmjmMUHq6ncNwAohaLC0u8+nnncuN3bsfPBQgpCK3uXIhkJYlOsI7EdQRKeMQmIok1UoEUFtcLwCb4ojNk3KyGSOF0LoBzFdAZRQgr8wAM5TrT7bVWiFggMGAlVnbmkEgkjoWw3iQ0MdlsDqUEhWyOer3C1IkJMvksS4slkijCz+Q5fuQIPb0F3MwwYbvOto0baDSbJz9+QFvTvYLTEkURBouJNDZjKZfL5PI9aBPhOIoTsyWKxTyJbnPg8H42jp8OQtOsVzBxjHAc6vUlgsBF65iw3WLD+BrG1gwjbWcm5tjoEEa3GR3tQ6kBEg3tZpPZ5XlKCwu4jmSlXMe1nQ/7CY0liX+Br8WQQrB5vI9rr/tHnvuMi/niF6/lob3HWF4p0Y5i7n/wYeLYoFsJDd1GIDrz2Q0Ypdm8eZz1m0bZuWsPkUiYn5pnamYB3wiyQYFGPelUSYWgGbcQWvGUs8/lob0PUVtaoX90hMXZuf9D3XsGWZqd932/E950Y+fu6enJCbPYiF1gF1iASKRJkaIo2RZtusqWRMv6IJvmF5dE2S65JNtFWiVZoqWSLRdLLEqkRIIyIwgCRFoBWIDYxeY8szupZ6Zz981vOsEfzu2eJasIfyBBE7eqa2Z6bt97+973POc5/+cf+NDHPsxkMOK5557DV5aoGVFby6SoGfQHtNtNahexNx4S1xalNf3RmNluCy8ki0sX2R3coixLlG4yGY0p8glOKUZlTZJE9Ec7GKOxowmd+SVGmwNyOSIWAiEKpADd6VKXDuFgrmW5cfM6K2unkSpmPBrQas2ipKS2EQpJZRwqkhgLEkur3cQURVgQQqG0Jo0TsoWUylkmZUGWZcGrIQ6mNds7BSiPK2ouXz7Jzk6LUa/mF37xX9Pptnnr6h12bt3gzsYBv/XMt5iTK2zamxR5RavVIi9zGnHC6UvnGBxUDEc9iEsSIr78xm0efPQDYAt2NrY4v7ZCXjquX7tC3AoyZqU0QlQgBHEiMDaAt84ZvNcYF7wWhTfBQEgEb8/gRmGRMsEJTyoT8B7rXSAyeR+mC5VFSY31NdZJauFROiIcOCW98ZA4nkFKRT6qWD49y8njJ7l1+xbGlIzHBTs7uwhh6A3GaCkY5BOiOKYVt/CAVgqZxszpmNlWm95kTENrPIayVOzfvIZqdtnZ64WjkWxz7c4tZlptJvkYYy1VZWg0OhTlBOFzlFDs7h8Qp3BwcIBwjrzKWZuZYzDok+cGhMUZw1y7i8k8fm6WOG1QjMbBR9RaGtl3NZPS8y9/7tMopfjx/+6/5v/8J/+En/kH/xxXTugjePDh+/jCF75Is9nC1A7wCB9k4VJ6rly7wZVrN/BI5mfnwnnWKgolIS+p6oIs7mBdRV6VzLXbXLn6JuQWn0i2Nu7ireG5bz5Lo9nGGsPiyiJDM2EwGAXiSqtBYRzWDhCVp/SWFIG3goPeCBVJmvE++IjCjKEo8VUwPxlNSqSsiHyKMyXjPBC9zrUlx7pdRNTm5vV1VpfmKWzN29c3cM7RSAx1toTSEZu7Q861WvQLx8jsg5HMd5vsHvQAQauzgNQSUw5Z9p6bN++QZcHn0xhHO5thY+sa7VaDteMnqaUi1hGVqZmMDK+++AZZqnj4gUts7w7pHexw4USHfGJ4//tO861Xn+fy0jK9uuYj7znN81/+CqcuXebuzXViqRiORmTtmMHIcvvWTZx2PPDe97K/u8dce5bxcMBHP/w4/+ZTn0JFkjTJUDqjGac4KVFRUKp6Y7FodBRYm5WpUSIC4YmjhDjWSK2Cb4RzeGsYlTmULvjOeEPWSFBx48jXtKoqkthx49otKlMgcHSaczRnZygnE6pijPcSa0YkcUIzrmkqzf7WOs1EsuNqtLXcWb/Jgw+8lytX32F2ts2xlUVubO4wGg7C0ROB8B4vBJtS4bxhd2efZrNJq5GweOwEd2/fxlUlI1uSJA185SjlAbGH0kzIrSNrNojihGbWQEyZf2UOQlaUThKlLYo8x3uBRyCcRiYgK4gih3MeV3ra7QZ17cKIWrpvuwL/TBeImZlZ1s6f4H//Bz/N733mc2xv7/LsC89Qmpq/97f/Fv/bP/0/QMSMiiHOBOeIh+5/kG89/xLKghGeKNJBUCQEVWlwsSC2kMURuW4wNz/P/sE2LdUAU/J9P/DD/ManP42zFZXXSOFQSYPZmVm2t27TGwwQKFppRlVV1FWFEIJ/9fO/wHsuneV/+ns/zStXr7GzuUXlLThPryjwdYkwwQdBRIK8qrBCIiqNakdkSZOqGHLp8lmiKOb27XXyvM/F+96Lkh4/HBG7dVCO+fkVcB6vJCstjTCOj33oA3TaXbb294l0hhUVjbjJay8/y/btXTrdLp6MZhKFGfpohJaSPD+gMzvDuDdCJSm98ZimNbTbM+T5DseXGzz2xJNcv7vJ3rU7TEYjPvu157l84Qxf/OLXSdOEp9M24JHCEXcXGfcnnDy2Ql4UZA1NXRts2WNppYmSEZsbN6i9YLI1IEbyqV+/wWhcMZjcJpYaqQVjW+FKR1RnwUxHK5wrEDLBGYvyDm8P8EoQRRatJePxkEilR7J3gcG5CJ8oEgS9UU4SDXHO4kWwums1UhqNNi3RQWrFZNRHekcUaaTWLMx26B2MUFFK14fFVOPAeJSMqWxOYQy90QjlHciY0XiAr2vGkyFZnEEUY2xOVTqEt6AkjWbM5UsXSdsd6tpy+cElmlmGkQplLXnt0dIyrh1CSDpJTBIJxuMSITUqCYWmLRUFgv4w58qV14niBucvHGP91k329veJswQhLN674FymLGV5aCEIzkbfdg2K/w/n+f9fb2dOn/b/y9//OwwmFbVvkjQSZpodGt0GK92M3/7NX+NTn/kKa8uz7O7uEkvFaNJnMnacPnWMQb/PaNDDCMnysVPcufk2MkmhdswuLtGIHLMzs9i6pjfs4T00Gg3ubN6ik7Q4mFiW2jFRs8ve3h6Zgv1xwdxcl4cefoDX39yi2xCcO3sCYQt6ZcHTX3uJpcVFhpUjjRzLcyv0xn1GoxEHO3eRXhA3W4yrik6qqesCGbVpJYqPft8nEEIz7hVcv3sVU0tMVdNoNBBKMt4bsH77CrGKGJcGpT0/+EM/xMbGFpOxYfdgm2I05pEPPolwnlF/jzdeex0dZczMN4iijP2DHSKdBh2DkBSm5pGHHqLwnvU3X6Wf1+zv77O2cpwoikgTwbHlBSyW6zfusLS4ikpiEhVUgkqH6+dwZl/X9ZFF3KEJbV3XCFWAy5hpZRyMBnh3z2quyis6sx12d3cR0mMdOFsHt2sLUoFXGi2CaXFlBdgS4xVRrMBLIuXD0cg6nBQoHToEvJwCsxoVRSgPcRwjhMc4T6T09PUG0HJ7d5PZmVmSJGZpaYm3334bU9W89/IFNm+8QzIzgxcR/fEBrbTBeGLAW+Iopl9N6CYxLrcUoqLV6OJMzrgUHDt+mqr27GzvUGlQ1AidkJCQxQWtZgenIC4klR1RW0dlEkb5EOdDoatcTdN6hsqD9XgXszDXYWZhkd7GNbqLSyA0qCY7u7fpdrts3lqHakxhA7FNS+h22+gsQRqHVJovfeGp5/6ooKo/0wUiTjO/vHoKQYmKNMoJFhcWaDQTlmZnqQzMzM3yxJPfw8njK2xtv8PP/evfRlvDpQuneOnl12k0Im7dvsvcwhK3b1zn3Noqg3FBrmLOHlvAlDWbm3eJshbj4Yil1SVuXb9GozkLWBaOLZGPxnzw8Sd4+IH38K9+6d/xiY9/iM8+/Rp60Gd4sMVWXpBECWmsAp+gnKCFYpiPiZIEhSJJI4pRzkw7JWq1yPMca0q8h6QxizAFRT5B6Ra16dMf5WQy4vz9DyCl5KXXX+T86gmi1IMPYFxVWS5duMgbb1yn0Uy4dN9lhlM1qXOO5597lrmZFs4qnHIcm58nyzJ29/eQCJrtFlKGSIGqNKRJhPMVeZ7TyFpTw2BFFGVEOsHpGi00kdJH1uqHxq11HRb0oST/0GDWe3vkI+ncFLTD422IAhDCU1uHEJ4HH3mYV557ARXHKCEoqtAu29rgBWHiUNvQhYlD3Y0IHaIKNm2SkDNS24pYxsFFGqZgbXCOEj7kkMzPz7O8tECSJAgRLOF+/Td+lWazifOC+9/7AM88+ywn1lbI8wKlNIgg+T91epW3375JGkmIMmxR0+2mOFFTFBWdmVWKieeJDz7J73/9BYpRRdxyxNJRGEeRlwzLIfWoIDcj7r94kbIsuXVni9mZJo0so7IWaQwORawFlfeMBjVl5blw9iz/8O/8TX7xM5/hytsbbG3dYVLXKATjqqCoLNLD/Pwc49GIzuwSMzMd4jhmv7dNohKGgwOEknzlC1/47iwQWaPhz9x/P62kS7ed0ul0EDjG/X3evHYDXxlQAu/h+MICq8cWOXPmDMdWlvmlT/0akyInTRrBVTjJwAypnWXYH9OdnWcyGDLTaSKVxE/NQRqJZGdnj0anTZZkvPc9l7n//nO88s1v8aXnXqPbaTPoFyA9rVaL3mCIqUryeoi0ilrHqNqSNCJm210meZ/+pCAiIs1ispkW890O3STFBISUsq6ovePa1XdQUYtmCmnSYn84op0mGFfSH9bMdjOSOMbrCGuCL+adnQ1kNMPE7rGcLnLx8n2MRj1u3bjBwvICrWYHObUtc14QxSrssnhiHSGicMpUQhCpUBAOQ4KUkH/A1fpw8QflpsHZewazf9gpvPYO5TlyozbGYEVQfwofjIHV9E8tJc6EUBwvABceSyUx0tdUzk4nOB5pFU44nLUoITHGkaQKi0biSGLNbDsjyhpUNQwGI0xVM9PKGExKVldXaDVTlIrDWPtdatRvPf8Mm5s7zCy2SERMHCtU7Mj7E4qyJm00iRSkaUqe5xSVRfkILxWzcxnOWyZVmycefQ+/9uuvsnTKUBzk9Hv7tLOMSa+kZMCAGCEKopFDJBGtVpO6Kjlx7hT9nQlJ5jE1NLIIVxtyI+gNe9S1pdFsU5cl7WYDFHzoA+/nxRdfpigKBsOcmbk2P/k3/zq//Cu/w8budpieOBes/6KU7kybfm9IHFkajRbtdpfP/85vf2cKhBBihpDsfT+BZfTjwFvArwCngRvAj3rvD6ZJ3j8L/CAwAf6q9/75b/f4cZr6pZMnEAZy60idwUYSJSRaRkFNV1UoEZFmCefOX+LFF58lVQnvubjG2ok1HvvA+/nH/+gfsbBwAmdHjEyO9horNJfPnSZSiqqqGI7HbGxtkWrJ7d0DKfwp5wAAIABJREFUlmdnyZrzFPmQg+GAfDAgabU4uXqcVqPF1Zu3GE8OwEZU+ZBmc4Y6L8hFjssNOolJpGfgPRESJQTvve8iyTQCzHp3lOFhHRgbsAzpHDhJRYmcuk0557AOvFDBdt9Ordi8ZHdzh/Z8FyU0165fobt0glMrq8gIYqUR0iJ8kAdLLZAohLR4p7ACUiSVL8Hrac7DYXfg8F6gtMd5jyTsxN778JhEIELHYE34PaSUKB2KiandkTntkcrTlUdF5dDuHqByodsQh7kYcC8HgyluMy08SkXhXbMVcaJpdNo0Gg1iEYW8EeeODAmNtUxGJSvH5hHoYM0ng6GukBCpGOfMkW1/WY3Z3z9ge3sLV4xI4iaDfMgoL5jPmog0YjAZI51nOKlYObbExNR0kgbNziqnlo/x7AsvYPMD1rf30TLs4iqOMC7EHszMzDC3vIisgwEzUtBKGyhZs3dg6fe22dzfpdNoIpyjNzFoEY5tVVkQK8nZC5cwVtI72KPRajIe5dgaqrrAK83qiXmqosA5T3+/x+nVs3z4Y9/Dpz/7u1N5eggZMnjOnTrDF373O1cgfgH4qvf+54QQMdAA/ntg33v/M0KInwJmvfd/e5rh+ROEAvE48LPe+8e/3eMnaea7y4s4LWnKCOM9J4+tcGtjg6zRCCj5cEgca7wX1A5kHWy9z124n43tdSYHIx575H088ujDfOWrXwLnyfOcg1HJxTNreB9207qs8QKuXbtJXlnAkkYZ5XjAyBfIWtFstDh3ao03bryDLwuc10gpwGsWl2bo7484fX6VV199jUceeZgsjfG148WXXwMnuP/hS0gRIaUIfgA+ODvrqVGpqWuEEuDuOT0f7s7WBsBTShnszW3YudvdGaQApYOJjZSBLXjIfzlMoxLeIVQortZaHB6BC/4USgTLOxdYhtZIpDKAPDJ0lVIe4QuBBBTcqd+dVXFYCA61MtZbJBLjwmv3SKyosVX4t/MCrQW1MXghjo4oSgiccEgv8UKBdRgfFvIhXpBGiiRJaDabobMUgrKouXXrFlGsWFpeRgpBpz3DaDRhe3ubE2urxHGM0vLIuvAwqk4pFT6P2hBF0VFBctwr5FiP0JIoivDWIhC8du0Om7dus9fbZzLcZ2It3WbK2umzfOzJDzIa9pBCh6nQZIK1juFwGN4P75F4isrSylI2dnaJYkmWNVBKURQFeZ6jtaaZJKgpsar2Qba9vrVDEgt0rcidYbbdIkkymo0WuanY3D4gjTULs/OYusAhGI8L/uMf/Y/40hefoigKnDe89corf/IFQgjRAV4Czr47Y1MI8RbwMe/9hhDiGPCU9/6SEOJfTP/+b//w/f6o54ji2C+cOIlzhsRLvAAdabJMonSTNI3RUuHRbOzucOrUKrdu3EHqmrIQVJOcRtYljh22cJw5vxZ2N2/Y2t6kmNREClqNBkvLi8w0O3zjuWcZFzkIxaXTpylrQRJBrCJUqknThFhonn3mJVozGaPhiLiRUNuIk8fnWFk+TtpqUk0OsJUlSgTSa5yxYQwnHJPKko/LMAWxBrxE4KhMDSJCYI4SpQ6LQ0iXqpAiwjiLd4Ho051fQAmPQ6KExwuFsKEYWFtPsyg9tbPEUiBFYBoKaZFWUSkT3I65lz2pEaDVveOFDDu9syHZSooYIWtqD5gwQQi5j+7wGgCYujBPv+dD1+SYApoeChMcwZ0xR/f3IihFhXchPEbc604Ou4pGMs3RiCIa7RbCeWa6If3LTVWmh6ld3c48h4lezk0xEuERPuRSKhWB9EcM0z+czyqlnI6E66OELyEkt7d2WVs7zvOvPs/1195hf28PIs0HPvgRdKSD+bDQxJEGKSjzMYkOXpGLizOY2jEZ9Sgqx9bmHivLc2zt7+NMcFEDAhsUyLIgQvRCUNcF1nqqqiBkYIf813o04cqt9cDzsAVx2qbTbNHvj5FJTJFPaMQdbGSY1RlGS8qy5q/81R/nf/67/8MfWSD+OGPOs8AO8PNCiIeA54CfBJYPF/20SCxN738cWH/Xz9+efu+PLBAAtbFUeYFLI5I4wQPdmUWEBx1HGCqEFcR4us2MqpiwemJtmvkApQ2jyDqvkEmLN197Ga8lF86e4Ud/5If59Gc+y3g0opEFTnqkUhJVU/iY48ePB6s7KfC14dlvPkOURkRJTHs2Q2rJyuoCxnqqckxRlPR6m1QbFXEjo50mSAIGIiON9SCcoqEF2azEmkZwLoolt25uMK7HR+Saw0SsCImXEuscSsXktUF6idJQ25D1KXxYpLVUCB9cp+PpxYPzOOHQXuGso5w6CIWL3yKtpFZM21gZzvIijIztdCGrqXj20KYeGQhmkprCehAG7aN3MQfdPczCeaTyeC9xBNmzQlBaQxrH5GWJ1tMcCO9D4RMCJxQqvNCjDA2AREmKokJryWQywdTBhyJL06OFLaUMaWbOUVUV3tfEcTotZKFAOG8RUkxTviRZlk07O4eUAdeCe/iKlAopFdZFvPLmW/R6+3zms5/H24rZhQ4f+f4fYLHToJElnD25xiifUOcTWjNdtu5uUdkZ4kSzuDBLlsDXn3mTGEkzkawdX6AoKpI4wWnLpLRhOiRClN7+Xg8rAwbTSjOyLKPRaGMQgKWlmtCdZX51FSEkaRKA5+3ePq+88CqqLNA48mpERkatKwqjwQv+n0/90rdd5H+cDuIx4PeBJ7333xRC/CwwAH7Cez/zrvsdeO9nhRC/A/y09/5r0+9/Efhb3vvn/tDj/g3gbwAIKR9dWF5FKYMnofaGqJ2gnMbVPsydE81is8H+cISWCXVdYY1FZzGtZhPnHA8/eB/98QGvvHKFSW/IBz70IZ579pvEUcrKsWU6maLymmtvvsX7H3mE//TH/hL//F/+PLaswIYW00pPGofEa2kNRDHOVEit0TpGS8mkKCiKMqRcOYOTKkwEGk3k1KvBOUflLOV4TFVUOGdJGw2ajS5ZE5wVOCupCYuu1oao8uAcFXKaAl6GhaokWZwghSbSGhlpTB28HNwU9zhsy6WwOBHhvIHa44VBKzXN6FDT44k8KgJh4XicrwLeADgp0MISEbJHQyG4t+Na69A63FdHUNQejD16DZWzyKlZcDHJiZIYbx01HgUIpQLLcwpSuumCDUnugmq6oyoEQpgwzkTgnSOOE7QWpGmDOA4Bxx6wVtDpdECBckHfozS0pKURVSid4lA4CxORhDwP54jjODAypWQ0GvHsSy+wvHqWd966Qqfd5ZlvPEXaaDC3uMqDjzyC1gqk57H7zrO11WNlsUur1eK5N29QFAVTrjvLS/OcW2rxyKUz/OrnvsbvfuEpPvjowzzz4is0uzNHBS6KBWkUc+bUGtJ7sixjbm6eqgrFca/Xx5QVRW0wtWE8HtNot3jz6nVWjs0y3+4yHEzotDKG45xGkvGFrz/NeDTg+NolGrEly1IajQa/99kvfkeOGCvA73vvT0///RHgp4Dz/AkdMXSc+LnFBYQS1EaQaIm0UCeKxDtqoJG1aCQCI4Jk2duAaqcqIk0bnD19EiNqbt/a5NSpVXQc8fJLrzI5OODk+fOYynL1rbdptFusrc5z/eZdzp8+Q6/XI0nDAldCUligLqisoZFlEGnOHzvG5vYdjIckyVDKE8cNvAu75+GZOgjBdDiLE+z8lRM4Bd35Oc6fPIPDEEUpk8kEBEzGE9555x3GZYGwDqVTrK1DVuO0JcZLsnYnWLpPsYHDxRoY5O9y+nUOKR0QxpRC2qAwdTFChsAZnA+gpAU4LBbTAqAkXgg04XkWFuboziywvNglSRtUpkQYhxWG/YMBOzt7nDtxgv54hI4Ur7/xNlWR4whRdxpBbQ1JkjCaTAgssoAl6YB/UjnLJz75Pbiq5kv//mmEr0HGgTI97VKA0OVEYDwhlEYI0jQlSRLySYmQARw8xFLmOykzaYRWhkhFSCdxqqI3qnn9xgE7OzvIOGE8HhM1UtbX7/D+xx7n+We/EcJziiFL586FVC4vUbHAlYInn/wgXgRdRFVVxCocNdqNhIVOi4cevY8bV+/y0fc/wM//wi/Tnk1Z39xHCMHGxh2SZpeiKLAm+FbOtlt88LEHubPd4+XXr5IkDRYWZ8nzCe1UYyvHuMwBz4njS0QyYnN3n9I57t7epN3NgGh6TRkunlimLBwvvnkLHYXUrtlWxlNf/tqf/BHDe78phFgXQlzy3r8FfBJ4ffr1V4Cfmf75m9Mf+S3gvxFC/DIBpOx/u+IAQVxkCRex9AG5L7xgRjdoNTNmZ1oMxwOMcWgcWaQRyjMpDVYWTIqS3ZcGNJsxywuL7B8MGYwn3L69SawTzi91WVpZ4djaMb72jWe4en2DVquJVBoXS+bnltnc2UVLRz2ZIKKErL1EVecU/THP718JtNWqxvfGxGlCt5Uho7Dz4AjuUdPJgNKKy++9TDNrgLcMD0a8duVNvrmzg/CC2juEk0AdFJAIhAuOVKdOrtJqtRgM+hhnub1+h6Iowu7MNOzW1UgZYa0lnkrVnXM0my3a7TZZGtFqt2k2m8EnYTJhZmYOpRTb29tID4PhkH5vD6VTPvihD+Cc48tPfQ09BTe9VhhnuXPnDg8+dD/OWLa2Nnn++RewIuAgxoEWkru3Nzh16iRSBQs9rwKo663FyYBxlHnBXLfNYDgkZBs5TDWdnEjJFz7/FLGWfPQjT7I/6fPacy9Pk6r8UYEweMrCorQILEkvmJQFWiqSqIEQnr29PbRKcb5iMMjIkpRmI7wP6+vrTIqQQapjReUsx2dbHAwKZqSkLkbsb28wGvVBN5g/sQZh0EPpDXW/oiorfvU3f4O5TpsPfc+H8UIxrgq8dRS5wVvBc8+8xvm1Jd6+9gb9KkebLJDLnMPrMDqtvcO6kCk3Ho/Z29slwrM0v8TNjU0mZQ4IDiIJLkJFFq00tYFROeHm1h6NJEWqhINBgbPFUZF/+cpdrK3QWlOWE7SO2DgYftt1/sedYjxMGHPGwDXgrxGMcD8FnARuAX/Ze78/HXP+M+AHCGPOv+a9/9a3e3wZRb67uEaiPFonFFUeshMqj04CMixURGEqvJegIXYCrEPEEi0zThyfBxyRUFy/u0ErS+l2uwjhefXFF5DEIKE7s8zG5k2SdjjbKa+R1gTvAAVRmnD/xYs0Gh1eePFFlPYoG+jOWmsiJTjY3+XUqVPgBGfOnWZxaREtFEi4deMmdzc3/8DcPYCABpiCkSa4MjvnWF1dZWlxkc3pz+zv9SjLknLK+HMutOJz84uhU1ERD9//AGVZsrOzw97BfkjbEsHbEOHQQvPIQw8yHo9ptjJefOFVpFaBuqzUVLIuWVla5sLFMzjnePpr38SrP4greBtMcP/8D30/VVXxe5//cjinKxnEckdneYnA8oHHHmU0nPDSa6/f41JMC4AxBktNtzXLZDQGGY4Sh4Cne1en4L3nEx99kspZrl+/zs0bd94FKEogKDO99yivsLIkjRKEUmjCGNdTU1pPXRkiASsLi3zogw8hVMRef0xvWHIwnPD7n/8ier5DSyj6kzF3t24QpbM0k4i5zhy98oBYKGzu6fX7qCzCCclj73uU1cVVmq2EuU6T1aU59scj7qyv05ht0dudsHqiw60rd7n2zm3Onl1h2M85d/oYV27doTaONImwQvLJJ+7nzuYW7zl9gY3du/RHNbPNBt1Oi81ej53NPrkrWJif5+svvYmwAmcFXkBJRVT5IOcWFlOELFLnDQiBtJraBY7EjTdf/+4kSkVR7DurxwCQlSOWmnECmQwafqkU3hmsDVyDNEmwvqbdyMiSiDRNGeYTlErY3N0Bq5CxoCE0W1sbnHzPWU60Fvn8s8/QiDVCCR59+Em+8fzTpCrCelg7tkiejxkVJXri0d0mTlkoPUtLc4zHJSdXjpMkjqu3N1hbWOSx9z3ItZs32NjewRtD5SwaEboEQHpz7whiPSiNFY7HH3uEIq84OOiTpCm31tfp9w/Che0cTgThj3MebwDtaTXbPP7442xtbOKV4+b19bDoD8lGQqC1JFKaR973ELUxvPzK6zjP0WgyjCU9kVKkccqTH36csix56ql/DyIAt5WDVEtq5xAy4v73nOPihXOMJxM+97nPIyQYMwWOpwUE57DCcfL4Cp1Oh42NTfYOhogpkHk4OoVpBkqSUNc1tbdgwjRCKhWUmy4UiziKqKzhw08+TjHJ2TvY5+b1GyGhzB4WExns3AVoFU+LlyLLGhzs7dHuzjC/soJD0klj9nvjqW4jKDujNKbo7XBjawvnLMZL7rz5JnGzSXtukWbapKxyhuM+XlToUhB3MiZ5QawVVelo6IxSOrQT/Lkf/ggrM3P0e3vEOuX6+iadTpO9vR5JHJEXFd//fR/hK8+8QDtJ2csVrVhx4lSXE7Ndtvd72DpmaHrMteepyzEWQzU2TOoaWVlIJHU+oSwlL964hbMWO32PlRc476lsjbI1UdKkKIpwrPSet1/7Dow5/zRuOo794vIqOZYk1minSFOFlgrhPZVQVGUV/BTrgkRqLl5+D5KM4XBAFMVsDUYMdjaZDPdJopTheIKpSmwkSQSYvKQ91+XemM4RZylVZaC2KCex0jHf7TAwNUVegFSkUgdz1WaTmXaT2XbKzu27XFhbgu4q29vrKCE5c+Y0nU4X4wxKafb3emxt3+bixctUVcXuxhY1jiRJuHljfUr2EXjvsLZGqQRjqvBBW4FVIZvUYnEe5mcXsHU95SvIKe3ZIlXIeXz/+x48Ah9ffOk1/JRnUE+1GIdMRonge7/vY9y4fpsoinj59ddCsjRgji60wJAE+A9/5Ieoywov4Hc/+wWEh0o6lCXQmoU4un+kBKdPnSBOEjY3t9nZ30EQHb0OAI8NugspabYyqtJgjAl6CqaUbmlxVuJlmMC4WiBxvP+Jx7l69SpxlHLtxnWUOBy7GlQU04gj3v/YQxgb2LKxjtjc3WNjcxs/HYtCSPMWQqCkY7s35L/8y3+RXi74p//sH6JRNDpdnnjiA8zOLOKA/+y/+E/4lU/9Im+99joH+z2GeYF2hlp68rFnsdOhMCP6gwmd9hy7e5ucXl3j+PFjRI2UcjgMpjFZlwunjhE0mJZ2ux1CfI0hzRRV6XnlynUunT5Oq9XizStvY7Rkc6ePm/JQjJEo6altiC5opDFznSZ3bu+Q1zXeOrzwKGnBhmOUMQYRKa5/J3gQfxo3FcV+dmWJWkRI6dFCcd+581hT4URGEit2t3bZPtiCsqCwNcoITCSpvccZg9QOZRRZGjF2OXbkiFSNkxHCOqKZFhQhyERHglilFNWI3PbQowjfaRGnKcrDYqfFYLjPpG4idIXAEScZC50Op9aWONjfYjQoWVEjRq1jGDypjchjS+IiKl9y8fQZ9vb7SAULC/Mc7A+4cfsOYmpcEngBIWshL2uIBLFIqE2O1hJrPQLF8dU5GmmLuzv7R0cEb2zIePAVS7PLnDy1ilKKjZ1t7t7ZRh8SjZiOOUUwTlFC84nv/SQCQ1EUfO2rX8eKewDl4RTi3Yv+L/7wnwuLTUR8+ou/h7McSZqF95jp0eCQDbkw3yVNU2bn5njuhVeOAFA4xE/CKPOwCDRbCdKHgNuyrgGN94Go1e12OX32FGkShWkOoLxDRDFVFc7cb7x+lV5vRBzHHDu2yN3bt3niiceYTCq29/t4b7lx/RYYizlUb0qF8DXNtMPJtSVoNjG2Jh8e8K3nn6MaG2aWl5mf6TLT6TK3vIyuHaKRMDrYIx8oxmXKojjOT/zk+/nwD/0HIDTWSH7ptz/PZz71c2zt7tCIEzY3N1leXkZ7gZ6dD8dLwJsKpRSl9yEcWHo8gijynFucY7bZZFyXDCYVZVXR0ILrm7uMxjleREefFwSynXMOLWFmNsPUis07dxnlI1aW50mUZlI7nn36G9+9BSJtz+G8QekYKS1xlCCdpfaCJNWUlUVZR6+qSJUlkoJJGXgCwtupuk8hVYyd9MmyYPk+sZZIJnRmGwz394jaXdxkhJIeoTNGoxFKRSzMdMk6Dfp5jrAJtiwoJgPKqiJJFPgET0GaJDz44GU2t3roOGV4sMv8wixxHFNZgcZPR5eKwhmkDb+TMYYHH7iPJEm5e2eXwehgGg84wHiHQmDxCOc5eXKNdquFTCLKcU5VGdbvbITdXSlwjvm5Oe677zLOG8qy5uVXXz9a6EyPKiHIVuNsmF78wPd9HLymNjlf/co37smlpwSsw+Ig3gUM/shf+MHgitRs8pnf/Rx4DQKSRNHqdjh+bJUkjsknI26v3+WRRx9GCEE+mRDHEQcHPZxztFotahPYi/u7Owilefudt5npLrCzsxVGxlPKdhil+jDN8SC8Qx9OWoTAesBX1FVgk3pvicoJk6SBKw2PPfYo47IKJjGRYn//Dr2DEcY69JTsoVQY+x5dg9ojvcZiGU8KpPPMdNp0Z+cQXjK3PE+iFTPdWWIFtTHUzuOtQ0hPu93CmoqyqJmUJdZ6RsM+KkkZ9g11rolUwo//9f+ch+9T6MUVXvvm8ziR8sK33uJLX/kc/V6OjB3trIuUmkIYlIdyGjMQzF+CcvUQ3zq8JhxB+1LVNd45xoM+zjua7S61t7i64urL360dhFI+abcRPlCBlYpJWkmYmVtLEiUMinxKDhJUeYWXnpoqeCLYEKHuvUXrmE7WpLaGujLEsaCwHmEmDHp9GlkLaz1FVRFFGUpbZBx8KL2tiaOUuuhR1gKbxES2DEXEOeKsQV05lKhJ0gaF8ThhefDihSnRR6Kko6ptSMzyEKtw/j5cvFEUvC6FEFy6dBGpRFB8Omg1M8q6DMVRhBFabRyvvv4maRaTJg2MMXzgscdopBlVPeGZF15Ee43QikBOdO8ahwqEUFjv+f5PfBxkAEif/sbXcA5m5ueIpEJKyczMDKaqmVuYJ45TlHRY50iT5AhHgWkXYJnOnQKgePPGHYbDPsPxiDKvjhiLh//vvaCWDuXugaDeE+jvLqgyURJsAHKFCF2G84B3YXqlgzrU2rAZAGEkO8UjDvo9uo0Oa6dO8+qVtxB1wdmz5zl27BjGGNbXbzIcDgPeoRVZkgb+g45IIn0kNEtShbOBgKW8I8syVKTRMiKa0r7Pnj3LzNwspiwQStJtt9nd3SNJElKtcbUhaqf8u1/7HX7kBz7OqMyZjIN61nqPqQOelldjTG0waLZ3e9hcsOOb3De7xD/+uz/G2fsvY1XE29dv8/xLL/Plr36FF155i7xfIJRBxzFqqjESShJHKnQoxjIaD1BKkWRNqrpACs0bLzz33VkgpFK+NZ9iRgqrS2LVQEUCZ4IWXkeWMkuISovHUkeChkgorSWLEoqyQKJpxDWDOkJLh5zkiDTCjQtUJClKsOQkcZOy9CTSkHRi6qJCqQaZggNrcOMhRBGiChZxhUiJBBhRoYeWUhmyVkbpFEuzHXpbA85dOIkVYWfSwmKNR0iPkDrQfgEjIELgXVA9Sh12+UNX7DhOUQLOnr+AwuNkjfDhfHrj9jrCCR599FFQMig2nQPnKZ2h3WgivCaOJUVV0mw2g1JSBA1GUZW04mCworWmrMbs7fY5GA4YjQeYvD7CKPz0GACBDSmmAKdSiljLcBziHvdCi7DrHra8urJUWoQdj3Del0IE85U6HJGkl1S+ngKxjiiKqE0ZvCM85HU1tWQTKCkxlX2X6MvhfEVVOlwkiX3oLLozLa5fvcXB/m7oQJzES8fa6jEWVk+EQN+9HlKXmImjmWWU1oCSaAzOKlIdoZRAJU2EcCRRRNJUQSIfxUgZ00wivIRWc4YTJ06wtDyHKSbUXlBXlihWnD42SxTHLM3PszbfZGANF1ZO8gu/9VnubO9R5yFfFOvozs1QVBVgOegNEVrifUj+FiJwPgb9XvC7dJaDgwN29vOpZidDqoTv/d5P8tD9F4lbkqVORupHfOmrT/PUN15k92BCOQ6RErfeefW7s0AIKb3MYpKoCZFD6oRIgSoMdaTRvmYiIhq+onAaYUq0lUykoRErRoMx6AipYiIvkFgmVUUkaxQpiU6pREVVFERpQiQCU9LUOaUpaHeWmAxHqEgTSYHBESvPxAVCDrXA6oSGtNS2wNaSzmKL4d6AWGj+wl/680RJjJSSbz7zDFEUxld+mvOBqRFCYYRFOI/FEsmI2lmMqdBCY7whkhHGO6y5x6m4eOksxpgQW69TtHRYgtbCOcdgMGBvbw9ThbRpKSW1N3gfpgWH59PDmxQyGMaqYOPmD8eLVh5lVEgZJNVISV2WJCqi9Pc0I+AR0h0pNoEjnMF7j8diPKQ6pnQGaT0qBluHHAvhNc4VeCEDgzXSeDN1cTKBbGa9Q0l1ZLYqRIT39dQ+TUzHyEEEBTAYj9i5u44QEVm7g7BBtGSdJm22mF+cpxz2KcpR2G1VEy+CmauUgiRugrQIV2HsoS7DECmFUBofWagEVkLsLe3uPN1mizRNAxlJJhxfW2ahO8tgMEBIx+zsLLPtBjKK2ds6oN2Zp7ZjNnf3qGuDFx5n7JGHhVKhmzPOUU8qTASpjqa4jaEsK4qyxNQ1lfO42h1hMRbPaDihKAqGw5xJnoNugxA0ui0evvwAv/Zv/sV3Z4E4ffas/x///v9KHEcopafuvWHeHm4+zL89mClnwRsXWtQpUGan3P97vIOwo3kp0Efzc3DW4rwPakc/nfl7sFOZrpJhh/cOyrLCe8fVN97g1LnzrN+4xcraMsa+y9/PBVNQO5UyOwd+2iobewjIyWmWpce7wL0/lEcf0py9U1hXsnZ8lXKUk6YJV9bXcVW436OPPXgPYyAkax/+ntY5In1Pcemdnz7XPcalwRMJiRPQUALjHUmWcuZYl9XFGZbnFhDSB37FXo/+YEDlDVUZHJmscfRGJcZU7A/zIP1WcmoGbBGE4hpEcm7aKYATIJwAwnsdx2Ec+d6zc3z8sQdIF2YwvRGj0YQDXd9QAAAgAElEQVS723v0+n12hhNGowm1c4xrx3hkqP09vURtHGoK0HlvEQKiLA3dZB0McdqpZqaTEU3p5bvDktH0aCc9oROTArxCKhAohAi7t1IqOFarafq3Aic8WsijSZEQwWw5EookcjgnaKcSJSUWQRJLpA/j2vluyDXZHwyRUnF7b0RhJbWx7zLcCaQx7w6PbhLvLd75QKYTYWMRLojPDrUw9xy9IEj3Q+HM93aIuh0sIJzHe8dP/bf/1XdErPWncjvk+CsFxv9Bg00pA5ikpeRQkeslYVf2Du0cWgR5tJoWAuPdEcob1tRU4DMd6QU/geCb4JkSiKbkJYGkFpY4jqjrmguXL2O9Y21tDSsd8dRpyVoLIkJKhafEO4VQNV4EqzepDErFRx+iEBaEwv0h0xVJzIWLi1w4doL1rQ1ujQeMx4bZLKZnJnQazfAc3uMESB++DqcUerqzH1GmRdhRlJxeeM4SibBINQLjNVJLrKm5eqdPUVTs7u3Tyhq0W7OByTnMqUtDZYKdvReSWCu8immWgpGopxyHcDED4Tmn5jHCedAK7WoajZR2K+Hc6iJoxUwj4b4LpxFKMNrYRgjB3v6AwWTM9sGYQZlja0NZh2NYM83wWPqjAicEkdbTz9WjmI5Dhaaow4i5NsFfoZ+PjnIrpJREUoYiIA+PRzKQvrwHqZEqSOGPsi6mPg/AEVYTJjwCrTRS1CRSInxNpMJOXyGnGIOgcBLHhM2+JRZTAFEKrJuCyIRiZI3DytANOSGQDpwCaz0OBzLoUqRXeOHx/t28FhiNRsEda8ohqYuaLz/9m3z8e36Unf0bdBeWaGSz33b9/RkvEOKovYJgH+4JH0rt7lVLLwVa6rCLuGDyGfngduCUQvp7DDst7smaAZju4IJwrkUS2IA+kHSOrNWkwnsTSCfO4g8tzwSIWBI7sELcM4ExgJiOLYULi0V6wlxA470Db3GoQGjBg/AopUPnIOCxi+eojeGVq++Q53mYbkzGOCHotFrEcTRd/A7pI5D19FhwqKoM0uTQUTi0jNDSM6mm8mop8LWYnukVjhpcAHyFq7m1XaOkopmMUGqDS6dP4GQAOMu6oCgdkVJ4D67yoD0LaRLci2TK7miEFIJYy1C03wVQKp1SezgY5LyUb3D/2UWyuMmNW3doJQk6idjeP+DWxg79UcmkqslrT1l6pJCUxuH9BHwQqXnrUerQRyNsEgJJogVCaIy/t6HEcXwkoT9a3EoFWr8HKcW0Ews6DyeC2Q7CTYtEuNaUUngBj55Z5uZOn4fPrNLIFM35GV54+SrrezKoWZFht0bhrUegsRYslkoInBd441FSIaUHZ9FSYlQIChIenPLgFdabUCgiddRh2Ok0CmNxQpPnA7K0w9ef+bc8+ckfQ4jQFX3mN/5v+uOC3/n0/8XKsQdYrSNmL30XFwgx9Qk8HDv9v9S9d7Bk2V3n+TnnXJP+5fOvzCvXVe29VUujFjRSN5IAIYyEXcEOEAzMAMPMLMHOxAzMwrIDC+yOYKRhhYQMCKFBEtIKgTzt1V1tq6vLdvlXz6e/mdccs3+cfK9aO9ARGywRTUZkxKuX92Vm3XvP7/zM1zi8SpIVEMjA/xxsHet3p60aXY6FQAwOhUCPDUy2L6zzHXU5Pga8XoFSEiuslxIbk5SsBWO3dmLvPh2gyPEuXlY4NCUCmXvGqQoQwmCMQrmQQmTbnxcFnithhUOEAukcwngSkdGCqYkKh/btoshHdLs9kiwFKZiYaLDR6hCGCu18ANrsJ+zfSufxHIStYOpLKoUZBwshFIZxfT7OKAIkLnTjQBJsBxNcgB1jDow19FOLIOCRo2epy5Ag0jSrdYLAMBgY+lnqadVWEkcVatUQYxxxFOIcGG1QkUIp//1ef/0OGqUyT524hHKStMiZr1Vx2kGoaA+GrF9OWGu1KXLNQFu6A+tLTCPRziCdwgof3MEL42xlBFu4Cn9W/LgzCkvj48abTXBFXm+rLIscEGxtIAI1bvyK7fJBfNN7KKWYCDSnlze4fd9OBkmCdQpXKCphzDsfuJFnnj3KdTvniJRBRg2OnjrP2fbwyj09vh+3fpZCUinF7J0pY7Ac2j2PtYLNTseLzqSGw5c2qQtolGJW+imhlD64hYK1S0t86ct/wnW3vo6zZ89z7qO/y77FQ7zpW9/m0ZPSIqQhGa3x5OMvsXL5v/e7feXjNR4gBKUoIlDe5GWrceYdMIAxCMen1eMTbXw6aa1FKkVgfU9CyAijx8In1vrdwd9VKOdrMf+iz1S8OInAWjHOLsAYxkg7icWgQv+dCBVKWbCCYCu7ERIRCJzxjL+t1M85h0B6SrO8wjVwzrF/1yQzzRppmmCtI9OWUVpQ5JrEue2xaBhGJGkfzBWK9isbjkop3BgABT7dhy369hUxFGstUqjx6waBYkvYHfCBQgDWoKQmdAHDwiB0QH+YUKlEJGmONj6oOAn9wYBwosJgpHF4XQkZRlRjibaCmw7Ms29+lnavxzW7Z3nh/Bp7F+oEcYhxAqlzNro9zq+0UVg2B6CNvcLxEHiDJIHn3Iwl5LZKLSX82PNKZiAQIvKaFUFEiMJssUDx2acYV6gqCrevxSvZsYFSMJ4ebAUHKSXCCYY2QjjBS8s9SoFmd9hEmw6VUDJYvsyt1+xl0OkSBDFCFtxwcAfXK0XSH/L1F8+Nie5sf/8oUAwNnF7tEigvabB7YZI816wP/EYzXyqTZJnXOh0HBzW+3x995PNstHqcOXYEFdS4+qqbOHPhGM76a6vTFOUiUpHwlvu/lde//k4++adbfMr//vGaDhBKSqrVkme85cbXYVKOxVS39BElOOe1/4TvMrvxgjfGjmtJAcYgw+AVgiBu+ynGWAWAcavCNxABxo1M3/Qak4YwSKEIFGjrCLbqR+VVnH3qacede4fTAjEOOkp4RQShxHZqaAqNUIo9c7PkzuBsznq/Q7+fkBV6OzAYb8eAyzJviiLtFYr3+DzAFYxBKODmq2Y5dblLYguE9qXY1jHbjVtrcUhwAUpocBFWaiQWpwVKvhKht7VYJb1hQSgVgSjG2VeMEoJmo0J72COUPgUHSLWjHAaMRpqvPHeOZDRCCB/YVts5vdFlMu3BWRGSzsjgjO8fCSWRgu1yTwqJk3D9jibFmHzV7RcMM4vF4tSVDEIAt+ybYf/CJEJJVje6vt8kBLOTE5RCwTAzDLOM6ckaT5/cpD1MsVzJGl75DIRfkOE4MIMPFmmRkxaQLHVRgSNwhqXugEbUojAGpzUZllgoquWQkRPsmZrgcj+jESk2RwWB8v6rsbCUyhXSdMjZ9YzjK5e2M2QhBOVIEIcRaZH7XohQCCWwFjY3B8xOz3N5bZNdc3s4evQxcCGnTj1HJCOIBCkFvc11/uqLX+GvvvyVV12Dr+kAAYCTaO2BRFuaiELwTWmZkFfGatswUysIAoUew5a3mINyXEM75yjyfHtXj8Y1nX7F+M+zHkCFikK7cZeb7V3Gak8YQ+cw7l4HQYizvrDZ0n7ckirbKi/KpZA8M+zdu5PzF1ZwgWTfwhRFnrPW6fpJgbFjiG1IbgzaWHJTkBd6OwAgLDcd2Mul9U26w4Fn8jkHDqqliEwbzq/3qJYVNpVop8dqVWpbq8KXUb7e9udTjQNoMMYi+M/xUxC/qzJuGMdSYV1GOSrTHxbj5i6sbg6IVYCwGQUhdjwVKjS8vLJBNYz5tlv2eXahivnGC+dpDzMfQMOYts4RWuDG/SCfJQXjTcE3EePA0BkOaY80hQl8xiQNAkstjkkL36g+NF8hwDAcDhHKayxYB61OwulLqwQSynFAURRYATM1wVStTJ4bVkZqu1QNhLzCMRlnElsljb/v2A4go1HqBWcyx1ALQqu55/o99IcjnHNMR2V0tcTDR88gpGOgJeXAZ2A+xivSXOOEF+jd3vSEzwD7md+stn6vtaYaKja7bXbumuXls8coRTX2Xr+TpS+dptaIeeTrn6UUhIyynCiIsSWHEJCb/FWX32s6QLySGm2/6WLI7R1tWzTkFaKpzjlfBliLisJxKiqIxNZYzR8bjmfaW3/jXwuIA8UoLxDWeFyg8cmyDNR4nHRF2kwIhxMxTz3+VV53z30I5zDO39xSSMRYgDZUAdVQcd2B/fR7CYMsJUn6LM412ez2WG4NWDYdj9wz1o9otR+H6vGoFHGlnPDK0pKZBkxWm6y1Q1QAxy91cFaQW4dQMNKCzPiiLIok2ni0ogCU8mmycWZcDowbl/abz22gJNpYRCAwmm1Qk3U5QkjS1DI7VWe6GnBquYW1ASiBxou7iPGY2QmHjALmG1VK5YgjZ5bZ6OVk1o9zkQqtvcyelX4UuqXCJQSE0ivJaGNJbUCa+flLGJjxlCkiiAyZc2N6u+BSN6MxSlnrjRhpn4WFgWRuokyrn+CMJIpjcusI+j2M8BtBOYwoSY3B40JCKbzWhfDlKoBkqzyzXD1XJlYBlVLMixc3cNYxUVXcvHcWi6DdHzAx2aC92adjRzSrIbftmqReqtAdFRxd6rFQL7HS7lIIRSC2rrMv016Z8W7d60oYtPUiuufPXeBjH/vPpKOcSq0GzvLQX30BISOGg4RhqumbnHJcZu/OnZw8/zIoSe0fszenEN4hCa7U6lvPVx6D2JJWV/h61NOXt8oRq8YlhgowtsArMoO13kF7+/2sd3ISQhAHCme9DH2BQYkt7IAby7GJ7axGCsPNt9+FkhGBKHjjXdexstZlbTBgZXWTAsncdIXpimcpSikprKE9yLB2RFZYD05yjjgMUarAFcIvSiWR45HkK4k4Qgi0hbTQBEFAkibkuaQRSzLtyLTAGAjUVsMN4lARC0FapBw4tIN+Z8jkZJ0jZ9YZ5rnHi4wbs3AlG0OIK03AaKxFIQVKhBgtkAH0Bwn9fkAkS+OAsxW0/U4VjMlfkRD0iowvPn0Wbf0NLkQA0mdgW1MYJ326IIQgGJdSUli0DlCBRliJoyAMJcYIpHCUQ8lsPWKmUSKKYrLUcGStSycFVfhyCEA7yWYvo1atMBxahuNNyGdIAUJJcmeIg9B7vRL4iZgDpSzK+VGnE1sTNsm5VgbOEoUjokARIIhUwNJ6n2o1ZKIU0u8laByDJKc7WqYSxWykbQoDM1UHImeuGSOMY3VY0IgEIhDsmJ7mpfMbOLwMH/jzCQFOWDCWW2++ho9JRxApNjc2qIzNj41xJNlw3D9R9LMhp869jNU5WW4Q4RXeyd/2eE0HCCkE9XJErVJirZOgrSUKrxB3fBDw/P8t/IIQcjslVsI7PIuxdiHObdfgyglsCAGOO647hNMjRKC4fHmZiYkJzl+6yErPn3zpPL7CFHr7M2Nv2MBdt9/ARqvH2dV1ZisBMox49vhpqlGZstRcvbiD9XaLiVqZ1XaPLHUM8twLpTg/HdnWqMeRFho7BllJ6TkFTkocvtdRGMfehQCtQ4zWrGz0kcoSBmWctJRlhBCwtJGgpHpFpuVIC4cRgmoU8OLFDhPlgLVzK5QDSW4Dn2kJQblcIk2z7SzJB0Z8g+YVO5hzjiAEYxV4gXv8bjeWqxN4nw/YHk8L6UhSiZUOKf0I0DqHUAaE8JOVMfioFASMspxSVCJQAd3hiCAEaxRCGaYnQ2Rm2b97J2VZYqBz2htdLm4O6Bd9T3sPSx7wJHxGIpX0uBnlCK2iUpbotPD/N6F9D0pYnPDCumEYElpv6KOkB1e5wPiRpPAYFh8Evd9IYSxWKEY4kkHO5jCHtiQ3GqeLcdNXYHEEQUqkFEoKZppVZuo1VlptKpWIfdUIrGOQpKxvdgmUGGMdPABuuhIwUwsYpYZYwX/4zf80tjAYEYYlRsOcMPQUQZykKDT1eh2XehkBoSKUdIzbOn/n4zUdIBwWo3OSgWb/rkkurPZRUrBlyPJKFKiUEpzASr+gPbvRIYNgG+u/xR2Q1mGlQwlB7Byb3VXWNwZUY39DrndXiMOyh1Mri8NhjfGKytrxhpv2s97qEocBFy6v0usnDHoJIg+BhFKgaA8HvjTIu4RhyNnLGxgz9rnQZrvhpJTadplyY4yF3cJYbDUd8Y3V3Apu2z+NE46zy6sEztusSQkKRa4tAytJRhlBEAEaCIkDzXU758is49Jml3qpzp2LC7QGPXDTnFveYFjkWKUAPy15pb7llggLfHNzc1s1SvhdVjqFdTkqcB4uzRXQltjCiIxxJx6WJlEKsJqbF+pe5PXMGgenpjjdbjPMfW8n0RqyghdeOMydt9/L7dftZOdkGeEEp5eWWWv3Wessows8zR/GSE7B5vomswvTbGNqxreMtZLN1PegBF4jY4ybRIwRk0IIbwmgvJSe7zF4ZSqjfXaH1Zw7dYTMBlx7621ePdyNkYsCnAtwjAltQeiVtJQY40d8szcQ0EuGxDiUdViT0s8doYByHLPe7VGOSowK33wPlaSbGfqFox4Z8kyyZ26RcxfPoURAObLIoE4gFN1hH2N99pxmGbVSg5EekQwHxEJQr9RfdQ2+tgPEuAGzuGeec8ubKBl7K3gsgXXs27OTzU6H7jClGgWk3tuNWHkIc2Z9E8cqH0CiIMDiqb1bcm+zk3UCIdm/e4YLS6tc3mgzWW8wHI2wugABN+xfIAoVZ5fWiUJY3dikUasyHOZeeCVUJMMOu+f3c3l9QK4LDwqyoK3AaY0Zw6ulDHAiQMmC/Ytz6GRAWhhy49js9JmcqJFkhmrZs/GWNxMvWwdctbNJOxnRHYxIEn/T5Xq8m1tHbkZcurDE3j27GQ//EMKRm4CjSy0/0kWwnmVsDs5jjD/HuTWoIEC6Lf2HVyDyRE5gBbcc3MnTL6+xNe6rRYp+WuC4Mg4EMMZ/V8M481K+8akcOKERhDiK7alQpAJK5ZizrQyzOUJIxblOz1+vMTI1cOBCx837r+LGxQlGyYBHLi6R5pZQSuLIGwlrZzDO7+Z+qOMo8j6hnPXZA54p6pz1pcQrAXPbcHwQhcHanG5nCVX45udIQ3t9jU6eoHsphw4d5KmnnyHPU+6+5x7KgaR1+gXm916LkwECKEzKxz/yfn74R36S973vt/mxf/qvqFbKOAfOauqhIjUeRdssl2iPhmANtUqVJo7cOtKkTSkQWKEpnAApsGMqAdrQ1eBMwV1veiM7DuzmA3/0QYwxZNowszBDlQpZmtOcnGZjc5W4GnLVvkMsn79ApVajOTnJow8/8Xeuwdd0gJBCUirFXFjbIJIBQ+vYv1CnWiozM1FnrdViz/w0g2RArVKmXq+PYc6G3AKFoVKrcuTUOYz2JrEKgSCkORHTH3Rw45CT5QahSkxPNuj3DAcWJ5lrOi6ubKCURBeWahRiJZzf6BJsDMfmJX5c+Y2nnqFRn0XrYnu05wTjbCdHqZDAKcCya66ElXX6nR7tbkK1EpFnBoHz/y6HDNKCwchQjQRRKSLA0uknFEVGtzPko5/4EMKEvPGNd4MKyLRBuYDF/XtRwgdCr9/glZXSIuWrDz3GW9/87Vg0WjuECLEBhEZtA6i2wGAEgnsPLaCQlMsxw9ywczqgVp7iwHydfpKhbcaTZ1qEJkOPpfGjMEAbgzK+8fnNi9BnKFuGL1s6koX1DVglItAZJnTsnqhxuT1ChuPg4hxiZoaXLneuNImdBzJleeHdvZEY7ftLWyPR2YoiRLNYrXM2Kzw4bYyatdZTvMH/TozLKdtbotfdJIrLFEXBw994ksWFnSxvdJieaqCLEWEgCCWkWvDI409Qjia5+86DPP2JJ5hd2EFQitlMNaurl3jf7//vXL68xu/8r/8zE80aczuuQwjJ93z/95EO+8zNzLHRywmV9yEZpUOSRLM2GNJZuUi5McVEs8KpE8vM7F3AZo71tRVWV9YZjHosXVoh62yy0l2jGBaEUUApDJC5dwtTYcDK6kWQinZ7k0EyYpT0uW3XHdx+6218mI/9nWvwNR0gwOFszlR9iljA3EwDqQJWWx3yXLPR64MbMFsrs9FPPGW50AxGQ9qJxuocFVzZ3eIwQgjLzESD0TBl52STrNBYoVjbbDNKc/Ks4OCeKTY7HaYmmsxOljh97hLTk3U6gwH9LGW+OUEkAi6sZdulwPmzJ4EHAUvoFFGgEMJQEpLaxBz9fp92L2dxoYnVhmGeEUeK6WaZ1Y2+F+DFoqKYVjLCGWjUIgaJpNsdeTiztTz++Nc5c/Y8NgcbDFFj/kFZCrRy3HLdNbx44jz7pmNUpcTRlzskSZ9PfeozDAY9vljAd3zH20B4oFBhQozSKOll+K+d99LrUkW0uwNKpTIvXFjnhp2zhLKEzhNePD/AGTBFyj0Hd3L03DJOe1q4tlAKHYXyKMqtUmRrRLndOxIeCi6lYqYqKQdeT0KqKS5trrPeGRE6D44S0vNxQhlh8xEiCDHWgoCRdgjj8SF2XLa5bai5pTkzSyOCck1xsGQpxVVOrHc8AE74piwAwhv3CCkhrvL0kYfYvbCbclnRmJwi1yMmKpKd81PMzx3EuYjbb76F5468hLYGKwwPP/Y0GMnOXbM8/NiTbHTaRKUJonKDWrlHbiVZbmltnmPnjr184XOfxKUFCkVpZoo3vf5O+v0EQcBDjz7E4lX7uO2GW0lzQy/RPP/cYe6bup/5hVnq9d3MzMwwUSuzsr7BH334vaSjEVffcC2nXz6HsTmbvU3mpqZpt9tUq3XSLMcVGhdoZufmefObvo0LyxdedQW+pgOE0ZrNdovDh5/n2++/h1MXRyzMNhkVlu6wx96ds6SpYTAc4pzj7OrGNpx6azy6rbCjBEo5AhyBtDSaIbGAzd6AZDPFWstkNWZpOKSdDCjHNdY6LVqbfWQgWd/skDnHo488zOvf8E9w2oOGhBhjFVKNEAk3HtpPOkzGEuZex7HX7xJIye7pCpvt7nbA0taQpKn3gRARQ20R2iAcSBHQ6eXjoBGRdHt846nHeOHoC5BbgjiAYe4brwrefOfVbLZ6nF9f4uBclfYwJ+sPCZSlPjHJ1fvneOSJC1y+fIbCCgIMVnoqtxrLyJdCx3o3Ic0lTvS8B+XAIpGcWW8xMp6bMNmIuHXfPOVGg/XVdXZPVWgnGb3cUJIBzkmPPMWzCbdGzkKK7RLGj+s8j6SdODpCeNm9oo2QkSfVCS8l55yhGjgKq3jx1Itcc83NOOHRqDIY90IMXkfCRyEfLKxjarLG8WNnsTIkigKStMdUqGjWYy61+yRJTnmijnO5L//SEXrUZ2piiihUxHEJnQ3RKkTV6jTqZXLrMGgG6QhVLmPynNm5eaqdHp1emxPnL6HiCoXoQ5JwemOTcjWms96isncnphhy4uRLdDobNCrz/It/+XPoouArjzzJ2978AP/pt/8DnVaP02ePcfO1N1COAz75yc/hpKMxWeHC2TNEUcSXvvYQeZ5z9txJtHBUG1Vam12qlRApy/S7PTY2NlElxermBvMTk6z0uyw2qwSB5Nip00xOTr3qGnxNB4hRmvGB//ohNjbWOLjvIKO8B/Ig4Ak3l9dabKk3b3Xbt1LLKy7VjMdriqv3znP2wir9fkI36XmKtZTesclaWr2CiUaJTj9jNOqitUYbh8lynPOS6Up6FibSIscoxGZZkWUpk+Umpy9cJk1HFIXms5/+LM8dfR6tA/6X//hvKQUhSZFDIbadqbJMez8JZ4gkZEVBoxrT7Q359Kc/zp4D13Ly1IvMz+zg6AvPIJVkZL2VXimusHemjjSal06f530f+yjPP3eSIrcszOzgn/3sj/Mbv/kbTJTrdLt9du/YxdkLF/j8p/6Yer3BW976ViIpcVb4Uss6cqQXtUGxZ2qSs2sdhBDkGvbMVKiogEAWnF/eIDm7jCkyNgaFZ9xKMTYRdmgBgYmwgSNA06xKNvtebFcYP+r1HltbIDfvJi58mY0qJL3+ZWq1GYQyfOQTn+N//MHvY6Y5w67JKt1+n3I5Zn008joWY7Srf/qgkVvDe9//h5TjEi+eOsFks0m9VkOIAKnAas3hZx+nsGWKYshkrc47vvudhLGiyBPW1kZcc80Bbr31NlrtdXqJ4eHDz2FNzhvueSOPPPkUKiixuGOahdkJNoMcZWPaaUqr3Wb33AJL5y/iyBn0HZNTNTbWW8zMzNBqbzIqHO/+3gf4+J98lGTYp1SpkBb3MhymTE5OccP1t/LHf/IR+p0u6+vr3HD9LVxcusSR545w6tQxqrUJNtYvs3vXVQz6bbQ1VCplls4P0CYDZZiamcXlmolKnUIPmZvxSuz33/8g8/NzVEr/iJuU6+sbJIOcXpLxmb/8LKtLy/zyv/tlVOgBTtZ5F6Wt6cSWtsOWeIm1W7ZvkiCEXqdPURRe8CMMGSWp77pLiQgklSCgnY7I87EUnBhLqEmHsF4IpVSJYQyvLsUhw2REHFa9sEekiLTiC1/7Gg8/8jgr3Q6NwMu254Wj0ENwEisKPPVjjIYzfrSJEIQq4Pf/4L2kmcMVmvW1h9CkbKy3sEGJvN9HRBVGaYqJIi5utjlz9mUe+ptHuHRhGRGFZEmfS2uX+JVf+w2iMKQ/7FCp1biwdInZhXmqk02OHzvNg28fy6ookGO0oxMaIQXCwJm1dQQBQvh0frWdAI5onAnkzhAJxeuvOcCLFy/QSsbNRymZiWG2IsmA5VZKNwGRtwjjGYLAUCkH9IYG5zSTExVcVjBRi+klOd1+n1KlRGe5T2lymkZUQqcJNal46fljHNw9RaVUYZRmzMUCTchaP8VZy+OPPcqlSxfZd+AA040mhw7uY21lE2EMTzz9HCUpkWHMtdfuJQpLZLnFFH2khH6/zUc/+hGc1VSDiNffezvJIEfnLTrtNqmrMlFrYI3m9Mun2Le4G2M1EsWpEycQFjJrWd9YpygKur0uKMV0cw5rLZ12mx2zUyzuP0ChR1SKEp/7wp+zuGc3RXdEd6XHe3/rf6O12SPcEfHoww9Tqng7wGuvv4mgHPDUE8+SDJA0afAAACAASURBVLte2HY0QmeW8+fPM0g2qdcnWFo6jbQhlUaD1nqLyUnNYOQz5DhwxKUIZzUXz5/n6Wee5IFvvf9V1+BrOkAEYcCD3/MtPPL1p/nqV/+GD/z+f2GyInFC4ogYFR4mury8zI4d82M4rqe2Ouu2CV5q3CgrjKZW99yOLEkoqzLaaAa5VxDqDFPG6xQlt/QAvJOUCCQBlqv3LzLfKNPqD71VfKAYDr16z2CY4JzgdXffzeXjx5lshkQq5tTJVaCgHEZUIsVGN0cqAVpjhKXTXuf48aMcfup5nCkoAovJNNpZ+oWlpiKczglUnanZBVrdFkHoA+Nv/fZvMegVDIoRZRWQJQX4ooF4osJ3ftd38cE/eD9F2UvMt1stDj95mFtvuZOlS6vs2bXg+SZS0CgFRAhcZEhGkJuAxVqd3/m/fp8f+qEfZ3Eqop8MGVlFUliEg8LBU2cukTvPpPWIB8OoEFzq5yzOTDA34fiJf/crmG6Xt337W3njG+7l8PMvsG/vItPlBv3El4j9lRSrBN1+QaOuOLe0wuTkLj5z+K8pCsu/f99v8uDr38KHPvYpJnfMsnfPVUxUQ44dO0alMsFjT32DIPC8mmMvvoApRTSrs+yamaDdbjHdLNNpdREm4/FvPMVEtcJwNKAUVxgOU4R0FE4zVZ0niELOnD7LKC2YrJUQGnRD0epcJtKeB3PnnXdz+qUTHLrzBspRiU6nhZVw6uxpRG5IbI+4XCZLU4y1NOplrBK8+OKLTM/USZKECxc3sRaCQHrpf1mm2WiyurpJo1Rho7VJIKpMNbtMqgZ5YWnU6pw7c4ZSFHHTjbcQxDEvnHyOWw9cixHw9PMvUBSaSqPO+tI61eYEWZZitKXXz9l39S5mZndz9NRJjp08+epr8O+zgIUQ/xL4ifFdcQTvrLUD+FNgCngG+FHnXC6EiIGPAHcAm8C7nXPnXu39iyLnd3/r97j/W+6jsDmlmqCdFBiTEoYhSil6PS8K+qu/+qssLOziB3/wXczNzvpa14EMAyYrMa1Bn/XuCIxX+n2l6o7EUqsG5PlYhNUqhllGECmUUIQOtLZU6xV0kbKRpDhnvb8GjsxJnAh49JEn+Iu//By/9K9+kZHLKROQ5SOCquL/+L33IkzBNddcz759+zh01VU453jxhRc4/MxTdPs9CpGj4jI2Sz09ulDM7ZgDm1MUjoVdCxw5cgST5+ROUo4knW4XUwiEtminCZSf6TvhaLXbfOADHwCjSHSKKiyptdx4w80cuGovJ46/xIG9CwgKoigiDgTDrKAYwo6JCVa6XZbSAcrlOEasdjSZ1exoNsi7A3ZMltlIUpJRgXKWiXJEnuXEcUw5FPRHBV95/Bv81w98COcsoyzn4Ucf4ctf/RLz8zuYnZni6EvH+df/07/h5LGXOHz4MHv27MaFimeefIrJ5jTHTp/j6kM3sW9fiY1LFV54+RL12Vm0i3nh+EnSdIgpoN2/TFSeJIpjtty967UaR196iaXVdd72Lfdz8tTz3lSoMJRkOJ4wBVjr9SMmag1sXlBkPVqmRKJHSBQrvS6lqMyEkLQ2O8RxFSktn/nrL3Lv3fdw8vQ5BqM+5VLZN8/Xe9RqNfSoIE0GGKPZsXOWlZVVfvqn/hm/9773c+LERSYqEe/8zrdz+PFvcObiCjPTVbAWEShqlTJWaGbnd7OxusGBq/bSHSTMNBoIaQlCySjLePHkMYo897gK4Snqg/6IUjnEOkdYqzBKhqAEeeHRn621Ns+m36AUVjh+9MSrr/FXgo3+PwaHXcAjwPXOuZEQ4s+AvwTeBnzKOfenQoj3A887594nhPgZ4Gbn3E8LIX4AeKdz7t2v9hlhGLip+jSqHFKvRjSbDd7ywJtpbXaYmZ1isjnNvW+4E1fAT/70v+A9/8MPs7h3D3/9+f+bX/iFXyAaG5TmeeHr4sIRRgKd+bKiKAo+/fm/5JGHH2eQpnzfO97K04eP8Pxzz0G1jBCSX/rFf878zAJWG0Kl6CcJSMdoqPnYx/+YcxcvkGnNZK3Ju773u/jaw48gpWSwfpk8HUGecXx1yDu+7+10NzaZm5nn4Ucf5frrr+fUuVMMe11K1SatTofJWp2puXnOvnyCen2Oajnkrjvu5KG/+Rt27tnLidMvMdzokNsIFQkG/Q7v+aHvJ4wkjzz0FEE5wlqNKxwaTRiVvcajqRCElpKKyV2Osoq5nTsY9Dv86Lt+gEOHFkEJymGZXj5iIqoyzBIoch5/+CHOXe6jAsfZixd44ME3s9nq0e12+c63fwfOGaQtcEqQ524b5fqZz/4Fx06dBAxJUjBMPdy3EpWZ37HA3sV9pGmPrz/0GNdee4hKHJAWliJPAUdUneDUsXNUKiFRXOMN997C8ZfP0+8lVBshaQLD0YgglGRGoEcFUTncVqCOpHeudsrrfA6GKQfmFxiMVnBGUWjjNUKRZOkQYwxxVGJ+Zoper4V2hjxzpHlGUA4oiRI7du7m6WeepFquEkaSKFKUwjKLi3s5c+EsyUabykSdNNckoyF5llGt1DwcXzk2NjvUopjGdINGHKEqFa696hqeO/o8w+GANMmpNGq0NtvcccftrCytsG/fHqy1aOeoVmroPCXNDcsrF2g2mx7/ob3J0J6dO0AKjh0/ixUFg802USOit5lQqpXIjGPX9AwqUCAFcVTCWsuff+pz/yDu3ruAJ4BbgB7wGeC9wB8DC845LYS4F/gV59yDQoi/Hv/8uPCD8BVg1r3KFwjD0C3MTBPWIhqNOkl/yOtedxfWFVTqU8xNNjnyzHO8893fy9PPPM2x48eRSK666mqef+kF/vB3fpd//e9/meWlFuVqlYN7D/BzP/eTDAYDfvU3fo0Tpy+zZ2GWPfv2c9cdd/KBj3wYRjmt0ZBDi7vROuenfuqfMj/r7f+2Mo40S/i3v/7rvPlN38bRoy/RG/SY37GT6w9cxb59e/jox/8EMRripIFsyJnljDfe/waGwyHdbpfJyUl2zs1z1aGr+eKX/4osK3AO8jxncXGRw08fpuwUB66/noOHDnhx0sLy/ItHOXXiKEG5wXA4oloOefAt38LhZ55FyQBrNOVGhX4voRxEjNIUpwQUcM1VB1nZWKI/GDE5OUmajsh1mUatzK/8u19AirFuhg1wQcHhx57kkScOc/3+fTx15AVuveVGKkXCl54/wdzMTsDR7nZpTjWZakzzutfdQ6vfJx+mhEGIjCM6rXW+9tWvk2QDSkHEjvl5lFIMBgMklnq1Rm5hqHMqoSLPHUpZZqbnqE1M89wzj1MLY7q9hH/y4Js5//IZXKjQWc7qaoswDD1pTUr6icVaQ6QCJqfqxGFEEERkRYpSiiAIiOOY2WadtcuXvHhOXlCdaII2DIuEOCzRnJyi19qgMMJLxoXxmDkZMT0/R9LdwDrLaJghhSMvHLt27aLXbeEcGOGYbs4w1ZwkyVNiJKl1JMOE2elZHFCOI5JRymg0QuuCer2OLQxG6LEzvCTPM+K4hCl8+Zprr6adau+SFcYxzljK5ao/n4HAZCPSNKVcLlNrNDFFgcZgtcU6g7MS4wzGFGgE6cCXdn/2iU/9w4jWCiF+Hvh1YAR8Efh54Ann3MHx64vAF5xzNwohXgS+3Tl3afzay8A9zrmN/9d7/hTwUwBSyjumm9Pe3r0qiIgxY8z+XbffzqWlC5RLDSYbdU6ePsnMwgIrS5eJSzGt9ggZ5MxOzVOvVajUKtx395088OC38qM/8c/p9lfB1XDGkjnHVLWGyVOCSolyuczq6ib33/dGzp0/w7/5+Z8hkIrMgHWay0sr22i9p555loMHDvDBj36S2++8ns21VdbXW8hiSD+zKDtkva+56uA+Ll5YQoqAB99yP1ftP8An/tuf8vbvfidf/+JXOHDVIb7y0FcRxpJqv6t959vfztrqBoXLsIWl1etSZIZ2u0WpFCNx/NZv/BK/+dvvZ35hmpXlTSpByKDIcdYwSjNsVCEwCaGK0WP9iU7Sp1arEYd1ppt1KnHA3EyT2akJzl1e48LFJaYbZdZaHSamF+n1OmRZjnKCxb07aa0t0+n2WNyzn263R1YUeAk92L0ww1p3SL8/QBiLCwJ+5F3vYLJa4RvPPkeaDbFWUwtLDNKUWJUoXE5RZNssW2Mzrr/2Lv7bZ/6cSqipNHey96o9nDt1nkZNkThFt7VJKAP6GZ6jMCa2RVHAjrkmRgtKpRJpulWOhmTOcd2+HZw9fQqAUqmEQqACR5oXhDLC4CiFJbTTxEFIWuSEYUggAuYXFjh75jRBVEK6DCVjT+ICTD4kiBTZKKUUBARRSG4tyGBM9XdYQoQVpEUONiUs11BWIqVBFwqHI4oiMqOxGJxTCGORyhGIgOnZOdZW1yi0/055nhOGEVoXY3ZvhFKedyHE1oYG4C35nHHjHo3AusID3qXgr//qq///i9YKISaBdwD7gQ7wSeCtf8uhWxFIvMprV37h3B8AfwAQBIErlMZamKxN09MZ8xPTrGxs0Jya5OjRl/iBn/1uPv3xLyCUIum3uPue23j2xeOUKwHDoabdvcyPv+fnefniJZ589iTv/dCHKamY0EUYPaSwAVhLp98FGXLfjTfy8KNfQxLxha9+iR/7nu9naXmdz3z2cwgH7/mxH+XM2VMcPX6G9c0NglKZl86cZWhTjh97mfW1i4RxiVpYRugRJo5RxrLe7TK/Y5Feq8NTR57n/KVL6LjKhz78YaIgRFvDIMkIncOEEUI6zp89hypVSUeG1sYpZGWWbm8NrS1JP0MKw5/82RdpNBosXV4h0pJyvcZ6f4M0gUqkMP0ORaDIsyGyJHHWEKqIUZJSMMIWKQcXZ9hsrXP3rbfy5YcOc9PNN9AfpeyIm6y0OhRpgdIpnTQnXi2xd3EPvfQ83SQl1SBUjM5TtNas9gbUSxUGg4Rqs0SWOh5/5gj9fpe33X8vn//S4xRYev11bjiwG2MF5y+u0G21GfUT4lBx+7138eyzT3HbTTeyezKgPr+LL3/9Se6790088cJjOG2pViaIAiiFil42ZDDsIpQkzQWXjCPCN6ejUgkhI9rraxQu4/TJ07z5vnvpbCzjqR6G0IVYZ8jyAUFYp9PaRAYKV23gjYAthfHYllBBrhOKLEWFlkhFhKHCRRFpv0dQDiAMiKMYPcrIC4FQIYX2QDGJ16RUYYOICBl6WHq9HJOmOWLsllWKIq/eHvlSWNsOQswRxyFSSUqlEiaQVzxFpEeyWmuJShF57vk0RVGgnSNUIYUeoIsKCI0MIo8Zsa+eIPx9mpRvBs4659YBhBCfAl4PNIUQgfO+9ruBy+PjLwGLwKVxiTEBtF79I7xISRBFLK2vEwcRy8kaDzzw7Xz5K19hmBmWzi1z7Q0HuPnWW/mLz3yRWAne8+53c37pMo1KieX1Dd7/wU/QG6X82i//DF9//GvkKieSkqwYp9V4qznnUo4ePcpGq0+tUacehXzy05+i3JzlrjtuY319nT/71Ofo9TtsrHfQKPRQkxdDAlPgREgUTdEvOgRRzCBLKes6I5FQcZL2xgrCBnRabebqswz6HQJloIi5vL7qIdJOI4YWg+PEyxdoVBRRrU6ltMC5ixcJKwElEzIkx4WKYb+DMQWyUAzR1Ay89cHvpFSr0u9lJMkIq1NybcnznFHSptsfMcwN5SBmYcc8E7UyWTFkaDy68PSpcyzML9BPejTLDVYHKc2pMgu1fZx6+WXOnz/J3oPXeYajKIgDCGXERj9n0Evpmy4EiiyD3fOznDxxhKsPXc8ffvjDzO44yPpyBxVa9PIa9RuuY3444JprDxAaRSaEV6oeZSxvnOa4CmiUlzl46BqWWqtEokLBiFKpRFFkWOWYnmwy1ZwEoxFCYQRe4r4+QWN6Aiklnc5OBAGzU1NUKxELCzsZDFLW2pexOoeRRFFCKouYmGA0SsiylIwRZQ0yDnHS0R8O2LNwAC08WK3X7pFrjRCSUmN6W7Ans4YgiMc2Cs5T06TEAoEpUGO168JAICFNh14tTDrK8difxVpMlhHEAakrURTemNc5RzpMsMLBeMSvrUEXCUpWSPPE81yE1zrdkl2UUQWtCw+px+uNBn/rvn3l8ffpQdwDfBC4C19i/BFwGLgP+PNXNClfcM79FyHEzwI3vaJJ+T3OuXe92mfEccndetsNhOUSd911N7NTU4SlMlmWYQuNxmFFgDA5RilkcQXZuNXVlTIiigSlUGKVJdKKv/jC57lw/hwrG0NCUdBLUhwFlcYEoXa0khaRqqKKgp/9xZ/h//zPH+A9P/wuer0BDz3yNXrtjCAWqLDMwf2LPP/Mi8jQIeOINC+Yq1SYaQZY7chFxqWVgt4wpVkPyXRBxYX0dcbBg3uoTk9x5tgF2p1VQkI0klAZRplhemGOWrXJhZPHETLCVgKacZleLyE0Gapc4r433kueGfZffx39QYIwjn6/SzpKGA0zn7I7S6vVYW7nLiZKUIphda2DERJtIspxyES9iRt1EZEgjiu8eOQ5IKA3LLjx+mt55rnnaE7WiGWJuZ27KIqCNM9I09RrFFhLJCMynREoRa1SIg4DllbXiUREvxgwXG9z02238Nb7Xsep42e4cORpehZ2lqpUJur0Oi2EzjFTk9QXD3n3sDNnqTUnts1+mrU6CElY8iK0WyJBSTLCOcPERJ2i8CQ/hEBGIZH0ak3g/UNNkXvZ/jynXKltW/YhBUp49aogjqhXI4RLWLt4CUHGrt0HWF5eodAJOs+JyjGuACcVUiqkCsjzFCkEtUrEKPNesaPcXwdcQBwqsjwZW0Ma4koZ6SDXY3l78FoTVoEyCBswzFsIAnbMLbLZWcMatb3zK2HQCIo8RcnYc0ms80pmcQhjnxitr+iJXNE/8VifL3/p6/9gPYhfBd6N5xU/ix957uLKmPNZ4Eecc5kQogR8FLgNnzn8gHPuzKu9/8zsrPuud76DcjkmjiPS0YgwiJiolrl0eYU0yxEUaOPZef1hNhZwkVSrFbRzxGHFoyADi5IRYaCQQUAtVuzfM48rClLj+JuvPcwLR47jQkEYlJidabBzdicPvPVb+OAffIQLa2tILEJZpHUoVWY97TJTnmSUpoRSUapWCUqSZHOTW++4jaTbwxjDqVMnsLkiqpWRNmfnjkWyImez32U00Cibe06ILQhCyQNvfYDTL58HJzhz8Tw7ZqbJrKQYJLQ3e1AMcZGiOTnLO975veQ6ZdQfUFiDMzmdXt8LuyQF6+0uozSjFJeYbEb0uhkFimzYZ252jvn5BVrr61RrZWqVmGG/y8mzpxmOLPsWd7O80SYd9JmeaLDRT2jW6txxx61QaAYmw2lQysvsWePITc4wNzijkUEIukBrx0SjBsCJY0foZ4ZA5zTnZjl15hw37l1kKh+hBCihES7A69wYZBChmtPEu/ZgyhWKfsbFSxdYWJjBCklZBaggRMWh1wOx3rOzPxqijaHQvnEYqRDrNNo6Lxwjxx4UUnqNSwHSSUQACl9yeLVri8tbOGuZm9vB0vLL6KKgyHIqlTqF0SgliQPvh1muVGi1ushYUg5CirzAOkMclxEIrLCkoyHWOKqVMuWoTKY1UkUUJkNiUYGk3x9Sq1XJc02aGfJ0xNXX3shguElnfYMkHaKCEOFCypUQnStUIDyb1QYEoaHQOcZIr1+ZptuiGIX1jm5COArjePShR/9xOmuFUeRmZ7xWo4piRkVGUVhkmiHDiheCkQUiqjJKM6S1KKmRUUygLAKFLEKGaKLQe3OiIS5HJFnKwsJuhqMhc3MLzC/MMFWfYOeOWR5/7BFuufV2vvCVL3Hu7CpCKSKlqZUnUNZQiJRcSx8wghBiRd5OfLo7M0G33eGOW+/wu7cWPP3U0zg0+w8skmeaJElozsySDgco5c14rYgJQ9A4SHPPFI0q5J0OjZkmm60N8iJEhRCP0ZhShXzHd7+T/jBh2B+AdfQGfapxicVdTZ5+9jhTc/O0NtrUShGzk5NstDrMzDc5d3aZqFL2xi9jOnyv00UWfSZ37OapJ5+mVKohRYG2ml43IaqWedf3vosTp1/2ZrDOUSqVGA5HeGkerxCFtd6fxFq0AKGNv5kJ6XUuobVmenKKc5eWaEQlbCApK0FpeoJ6u0fgUsoocBpFiFTjul1YiqIgjitklRrV3YuoWg2lIlY2/p/23izIkuu87/ydLTPvVms3GtV7A90NAiBEEAQXiRJNkRS4BIegQ7aCDk+YY8nB8Fjj2R7GZOhBMU8TGk+MHZ7wWGZ4NJZnZEm2bInUSkIQKY1JcQFA7OgNaAC9oau69rr35nKWeThZ1UUSRYpEd6Nhnl9Exs17Mm+dzKzML8/5zne+/wLlaMT07hkGeY9Op4POFGdffmXbjFLR5iRtA+e8Z+PKKqsb69x+/ACzgwFVPWJYb9AxE5w/d5aDe/cyNTXBpYsXyUzB8uoSF5Yu09ExwU6/N8mwHNPrddC6oJMZ7rjzHrpFxje++f8xGpVMTU2wNhxtjaaU44rcaKTp08kCw3JMsA6dZzRNQ0dKom4fjEYl5dgRjOLgngOU5WWq0jIeVzTekWUZmcxxQlJ5y2SnR90MY/RuXQOSqcEEzjkaq/HWYtvo48XFZZyznHzu9BtTWSszhsNHb2dc1dSjMcP1NTbKCq8MwlaMQ8CioBySA1Y6jDY0NpD1Z8g6GUWny5QXrM4vMNxYx2jJWhXohiGnnz9BNytYXljghecNymQUWYe3vf0+sl6Pn/vrD/LnX/4KTz35HNbDlbVlCmno9DtIv4bOMoZryyAkLjMYG1hZWCU4h8PhPHHadavkXZYlmeni2aAerqE1WBvDxYsCjDJU4zHZoIO1OVpr9PQkpW3Yv+/Q1UxawlOVFd5Llq4sMujm7Du4n7WxZdDp43zNwkrJ7O455hcW6HUKysry548+Tl/DxcVJBl3J6vIGw+EYZJQbrEvL/rkZGmu558fujrkRwtUM0VIr7n/LnawsrfLSxUsQAisb61F3JARq55C+JteGUVW1syWh9Baqmne8/V5kOcfXHnuMhYUFvA+s24pB3qd0FR3rebmsyYxnymTsahReWqz1ZJnCB8Hi5Cz99WV6I0956tmYFEgF8k7B1Nxh8rxP0Jr1tUXuvOsOHn7oy0xMTnLwttvpdTOmBh0mJ3oI73nqyWd59uVTlNU6l8+9iAV6PUFH99h3eI4D+/dRlxXeCu67717Whxuol3XbnO9Q1yVV1ZArSXAOZRzL6xVz07dy5uXnqGtHbR14QSZzalfFtIQykOUZgzwwGllsE9/2us2PWnUz1peXIAgmB12Kfs6wqul2O1yeb6ibcXRAWkvjLLIQlHWNkFCp+MKvqgrnAkWRsTZcQwhFWcLa2jqj8biNAQl01Pc2ATd1C0JpHXq9DJXlYIdI0WNoG4wS9LsDhvUILQ22sUzPzsSsRtRRBcmr6IixlsXROq6B3AWcDxS6wuk+t+zdx4Wz5xjVGyhl6Isa5yWuP0HXBXrT0+w9coC3v/lNdPOc/+P//CwuaPLCI4OM03QHPSo7ppN3cBaqSkJecfTg7UjpCFbwxFPP0JQlc3OzgMc3CpVl0IwZjWoq4t8TrqaWEi0DWhuQmu4gox57ukURsyo7C9rQ+BIZDG9681vIpObO43t55NGnGUxOcurM8zS1IzOxGbm0OI9A0ekNsN5RliNEkBQmUJcN3UEX5TPyjmR2dpbGXc14bZBRfKjN7fmLv/BfcvqFC3zp4S9x++13EIyPgWhVw0sXLjM7OcmJc6/Q0JA1sQUxWh9y7713sH5lmSoEytGYhhrlJUsLi6AMS+urZEZTDsfsO3gEW63QN12sK1FFzoHlIV5bgvBkvS7Dzi6ClEysLqMne5gxrG4sxG6NaBj3d3Pve96NNj1+/08+T8d0OXH6NEIIJicnOXboMEJ6TAbDWnL6xPPgx0xMTVOOKm47fowjB/cyf/Ipfuz+n2Bi92wcyt2W42KzT785lLo9mfHmcyWEYDyK0/mXFxcJXrG+sdw+wHHkat+hwwzXrrC6vo5RirWNDaTKCd5z6OBtzM7O0FOCJ54+xXq1RhYa1uuaEBRTU32kzNDGMBoOUSoqc42bBmEluuhSaMm4DnQmurx49jxvfsuPs7YxT0dP4JTgj//Dv31jdjGUVqHT6UfJPV/HfmQUo0B2O3Ee/qjCCkFnskMmFJmJMxOllBiVIbXY6m8pLaJOphCcfuF5MmGovUXXnv0HD2CFZGn+ZZrG4Nw6ve4Eo40RRW/A9K5ZPvCBn+bkM09z7sJFxsMNnNcgSoZ1idJ9ujYw9paxrcl0hrdDaqvJQ0VDxm3HbgfZQB2TyWxNTQ4xUMo0hlpZ/GYWY6kItsFoSVM7lMrJix69bpS3m5ocYHHsu3UXJ547g5Y6qlgphcri0Gk5qhg3NSZYymYYDZEw1HVFkIHJ/iRluYG1ntndezAyoJXZaqlsKpuFEBjXsPeWOd553z1MdAre9+H38dEHf47jx49x+fIVOp1pgg6cfPJZdu/bxdLSMnfeeSd3HzvGC+de4sKlBVSWodwYABEkLtSsLm+wvDZk1+5ptI7p4LAl1uT0tURYhx6v42bmuDWMefbSCutNjbCtbGI/48P79hGCY7i6hsexNjHg7e/9SR595EkaGzOEnz93ntX1NYTq0OtKqrURMsuZ2bOXcn2Ft953D7YsefyJ5ygm+rz9vh/jyotnec8DP/NtamwxxD+GU3vvt9LPbxrVzeQX243EZraqsJn8pl3fNDCj0Yjl5WX6/T7PnHiOg/v2M9Ef0J8YsLGxweXLlwnWsbS6QtbtcGVxnpWlZfbcugsZBMYb6HawTcXGaJWO7tPfNcORw8epRhVXVtYwRU7ZxNGspmlwNuDqiq/82R+9QQ2EMUHnXQaZpqnXqVUHrTWicczN7WZxcYnxyFJ0LDO37o/9tWEFQpIVBqViBJw0UWuRu/ICkQAAH0tJREFUJrCxsUYoAouvbJC1OdGaUUlncsA4WAonEfWQztRugswYLV2moYYMfF2g85JOsYsHP/YRnjvxFM+fucDeuVneef/bKasRJ86cpl8UvHjmJK8sWdRomT1vuh2ExYcMHQTBx+njLsBmTomOLliv4kPrnaejMjr9DpmSDMcNQhh6/T7DckxRdLA2TrHOVfTYj4VEOI8mMF5dZTwcIfKo3dntFdjGU9eWuqkQgMk1ogmUTU0mc8b1kN5Ej8luH2Py2F9ufSIdk/G+n/4J/v3vfJEHP/5hMuE58/xFfKgpBrdw8uRzXLl0mfVmGTkO1NmQ6dnbeOvdMww3JrhwaR5rLYNOweraIoOpPuXKCl518DYwHA9ZW59Hqx5GaaZnJ9g/N8fiwiUuLY2Y6nUQ7Th/XzScXFxGVCXWW1StaEyGFooDh3dxj8pZWVlhOFAcnsl57Owi/VsPUNWWbrfPlYVVXnrpNP2pAaPVgOoL5iYnmJicZDA1y4snnub4xICNRnByuM7cnlv52Z/9m5SrlzHmqoDvpvp2nuff1bKQQiKk2JJU2PxNaCe0VVWDUldnIZdlSScv4qTA1phYa1HKUHvHyRPnKMshw+GQg4dupSgM3gtUXiBkIKsFlxeXuDh/ntuP3QmAdZqlUcnBicBLV0bUdY2rAiNXb7VexuMxmYInv/GXb0wDoZUMpjuDdms00pBZhSsaGjS37tnDysIauAaKgqkJQxMk4+GIcjjC5B2MVwzDiK7pMC4dnYyYNFRKKluRmS61DTTVCGUtKssRypJ3duMZsz4qmRhMkmvDlVdeRKkMgcKFgNYgTMY9d9/N8sICx950BNcE1tZWuXDhHATJ2qhmY36BQ8cOYEOFtxoXPFpZRusOU3gsGtuEmGJdSyoLKgRUlnHwyCHmJm7lG089HuPuA20k3hhPoBzWvO1tx1m9dIn59RolNa+88jJ105ALg8sUhYZxE8i8ZSQyplTGeFwRZMloVNLNumSdPrLQFJmkozO01luOy6A0H3nfT/Hwl77KS6/MMzUxSaY0c/v30St66FxSlmOGwxgNWdeWuk3R7xuHI2Ck5NKFSzQ2hg3nheK22w+wPL9MU1bUIk6JNwKsrdioHMFpfvonfoy6bHjx3HlWh0OGTclbbn8TjzzyLSZ2TSKVwXnAjVgZrqNlj6P9Afu6GnKF3WiYZ4UlpqiGFU2oaCrH9MwEBw7sZ2l5Bbu0yB4pcMJwYuEKvekp+iYnm5zm4z/3CR79+ld59sQz/OzHPrKVkg+u6nUAMeRbRNlFiK3DzURFcS5Q/W1CTyCR8moOk03fUox8jF0UqSxf/sqzXFm8xNzcHHtuncXVgU6vR57nrC0vcPLkSS5eWmD/vl04K9k9t5e1pWVqJbnztiO8Mr9BTU1Ve2wZDUNd11T1kMmZaRYvLzMcrnPx7Mk3qIHQOvR6g5gpSDhc7XBG4KWmozTBVYw9ZCFmjPJCQGMJSqNlhq+HCFNQl2PyLMOKhl5eUNsR1ivIFKLxBFdHmXiRkzWWot+jEgFVew4cvR2jFM8+9VibdLYAtwHorZvFGEUoPaLI6Xa7TM7MkmeSEODo0eOcPvEEWitwsDZcYzwe0+l36BV9cIL1ah3XOLqdDkVRtDeRY35hkVv3HW2VsBpqbxmPYvO8tg3GS7oZmP6AIuvw4tkzlDVMTyhuOXCE86dPEVO0SIwIVB6qypIJEEYhMkmRd9FKYnQPowWZMag2D4Yxhgd+5n08/KdfxhN4+cJlurkhyDik5xuLa7M43X38MIcO7MN6QeFLfudP/xNKGgRuK79GMx5hspyZ6SkAuoMu1XiIs4LaO+qmwUjQwtE4iw+aajzCC8XIOkJTIlVOt5MjpYhGzDkyOaA0NetLi9z/1rdw9PjbmF+4wre+8TX2+xVesjmmqdk3pfEWltYDC65kbno369Kyb3qGvYcPUQx2M9EV/OEffZGFy1eY3DVNoSTveMe97N2zl1OnTkUVq04XV9UIBE4H7r///m35PK+KQ2+2KKy1WwZl856pnSVTcXLdJsZE0WMPfPPxp7nj9kOgNFJq6soxrErOnDrFwduP4qqGTkfwl3/xn3jLPXczNTvDmXML9PIOtXN0Ms3aqCTYmoWlJUZVSd7vsnJpGXxNt6PxQaEkPPPE42/MUQzvPZWz5DJn2GyQhQLrBVKWNJUh6IauKoCA9YpCSEolcTZGGXaLHhsMt7Q4rTcMxzVed5B4MusI0iCDYFzWCFFRO0dXD8A5xr4iywyLF16BoNFeEBjj5SBG32UZtlkn2BxlBE21RlOtMxqtUtv4tpg/d56Shn1zu/BS0+32KDpdBK0PAhgNh1TDmo4osNq2mbg9Bw4d55knHsM7zQMf+QhZf4LDe2f53Od/H6Ek/UEHo3OCkVx6+TyCwFRP09Gal0+fYmJiklcuXqLTK6i8w9oxJu9RBI3sx2FHSY6RDiEtipgqX0iFQvHA+36SP33oS7HVIyWzU9Osrq4jZMnIxgCsEByGTc8+SNeg8w62rihtzKXZyTLKuqbQhuXhOnm3QHdy/MaIt73lHh5/6mkyEYOU6romZAUOqCuLVoa1cUVtGgYmwzeeoKOM4h2HDlJvrHNxeZ2CgjCY4blnXuDMuUtMdif4b//hp/gn/+R/YdVWDFTGOQu57FEcnOaD972Luw72+X9/70+44847KbSiHK0wv1ZzeWWZmd2THNh3C0Yoet0BtbUcPXoUaUALHVtZUiKkjBKLbSvAqKi1GgTkSlPapu1e+G9rfUR9FYCrEn7exwxof/nI0/Snpjl/ZURhFEpKbpko2HANbzp+FLRiaX2F1cWSd7/zHTghubg8RBuDzmtmsi7LK2sUzZDT51fpTuSsjkZMW0eRS4zpooREme/M7P3d3NQtCKlUyLRGZxKddRgPR8jcINAUBjacIxc5hckYlaMYYisyghpHAyItkoD0AqcCucpwrsLKAm+HFEWf2lXYsiRXWYwEFIKgJarxHLv7LgSKZx97FGEcRhZUdhido87SywdgJbVrkNogZUnIe3jr6BeaoVV0s4ymbiiymoN7D0RDVVYEKTAmi4I8vtXBdjUuCKyFjXKD9fUhG8tDZCGZmZhiZmqG088/j/SBoCXvf+BDnHj6SWpXYjdqvFSoXCFabdD9B/dx4vRLaF/FLpcISJ0hpUfqHkY4dC7RGKTRSNG+/aTg4x/+Gf7ki1+OymLB431gfmmVwwcOs3DlEhcuXMI7j5YKaQxluYbRA6pmRKeTx/53CEihYuav3DCYnEYgcc06hhxlJEIo3nznMbq9Ho8+9hjCZPiqieLHVcPYR4fvuK6wVoOv6PS67L11EuUC1sfcpauLFbURLC0tsfvWGUalpRCK+975Xvbtv4UXX36Zpx97lLouWV9dw6PwrqLbLXjwv/gozgfOn7vM82dOMjMxYNjUXDg/z9yeW5ndPcPBA/uQJsoyIjzTUwO00nQyHRWvREzTH9XRsqh92soveELsfkix9V0IsRXJeNWZCc+cepH5+TWOHz3AuHGM6oa6uppKcctZ2gopBVdTW89k4dg9u4uVtTGPnz7DnYeP8LVHH0PJqGvrvaA/0eOWiT6j2jMzkSN1QVXX/OHnr8N07xuBlCpMdvt4JQnNiCbrYXBkeZ/heBHbKDqdDGclQjWEYCALOOtwjUMbg3QBgkEIR1WXyNzQ0ZraS7wxsLZInhWUrgKfk2nBoYNHmdo9yzcf+SqFCGA9Iw1d2cWHmhqLKCWyo7FVDK31SHKvaAQE6cFX6HyC0ARccEjtObx/D4uLa4zqqp3gtEYInkIXOOHigy26jMsNNJ6jx+7k4sWLuMaSGcXK+hq3zB1muDLPxkaJ7ghumdvFcATG1+isj8wNkxPTLF+cZ314iSLPsSInUzkmL5C005+VwmRdRPAoLWjI6WUxM/X73/9+/vTP/myrH70pAoN1rKysMFobMQpQCE1/eoI9u2eYnp7F1g3j0lI5uxX8M1rbYHFjlSxIrK3AKCYmZwmiRrpAJ+u1atgNP/WTP8VXv/51qjZTWImj8ILSeQQO2QRKb2lc4K13H0E2ApH1sXaDs6dfYlUZnK3JKsftx49waXGBhVcWUHmObUp8UKAN1foaMzO7cc0QoXKmJwfgPK+sDvHlKoU01MEizYCJrkFpQZ5n5NKADuRZn4nJDrk2eBSDwYBbbrkFLePMTqMU3W4RU+mLmFZwU181KtNHZS25qYcqNodMNQ995VHuPLSHsoG1ssQ1mnFdRa1OAra9H4WSHLt1hgsLl9m7e5pnT5/FygyJ5PLCZRSxyyKlpFMUIAM6K+gXOb2OocgNa6sjai/4kz/43BvVQMjQ7XajDkHWjTPQbI3RORuhoZsprANfVQgMIoMgJNoYqqoikw4hNa62qN4Eu6ZnW03DwOLaKsP1eVwZ9SikzOK8DgJdrRiNVvAyRgEo3aFyVdTnlJZcDmLTMjQEb/EIjK1wQYOQdILFG0PpKrqmhxIBl0lmB9Ocv3wp5m3UCu1BKIl3gkZUUCsyYVADgQPcCGywHDlyhFwETr3wPHgFrsLpDCMk/dk+oypgx5aZwlMHgy46SJ1RjtYQMk4VzvMcYxRaCbSKvw3td4hDce959/0MJmf44kNfAohzFNru2aYzbTjcoKk9I1sj6pLhuJ0HUBCTlwiBCTUEA7nGDsdIocm7BluWjIxirj+FNB26uUArgfOgsqhn+d6fehtf/NJX8NYTfPu2DJYmeKy1ZEpjQ4MG/uYH3sMf/vmj6NzghWB5fhUnG0bjko2RpzCe6T17EC6AjE5EHyxKCKrasb5xBTv2uCAQQRCEp9/L6E72WLq8xN69c3S6PZSUZJlBBjBZhnU1NDFXaW9yin7Roawbik6O8AKkRIl2Grhz7Nq1K04tV7FrEQIMegWZ0jHBTwh4ITlz9gUWNzx2bLmyeIVuv4fMCqSIczO2+zC8tOzq9WmaMbv37OEvHnmcrhBYLEWW08lypGqNm8lASbSQW7qrUeksKp/98efesAZChEIVhEyQGYHodXHjin6noK40QQVKWzHVn6Tb7cWkK75m+coK0pVUXiCCJS8MztUwUtSywmJRvoiBOXWNVq3u4tiCFtF56QUiB+kCZWgo1AApAtYQnXwBmtqhpWdUV2jZwYcaN6rRmcY3dQzD9gK0JDNdRBiTd3rkRRzumuh16RqDdZqyGjIajVgaQV0PMZlmdWkN2aakP3z0dqyLsvIvvHCWf/gPfpFvPfEEJ587ETM41xYjCxplYwBXt4P3NUZLlDJxHoqI+QaklFgRE84qHYfgPvjBD/DCyVOcOvvS1ZtwM4JSaLyMkoGuzSnR6RQIaeh2C4zK8Cow6HSRMooOLywtsrG6ig2B4coGpbRQNkiTERpHZ6KLCQptZIzY3KZm/aG/9m5+/6EvR+m6xqKUwlm7JalX1iOcF7z5TYcpROCZU+fodQoWRzWuqiFonB9T2oap/oAQXHSENjVVWXPnvfcyXF9jdX0NTGDh3BJaOjKlyFRgqme4uOY5dGAfSil6nQJ0FMzVMj5kRsSRiEwqaDM0Bee3HuLNIKrYlTQoaZDxRLHWbm0vig79fh8hBI0PnLu8TD2OSV/OnH0hRqlKjRZxslegudqqc45uZmisQ5kCoyDLo29kc2Rl03m6OaISZ3FGJ/TmsOsf/d7vvVENhAp5plA647ajhyidYW20jg6etbVFxEjgWGNoOygZyJRGmIDykqYBqR2VkEih6YSSsonTbK3XeBfICkszigk7hAItc5oGskzEt7xQjKshg9kpQu0xriYruqyIGrvRoIoMvT7Ed/tkUrBc1uRtEJBrPHmeM64alHBoBwhJb7aLy/tkTUOlILMCqQ3WVdSAEprgxuACeWeC48eP842v/iUze6aYntjF5dUNFi+dQwZPJhTF9ATaa7SUuGBZDWNmupOovEAGTy4FqDyGAwsf38ASOkYx6M8wu2uaPM/jW0YLtJZoqVDKbN1YBoWTASE1b7nrTl68cJZy7GlsbPpvH6rbFKxx3m8ZGNumpe8YQ5ZlLC0tRaV122CRUU2rlSYsbYOvS4zKWF5f5dLlK1TDDbJWfnAYLNY2NOMYz3HPm27DesfTz19Bi4C2FWPnWR+tkZku5XAj5sCYmsXYEbLI0KVi2IEMh10PSFkxdg2q0UxO5FxZX+PA/uNkBjpFgVICo+ODlucxq3mWmatDlziMVNFAEBXjo+6o2Aqkqus6+ieUYFR7VPsAb8Y8CCHYJXLkgaO8cvk83ULx3LOnwfQo6iXWgoZWPEmGgAgCJ0F4Tx0cvawgyzKKTraVr9VLQbalQdIeaysqFERsRTjv+eLvv2F9EDJkhYnTWL0H77E4wGNUEQWZG0cNMaw4OKrGIYwmWIFUFiUNjY1dAaM7lKMNdMcQ7Kb0momBSf0Bk8JwebyOtA3S5ARpweXga6RUaBkDTaQpyKWjqSVNVVH0FI3IyaRnWLXy70LjXI22GZYSh0B4x+TENLqfE4Kk8TVCFrhyhDayTWHmEGg8NcELsJ710TpK5gxmB6wvxCzIInicC+ya2w1BYnSGVKId3Si449jxOLvQZAijMUajhUJohRBgTLb1QGetTmXsfYV2PovDaL21j7W2jaqU8Y0lZfufCORSRTk/D7irw3tSCEL7WbcSBLRTqwUxExQ2SgTGmaBN+7DIraTCIniEjU5SJwNNbbEiUFZxshLWIazjmdNnWF1dJwjDsF6jGwzL4w36ylEbw1S3INcdbHBcWlgkzwxG92jawKFcBko0PSXp9TsYren2Juh0uijpybIsDl1KidEaKQVam+h09J5evwuBresUQgxgK8uSbrcbDYWMfoHNfTZbG66xTMzMsveW/fR3z/LK/AJXLl3GC0vtFdMdw9OnzqCExvqG4AW2qRBStxOyYr2OEK+sc0xMTDAYDJicLAhB4nw04sYYaKeDb3Ydv/DGNRAqKBU1LUINCIETUQ05qABe4ELsQxpp0UHReAPC4UMVZ+6hWiebRHsZJ1Apx8cffJDnzy2gCs25M89z+6HDnDj1LYbLlk4W8yRqrfG1RfUUwQd8rQkiDmtpEd8MzltEcOhsQOMCSgSkcjRVTcdIhi7mBGx15dC9HlMTOYXpUNcOhWWMBlshMSADwQmsHCOsoFwdxVET77aa73MHD3D5lYvQBD7+sx9BmS6y7WvG1P9h6y3iXIxnyJQGJVtxmrDVjeiZHBcc3W7UmZC5xlfxZlMqajsKIciIcgJb8nYhYLIM33rXY6CPw7lN0d+oQxp9mw4ZQkycIqOa1qbgkRPQ73TZWF+PyVmtJRCddqo9xs0HyvoahwHXREVVF41HY0vwgrFrkN5TtnodK8Mx3/jqw2jTR2cqTjvv5rw4v4z04NG4sIYmR+uMWkTVtZmpabQUdLIemVSoTh5Ha9ps2dbVW+e8WRaCRwcZR8CUxNdRwFlrHbVVgozOSmuR+GhMZUC1OqV2OKbpTxAaaLwlU5LaRgeyqx1KglcCIyR79+5i8coqq6MNfBWvv3UB6+qt0O3axfgKHwQyaAaTGbfumqXIu1TW4TcV56TgD3/3DdrFEELcvAeXSPznw44GQr5aYSKRSEAyEIlE4nuQDEQikdiRZCASicSOJAORSCR2JBmIRCKxI8lAJBKJHUkGIpFI7Mj3NRBCiF8TQsy34rubZTNCiIeEEKfbz+m2XAgh/pkQ4owQ4kkhxH3bfvPJdv/TQohPXp/TSSQS15K/SgviXwMf+o6yTwMPhxCOAQ+33yGK9x5rl08B/wKiQQF+GXgn8A7glzeNSiKRuHn5vgYihPAXfLfI7oPAr7frvw58fFv5vwmRrxGFfOeADwIPhRCWQgjLwEN8t9FJJBI3GT9sTso9IYRLACGES0KIW9ryfcC5bfudb8t2Kv8uhBCfIrY+EonE68y1Tlr7ahkww/co/+7CED4LfBbSZK1E4vXmhx3FuNx2HWg/59vy88CBbfvtBy5+j/JEInET88MaiM8DmyMRnwQ+t63877SjGe8CVtuuyBeAB4QQ061z8oG2LJFI3MxsZpXZaQF+E7gENMSWwC8As8TRi9Pt50y7rwD+OfA88BRw/7a/8/PAmXb5u9+v3vY3IS1pSct1Xx7Z6RlMCWMSiURKGJNIJH5wkoFIJBI7kgxEIpHYkWQgEonEjiQDkUgkdiQZiEQisSPJQCQSiR1JBiKRSOxIMhCJRGJHkoFIJBI7kgxEIpHYkWQgEonEjiQDkUgkdiQZiEQisSPJQCQSiR1JBiKRSOxIMhCJRGJHkoFIJBI7kgxEIpHYkWQgEonEjiQDkUgkdiQZiEQisSPJQCQSiR35vgZCCPFrQoh5IcTT28r+sRDihBDiSSHE7wohprZt+4wQ4owQ4qQQ4oPbyj/Ulp0RQnz62p9KIpG45vwV1K3eA9wHPL2t7AFAt+u/AvxKu34X8ASQA0eICluqXZ4HbgOydp+7krJWWtJyUyw7Kmt93xZECOEvgKXvKPtiCMG2X79GFOMFeBD4rRBCFUI4S5TZe0e7nAkhvBBCqIHfavdNJBI3MdfCB/HzwB+36/uAc9u2nW/LdipPJBI3Mfq1/FgI8UuABX5js+hVdgu8uiEKO/zNTwGfei3HlUgkrg0/tIEQQnwS+Cjw/nBVAfg8cGDbbvuBi+36TuXfRgjhs8Bn2zpe1YgkEokbww/VxRBCfAj4R8DHQgijbZs+D3xCCJELIY4Ax4BvAN8EjgkhjgghMuAT7b6JROIm5vu2IIQQvwm8F9glhDgP/DLwGeJIxUNCCICvhRD+fgjhGSHEvwOeJXY9fjGE4Nq/898AXyCOaPxaCOGZ63A+iUTiGiKu9g5uPlIXI5G4ITwaQrj/1TakSMpEIrEjyUAkEokdSQYikUjsSDIQiURiR5KBSCQSO5IMRCKR2JFkIBKJxI4kA5FIJHYkGYhEIrEjyUAkEokdSQYikUjsSDIQiURiR5KBSCQSO5IMRCKR2JFkIBKJxI4kA5FIJHYkGYhEIrEjyUAkEokdeU1p728AV4Bh+/l6setHvP6b4Rh+1Ou/3sdwaKcNN3VOSgAhxCM75ctL9f9oHMOPev2v5zGkLkYikdiRZCASicSOvBEMxGdT/a87r/cx/KjXD6/TMdz0PohEIvH68UZoQSQSideJZCASicSO3LQGQgjxISHESSHEGSHEp69THQeEEF8SQjwnhHhGCPHfteUzQoiHhBCn28/ptlwIIf5Ze0xPCiHuu0bHoYQQ3xJC/EH7/YgQ4utt/b/dCh7TiiL/dlv/14UQh69R/VNCiN8RQpxor8WP38hrIIT4H9rr/7QQ4jeFEMX1vgZCiF8TQswLIZ7eVvYDn7MQ4pPt/qdbxfvXUv8/bv8HTwohflcIMbVt22fa+k8KIT64rfz6PichhJtuIQr8Pg/cBmTAE8Bd16GeOeC+dn0AnALuAv5X4NNt+aeBX2nXPwL8MSCAdwFfv0bH8T8C/xb4g/b7vwM+0a7/KvBft+v/APjVdv0TwG9fo/p/Hfh77XoGTN2oawDsA84CnW3n/l9d72sAvAe4D3h6W9kPdM7ADPBC+zndrk+/hvofAHS7/ivb6r+rfQZy4Ej7bKgb8Zxc1wf9Ndw0Pw58Ydv3zwCfuQH1fg74GeAkMNeWzQEn2/V/Cfytbftv7fca6twPPAy8D/iD9ia8su1G2boWRHX0H2/XdbufeI31T7QPqPiO8htyDVoDca59yHR7DT54I64BcPg7HtAf6JyBvwX8y23l37bfD1r/d2z768BvvNr9v3kNbsRzcrN2MTZvmk3Ot2XXjbap+lbg68CeEMIlgPbzlut4XP8U+J8A336fBVZCCPZV6tiqv92+2u7/WrgNWAD+77ab86+EED1u0DUIIVwA/jfgZeAS8Zwe5cZeg01+0HO+nvfpzxNbLa9X/cDN64MQr1J23cZjhRB94D8A/30IYe177foqZT/0cQkhPgrMhxAe/SvWcT2uiyY2df9FCOGtxLkv36sve62vwTTwILHpvBfoAR/+HnXc0Hvj+9R5XY5FCPFLgAV+4/Wofzs3q4E4DxzY9n0/cPF6VCSEMETj8BshhP/YFl8WQsy12+eA+et0XO8GPiaEeBH4LWI3458CU0KIzYl02+vYqr/dPgksvYb6N//m+RDC19vvv0M0GDfqGnwAOBtCWAghNMB/BH6CG3sNNvlBz/ma36eto/OjwN8Obb/hRtb/ndysBuKbwLHWk50RnVGfv9aVCCEE8H8Bz4UQ/vdtmz4PbHqkP0n0TWyW/53Wq/0uYHWzSfrDEEL4TAhhfwjhMPEc/yyE8LeBLwF/Y4f6N4/rb7T7v6Y3RgjhFeCcEOKOtuj9wLPcoGtA7Fq8SwjRbf8fm/XfsGuwjR/0nL8APCCEmG5bQg+0ZT8UQogPAf8I+FgIYfQdx/WJdgTnCHAM+AY34jm5lg6Na7kQPceniF7aX7pOdfwksUn2JPB4u3yE2Kd9GDjdfs60+wvgn7fH9BRw/zU8lvdydRTjtvYGOAP8eyBvy4v2+5l2+23XqO57gUfa6/B7RI/8DbsGwP8MnACeBv4forf+ul4D4DeJPo+G+Cb+hR/mnIm+gjPt8ndfY/1niD6FzXvxV7ft/0tt/SeBD9+o5ySFWicSiR25WbsYiUTiJiAZiEQisSPJQCQSiR1JBiKRSOxIMhCJRGJHkoFIJBI7kgxEIpHYkf8fRRiCi6EgtgYAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2qIApnwh5pK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "e57dadee-f4eb-4bce-9c99-ae12d6d0b543"
      },
      "source": [
        "draw(out[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0jfQRuyqhHq"
      },
      "source": [
        "#Testing (Nuscene's Basics)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1v635cuk858"
      },
      "source": [
        "classes = nusc.get('category',)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVYn959sH3Pz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e1bafa7-c9fc-4a69-c631-391fb9189069"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Darknet(\n",
              "  (module_list): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_0): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_1): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_2): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_3): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (shortcut_4): EmptyLayer()\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_5): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_6): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_7): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (8): Sequential(\n",
              "      (shortcut_8): EmptyLayer()\n",
              "    )\n",
              "    (9): Sequential(\n",
              "      (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_9): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (10): Sequential(\n",
              "      (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_10): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (11): Sequential(\n",
              "      (shortcut_11): EmptyLayer()\n",
              "    )\n",
              "    (12): Sequential(\n",
              "      (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_12): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (13): Sequential(\n",
              "      (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_13): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (14): Sequential(\n",
              "      (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_14): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (15): Sequential(\n",
              "      (shortcut_15): EmptyLayer()\n",
              "    )\n",
              "    (16): Sequential(\n",
              "      (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_16): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (17): Sequential(\n",
              "      (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_17): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (18): Sequential(\n",
              "      (shortcut_18): EmptyLayer()\n",
              "    )\n",
              "    (19): Sequential(\n",
              "      (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_19): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (20): Sequential(\n",
              "      (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_20): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (21): Sequential(\n",
              "      (shortcut_21): EmptyLayer()\n",
              "    )\n",
              "    (22): Sequential(\n",
              "      (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_22): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (23): Sequential(\n",
              "      (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_23): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (24): Sequential(\n",
              "      (shortcut_24): EmptyLayer()\n",
              "    )\n",
              "    (25): Sequential(\n",
              "      (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_25): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (26): Sequential(\n",
              "      (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_26): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (27): Sequential(\n",
              "      (shortcut_27): EmptyLayer()\n",
              "    )\n",
              "    (28): Sequential(\n",
              "      (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_28): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (29): Sequential(\n",
              "      (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_29): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (30): Sequential(\n",
              "      (shortcut_30): EmptyLayer()\n",
              "    )\n",
              "    (31): Sequential(\n",
              "      (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_31): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (32): Sequential(\n",
              "      (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_32): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (33): Sequential(\n",
              "      (shortcut_33): EmptyLayer()\n",
              "    )\n",
              "    (34): Sequential(\n",
              "      (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_34): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (35): Sequential(\n",
              "      (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_35): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (36): Sequential(\n",
              "      (shortcut_36): EmptyLayer()\n",
              "    )\n",
              "    (37): Sequential(\n",
              "      (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_37): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (38): Sequential(\n",
              "      (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_38): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (39): Sequential(\n",
              "      (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_39): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (40): Sequential(\n",
              "      (shortcut_40): EmptyLayer()\n",
              "    )\n",
              "    (41): Sequential(\n",
              "      (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_41): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (42): Sequential(\n",
              "      (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_42): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (43): Sequential(\n",
              "      (shortcut_43): EmptyLayer()\n",
              "    )\n",
              "    (44): Sequential(\n",
              "      (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_44): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (45): Sequential(\n",
              "      (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_45): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (46): Sequential(\n",
              "      (shortcut_46): EmptyLayer()\n",
              "    )\n",
              "    (47): Sequential(\n",
              "      (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_47): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (48): Sequential(\n",
              "      (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_48): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (49): Sequential(\n",
              "      (shortcut_49): EmptyLayer()\n",
              "    )\n",
              "    (50): Sequential(\n",
              "      (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_50): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (51): Sequential(\n",
              "      (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_51): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (52): Sequential(\n",
              "      (shortcut_52): EmptyLayer()\n",
              "    )\n",
              "    (53): Sequential(\n",
              "      (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_53): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (54): Sequential(\n",
              "      (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_54): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (55): Sequential(\n",
              "      (shortcut_55): EmptyLayer()\n",
              "    )\n",
              "    (56): Sequential(\n",
              "      (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_56): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (57): Sequential(\n",
              "      (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_57): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (58): Sequential(\n",
              "      (shortcut_58): EmptyLayer()\n",
              "    )\n",
              "    (59): Sequential(\n",
              "      (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_59): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (60): Sequential(\n",
              "      (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_60): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (61): Sequential(\n",
              "      (shortcut_61): EmptyLayer()\n",
              "    )\n",
              "    (62): Sequential(\n",
              "      (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_62): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (63): Sequential(\n",
              "      (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_63): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (64): Sequential(\n",
              "      (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_64): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (65): Sequential(\n",
              "      (shortcut_65): EmptyLayer()\n",
              "    )\n",
              "    (66): Sequential(\n",
              "      (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_66): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (67): Sequential(\n",
              "      (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_67): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (68): Sequential(\n",
              "      (shortcut_68): EmptyLayer()\n",
              "    )\n",
              "    (69): Sequential(\n",
              "      (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_69): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (70): Sequential(\n",
              "      (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_70): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (71): Sequential(\n",
              "      (shortcut_71): EmptyLayer()\n",
              "    )\n",
              "    (72): Sequential(\n",
              "      (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_72): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (73): Sequential(\n",
              "      (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_73): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (74): Sequential(\n",
              "      (shortcut_74): EmptyLayer()\n",
              "    )\n",
              "    (75): Sequential(\n",
              "      (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_75): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (76): Sequential(\n",
              "      (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_76): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (77): Sequential(\n",
              "      (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_77): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (78): Sequential(\n",
              "      (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_78): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (79): Sequential(\n",
              "      (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_79): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (80): Sequential(\n",
              "      (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_80): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (81): Sequential(\n",
              "      (conv_81): Conv2d(1024, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (82): Sequential(\n",
              "      (yolo_82): YOLOLayer(\n",
              "        (mse_loss): MSELoss()\n",
              "        (bce_loss): BCELoss()\n",
              "      )\n",
              "    )\n",
              "    (83): Sequential(\n",
              "      (route_83): EmptyLayer()\n",
              "    )\n",
              "    (84): Sequential(\n",
              "      (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_84): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_84): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (85): Sequential(\n",
              "      (upsample_85): Upsample()\n",
              "    )\n",
              "    (86): Sequential(\n",
              "      (route_86): EmptyLayer()\n",
              "    )\n",
              "    (87): Sequential(\n",
              "      (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_87): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_87): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (88): Sequential(\n",
              "      (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_88): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_88): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (89): Sequential(\n",
              "      (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_89): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_89): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (90): Sequential(\n",
              "      (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_90): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_90): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (91): Sequential(\n",
              "      (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_91): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_91): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (92): Sequential(\n",
              "      (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_92): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_92): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (93): Sequential(\n",
              "      (conv_93): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (94): Sequential(\n",
              "      (yolo_94): YOLOLayer(\n",
              "        (mse_loss): MSELoss()\n",
              "        (bce_loss): BCELoss()\n",
              "      )\n",
              "    )\n",
              "    (95): Sequential(\n",
              "      (route_95): EmptyLayer()\n",
              "    )\n",
              "    (96): Sequential(\n",
              "      (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_96): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_96): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (97): Sequential(\n",
              "      (upsample_97): Upsample()\n",
              "    )\n",
              "    (98): Sequential(\n",
              "      (route_98): EmptyLayer()\n",
              "    )\n",
              "    (99): Sequential(\n",
              "      (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_99): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_99): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (100): Sequential(\n",
              "      (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_100): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_100): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (101): Sequential(\n",
              "      (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_101): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_101): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (102): Sequential(\n",
              "      (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_102): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_102): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (103): Sequential(\n",
              "      (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_103): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_103): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (104): Sequential(\n",
              "      (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_104): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "      (leaky_104): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (105): Sequential(\n",
              "      (conv_105): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (106): Sequential(\n",
              "      (yolo_106): YOLOLayer(\n",
              "        (mse_loss): MSELoss()\n",
              "        (bce_loss): BCELoss()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxTzVdt1HyNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac1b271-df32-49d3-cc08-c7f605a70757"
      },
      "source": [
        "img, label = next(iter(dataloader))\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 1184, 1184])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q89sfq4sHyPY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee8f2cf5-f9d8-4dfb-a58f-9a56faab6f6d"
      },
      "source": [
        "loss, out = model(img.to(device),label.to(device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:217: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:218: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:219: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:220: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:221: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:222: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:223: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:224: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:225: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:226: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:228: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:232: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:233: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:234: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EL2lkUEUaeZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2538f9e0-5e4f-499e-ad7b-beb97ff23bc9"
      },
      "source": [
        "print(non_max_suppression(out.to(device))[1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 11])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6K8n4CZT7Ft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14c726dd-6045-4fcf-d9c7-d2ac2f625efc"
      },
      "source": [
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 86247, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-DD17QtR2dq"
      },
      "source": [
        "del imgs,targets,out,loss\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgzPg8rc4Bse",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09b09246-a40c-4a3e-ee09-ab10d16f41a9"
      },
      "source": [
        "print(label[:,2].max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.8393)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rju84T256zm-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d9cfc4c-89f4-4450-9bc5-0871adf180e2"
      },
      "source": [
        "print(label[:,2].max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1982.4609)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3TwxDkCqj-g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08e44627-9bf0-4ef6-fbb5-2840a68bde2d"
      },
      "source": [
        "%matplotlib inline\n",
        "from nuscenes.nuscenes import NuScenes \n",
        "\n",
        "nusc = NuScenes(version='v1.0-mini', dataroot='drive/My Drive/data', verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======\n",
            "Loading NuScenes tables for version v1.0-mini...\n",
            "23 category,\n",
            "8 attribute,\n",
            "4 visibility,\n",
            "911 instance,\n",
            "12 sensor,\n",
            "120 calibrated_sensor,\n",
            "31206 ego_pose,\n",
            "8 log,\n",
            "10 scene,\n",
            "404 sample,\n",
            "31206 sample_data,\n",
            "18538 sample_annotation,\n",
            "4 map,\n",
            "Done loading in 1.387 seconds.\n",
            "======\n",
            "Reverse indexing ...\n",
            "Done reverse indexing in 0.1 seconds.\n",
            "======\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A13iNdjFqkm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2757e855-84de-40c4-fcb5-0b087ca3c486"
      },
      "source": [
        "scene = nusc.scene[0]\n",
        "scene"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'description': 'Parked truck, construction, intersection, turn left, following a van',\n",
              " 'first_sample_token': 'ca9a282c9e77460f8360f564131a8af5',\n",
              " 'last_sample_token': 'ed5fc18c31904f96a8f0dbb99ff069c0',\n",
              " 'log_token': '7e25a2c8ea1f41c5b0da1e69ecfa71a2',\n",
              " 'name': 'scene-0061',\n",
              " 'nbr_samples': 39,\n",
              " 'token': 'cc8c0bf57f984915a77078b10eb33198'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hkw-qStdrcmq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf69695-0ca8-4faa-deb4-de210e99c4d9"
      },
      "source": [
        "sample_token = scene['first_sample_token']\n",
        "sample = nusc.get('sample',sample_token)\n",
        "sample"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'anns': ['ef63a697930c4b20a6b9791f423351da',\n",
              "  '6b89da9bf1f84fd6a5fbe1c3b236f809',\n",
              "  '924ee6ac1fed440a9d9e3720aac635a0',\n",
              "  '91e3608f55174a319246f361690906ba',\n",
              "  'cd051723ed9c40f692b9266359f547af',\n",
              "  '36d52dfedd764b27863375543c965376',\n",
              "  '70af124fceeb433ea73a79537e4bea9e',\n",
              "  '63b89fe17f3e41ecbe28337e0e35db8e',\n",
              "  'e4a3582721c34f528e3367f0bda9485d',\n",
              "  'fcb2332977ed4203aa4b7e04a538e309',\n",
              "  'a0cac1c12246451684116067ae2611f6',\n",
              "  '02248ff567e3497c957c369dc9a1bd5c',\n",
              "  '9db977e264964c2887db1e37113cddaa',\n",
              "  'ca9c5dd6cf374aa980fdd81022f016fd',\n",
              "  '179b8b54ee74425893387ebc09ee133d',\n",
              "  '5b990ac640bf498ca7fd55eaf85d3e12',\n",
              "  '16140fbf143d4e26a4a7613cbd3aa0e8',\n",
              "  '54939f11a73d4398b14aeef500bf0c23',\n",
              "  '83d881a6b3d94ef3a3bc3b585cc514f8',\n",
              "  '74986f1604f047b6925d409915265bf7',\n",
              "  'e86330c5538c4858b8d3ffe874556cc5',\n",
              "  'a7bd5bb89e27455bbb3dba89a576b6a1',\n",
              "  'fbd9d8c939b24f0eb6496243a41e8c41',\n",
              "  '198023a1fb5343a5b6fad033ab8b7057',\n",
              "  'ffeafb90ecd5429cba23d0be9a5b54ee',\n",
              "  'cc636a58e27e446cbdd030c14f3718fd',\n",
              "  '076a7e3ec6244d3b84e7df5ebcbac637',\n",
              "  '0603fbaef1234c6c86424b163d2e3141',\n",
              "  'd76bd5dcc62f4c57b9cece1c7bcfabc5',\n",
              "  '5acb6c71bcd64aa188804411b28c4c8f',\n",
              "  '49b74a5f193c4759b203123b58ca176d',\n",
              "  '77519174b48f4853a895f58bb8f98661',\n",
              "  'c5e9455e98bb42c0af7d1990db1df0c9',\n",
              "  'fcc5b4b5c4724179ab24962a39ca6d65',\n",
              "  '791d1ca7e228433fa50b01778c32449a',\n",
              "  '316d20eb238c43ef9ee195642dd6e3fe',\n",
              "  'cda0a9085607438c9b1ea87f4360dd64',\n",
              "  'e865152aaa194f22b97ad0078c012b21',\n",
              "  '7962506dbc24423aa540a5e4c7083dad',\n",
              "  '29cca6a580924b72a90b9dd6e7710d3e',\n",
              "  'a6f7d4bb60374f868144c5ba4431bf4c',\n",
              "  'f1ae3f713ba946069fa084a6b8626fbf',\n",
              "  'd7af8ede316546f68d4ab4f3dbf03f88',\n",
              "  '91cb8f15ed4444e99470d43515e50c1d',\n",
              "  'bc638d33e89848f58c0b3ccf3900c8bb',\n",
              "  '26fb370c13f844de9d1830f6176ebab6',\n",
              "  '7e66fdf908d84237943c833e6c1b317a',\n",
              "  '67c5dbb3ddcc4aff8ec5140930723c37',\n",
              "  'eaf2532c820740ae905bb7ed78fb1037',\n",
              "  '3e2d17fa9aa5484d9cabc1dfca532193',\n",
              "  'de6bd5ffbed24aa59c8891f8d9c32c44',\n",
              "  '9d51d699f635478fbbcd82a70396dd62',\n",
              "  'b7cbc6d0e80e4dfda7164871ece6cb71',\n",
              "  '563a3f547bd64a2f9969278c5ef447fd',\n",
              "  'df8917888b81424f8c0670939e61d885',\n",
              "  'bb3ef5ced8854640910132b11b597348',\n",
              "  'a522ce1d7f6545d7955779f25d01783b',\n",
              "  '1fafb2468af5481ca9967407af219c32',\n",
              "  '05de82bdb8484623906bb9d97ae87542',\n",
              "  'bfedb0d85e164b7697d1e72dd971fb72',\n",
              "  'ca0f85b4f0d44beb9b7ff87b1ab37ff5',\n",
              "  'bca4bbfdef3d4de980842f28be80b3ca',\n",
              "  'a834fb0389a8453c810c3330e3503e16',\n",
              "  '6c804cb7d78943b195045082c5c2d7fa',\n",
              "  'adf1594def9e4722b952fea33b307937',\n",
              "  '49f76277d07541c5a584aa14c9d28754',\n",
              "  '15a3b4d60b514db5a3468e2aef72a90c',\n",
              "  '18cc2837f2b9457c80af0761a0b83ccc',\n",
              "  '2bfcc693ae9946daba1d9f2724478fd4'],\n",
              " 'data': {'CAM_BACK': '03bea5763f0f4722933508d5999c5fd8',\n",
              "  'CAM_BACK_LEFT': '43893a033f9c46d4a51b5e08a67a1eb7',\n",
              "  'CAM_BACK_RIGHT': '79dbb4460a6b40f49f9c150cb118247e',\n",
              "  'CAM_FRONT': 'e3d495d4ac534d54b321f50006683844',\n",
              "  'CAM_FRONT_LEFT': 'fe5422747a7d4268a4b07fc396707b23',\n",
              "  'CAM_FRONT_RIGHT': 'aac7867ebf4f446395d29fbd60b63b3b',\n",
              "  'LIDAR_TOP': '9d9bf11fb0e144c8b446d54a8a00184f',\n",
              "  'RADAR_BACK_LEFT': '312aa38d0e3e4f01b3124c523e6f9776',\n",
              "  'RADAR_BACK_RIGHT': '07b30d5eb6104e79be58eadf94382bc1',\n",
              "  'RADAR_FRONT': '37091c75b9704e0daa829ba56dfa0906',\n",
              "  'RADAR_FRONT_LEFT': '11946c1461d14016a322916157da3c7d',\n",
              "  'RADAR_FRONT_RIGHT': '491209956ee3435a9ec173dad3aaf58b'},\n",
              " 'next': '39586f9d59004284a7114a68825e8eec',\n",
              " 'prev': '',\n",
              " 'scene_token': 'cc8c0bf57f984915a77078b10eb33198',\n",
              " 'timestamp': 1532402927647951,\n",
              " 'token': 'ca9a282c9e77460f8360f564131a8af5'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0WDSEtHOK0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb95afc0-89c6-4a4e-8d01-97c7815145bb"
      },
      "source": [
        "for first_anno in sample['anns'] :\n",
        "  anno = nusc.get('sample_annotation',first_anno)\n",
        "  vis = nusc.get('visibility',anno['visibility_token'])\n",
        "  print(vis)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'description': 'visibility of whole object is between 0 and 40%', 'token': '1', 'level': 'v0-40'}\n",
            "{'description': 'visibility of whole object is between 40 and 60%', 'token': '2', 'level': 'v40-60'}\n",
            "{'description': 'visibility of whole object is between 60 and 80%', 'token': '3', 'level': 'v60-80'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 0 and 40%', 'token': '1', 'level': 'v0-40'}\n",
            "{'description': 'visibility of whole object is between 40 and 60%', 'token': '2', 'level': 'v40-60'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 40 and 60%', 'token': '2', 'level': 'v40-60'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 40 and 60%', 'token': '2', 'level': 'v40-60'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 0 and 40%', 'token': '1', 'level': 'v0-40'}\n",
            "{'description': 'visibility of whole object is between 0 and 40%', 'token': '1', 'level': 'v0-40'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 0 and 40%', 'token': '1', 'level': 'v0-40'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 40 and 60%', 'token': '2', 'level': 'v40-60'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 0 and 40%', 'token': '1', 'level': 'v0-40'}\n",
            "{'description': 'visibility of whole object is between 0 and 40%', 'token': '1', 'level': 'v0-40'}\n",
            "{'description': 'visibility of whole object is between 40 and 60%', 'token': '2', 'level': 'v40-60'}\n",
            "{'description': 'visibility of whole object is between 0 and 40%', 'token': '1', 'level': 'v0-40'}\n",
            "{'description': 'visibility of whole object is between 60 and 80%', 'token': '3', 'level': 'v60-80'}\n",
            "{'description': 'visibility of whole object is between 60 and 80%', 'token': '3', 'level': 'v60-80'}\n",
            "{'description': 'visibility of whole object is between 0 and 40%', 'token': '1', 'level': 'v0-40'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 40 and 60%', 'token': '2', 'level': 'v40-60'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 60 and 80%', 'token': '3', 'level': 'v60-80'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 0 and 40%', 'token': '1', 'level': 'v0-40'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 40 and 60%', 'token': '2', 'level': 'v40-60'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 0 and 40%', 'token': '1', 'level': 'v0-40'}\n",
            "{'description': 'visibility of whole object is between 0 and 40%', 'token': '1', 'level': 'v0-40'}\n",
            "{'description': 'visibility of whole object is between 60 and 80%', 'token': '3', 'level': 'v60-80'}\n",
            "{'description': 'visibility of whole object is between 0 and 40%', 'token': '1', 'level': 'v0-40'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 60 and 80%', 'token': '3', 'level': 'v60-80'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 60 and 80%', 'token': '3', 'level': 'v60-80'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 0 and 40%', 'token': '1', 'level': 'v0-40'}\n",
            "{'description': 'visibility of whole object is between 0 and 40%', 'token': '1', 'level': 'v0-40'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 60 and 80%', 'token': '3', 'level': 'v60-80'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n",
            "{'description': 'visibility of whole object is between 80 and 100%', 'token': '4', 'level': 'v80-100'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u035LGwgPRiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec34f518-7c50-47c1-c7c8-99daa9a837ba"
      },
      "source": [
        "vis = nusc.get('visibility',anno['visibility_token'])\n",
        "vis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'description': 'visibility of whole object is between 0 and 40%',\n",
              " 'level': 'v0-40',\n",
              " 'token': '1'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9b82vLGnJ4v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "2d32c171-6c7a-4c6f-dfd2-e96a6c7dd2cb"
      },
      "source": [
        "import json\n",
        "\n",
        "\n",
        "with open('/content/drive/My Drive/data/v1.0-mini/category.json') as f:\n",
        "  data = json.load(f)\n",
        "for d in data:\n",
        "  print(d['name'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "human.pedestrian.adult\n",
            "human.pedestrian.child\n",
            "human.pedestrian.wheelchair\n",
            "human.pedestrian.stroller\n",
            "human.pedestrian.personal_mobility\n",
            "human.pedestrian.police_officer\n",
            "human.pedestrian.construction_worker\n",
            "animal\n",
            "vehicle.car\n",
            "vehicle.motorcycle\n",
            "vehicle.bicycle\n",
            "vehicle.bus.bendy\n",
            "vehicle.bus.rigid\n",
            "vehicle.truck\n",
            "vehicle.construction\n",
            "vehicle.emergency.ambulance\n",
            "vehicle.emergency.police\n",
            "vehicle.trailer\n",
            "movable_object.barrier\n",
            "movable_object.trafficcone\n",
            "movable_object.pushable_pullable\n",
            "movable_object.debris\n",
            "static_object.bicycle_rack\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SLzR8LenKIE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "b6c32e34-7bb9-4eab-f3f3-6577eaecc7d5"
      },
      "source": [
        "img,targets = iter(dataloader).next()\n",
        "plt.imshow(  img[0].permute(1, 2, 0)  )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1b0582a5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvAnhNUPhFgU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61f9f234-19e5-4919-bc14-6ce530b34873"
      },
      "source": [
        "output = model(img.to(device))\n",
        "print(output[...,8].max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.9947)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX05wMiohJNz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a34bb29-1ead-4d03-c55e-f21ecfd27f9b"
      },
      "source": [
        "output = non_max_suppression(output,conf_thres=0.9)\n",
        "print(output[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 11])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw4rYBEDWKaY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "bea4e00b-1ef4-47d4-a455-c83b3053007e"
      },
      "source": [
        "print(targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0000e+00, 0.0000e+00, 4.7458e-01,  ..., 3.2640e-01, 1.1154e-03,\n",
            "         4.6662e-01],\n",
            "        [0.0000e+00, 0.0000e+00, 5.0075e-01,  ..., 3.5600e-01, 5.4577e-01,\n",
            "         9.9790e-01],\n",
            "        [0.0000e+00, 8.0000e+00, 7.4861e-01,  ..., 3.0260e-01, 3.0156e-01,\n",
            "         4.1066e-02],\n",
            "        ...,\n",
            "        [1.0000e+00, 1.8000e+01, 4.8719e-01,  ..., 2.3620e-01, 3.9791e-01,\n",
            "         1.0534e-02],\n",
            "        [1.0000e+00, 1.9000e+01, 7.3987e-01,  ..., 1.5480e-01, 9.9424e-01,\n",
            "         5.7565e-01],\n",
            "        [1.0000e+00, 1.9000e+01, 3.6606e-01,  ..., 1.3800e-01, 7.7270e-02,\n",
            "         7.6702e-01]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU7biujtWx1R"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import matplotlib as mpl\n",
        "import matplotlib.patches as patches\n",
        "from IPython.display import clear_output\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcQwss6bXKoR"
      },
      "source": [
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "ax = fig.add_subplot(111)\n",
        "for annotation in targets:\n",
        "  annotation = nusc.get('sample_annotation',annotation)\n",
        "  cordinate = [annotation['translation'][i] - ego_pose['translation'][i] for i in range(3)]\n",
        "  cordinate[0], cordinate[1] = rotate_around_point_lowperf(cordinate[:2], ego_yaw, origin=(0, 0))\n",
        "  rotation_yaw = quaternion_yaw(annotation['rotation']) - math.pi/2\n",
        "  print(\"rotation_yaw = \", quaternion_yaw(annotation['rotation']) + math.pi )\n",
        "  object_rotation = rotation_yaw - ego_yaw\n",
        "  height = annotation['size'][0]\n",
        "  width = annotation['size'][1]\n",
        "  x_temp, y_temp = rotate_around_point_lowperf((cordinate[0],cordinate[1]),2*math.pi -  (object_rotation+math.pi/2), origin=(cordinate[0]-width/2, cordinate[1] - height/2))\n",
        "  x_offset, y_offset = x_temp - cordinate[0], y_temp - cordinate[1]\n",
        "  rectas = patches.Rectangle(xy=((cordinate[0]-width/2) - x_offset, (cordinate[1] - height/2) - y_offset) ,width=width, angle = (object_rotation+math.pi/2)*180/math.pi, height=height, linewidth=1, color='blue', fill=False)\n",
        "  ax.add_patch(rectas)\n",
        "  ax.scatter(cordinate[0], cordinate[1], color = 'red', s=10)\n",
        "  break\n",
        "ax.scatter(0, 0)\n",
        "plt.xlim(-80,80)\n",
        "plt.ylim(-80,80)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xsHPdyHjeJ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5c344ee7-135c-4ae3-cfee-5b98fa617b5e"
      },
      "source": [
        "dataset.categories[18]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'movable_object.barrier'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwvIc7iFZ__d"
      },
      "source": [
        "#Angle testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbhkMNF-aCGL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5c6caf94-8306-4097-bc84-e906730bed04"
      },
      "source": [
        "#30degree\n",
        "rotation_yaw = 0\n",
        "r1 = (1 + math.sin(rotation_yaw))/2\n",
        "r2 = (1 + math.cos(rotation_yaw))/2\n",
        "print(r1,r2)\n",
        "teta1 = math.asin(2*r1 - 1)\n",
        "teta2 = math.acos(2*r2 - 1)\n",
        "print(teta1,teta2)\n",
        "print(angle_decoder([r1,r2])*180/math.pi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5 1.0\n",
            "0.0 0.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT11qiCtaLLS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "317537dc-fd14-4746-cdc2-d7675279f749"
      },
      "source": [
        "#120degree\n",
        "rotation_yaw = math.pi/2 \n",
        "r1 = (1 + math.sin(rotation_yaw))/2\n",
        "r2 = (1 + math.cos(rotation_yaw))/2\n",
        "print(r1,r2)\n",
        "teta1 = math.asin(2*r1 - 1)\n",
        "teta2 = math.acos(2*r2 - 1)\n",
        "print(teta1,teta2)\n",
        "print(angle_decoder([r1,r2])*180/math.pi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0 0.5\n",
            "1.5707963267948966 1.5707963267948966\n",
            "90.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjJ5mE2TaN6H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7ba8beba-ad6b-4538-da10-41a70485e032"
      },
      "source": [
        "#210degree\n",
        "rotation_yaw = math.pi\n",
        "r1 = (1 + math.sin(rotation_yaw))/2\n",
        "r2 = (1 + math.cos(rotation_yaw))/2\n",
        "print(r1,r2)\n",
        "teta1 = math.asin(2*r1 - 1)\n",
        "teta2 = math.acos(2*r2 - 1)\n",
        "print(teta1,teta2)\n",
        "print(angle_decoder([r1,r2])*180/math.pi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5000000000000001 0.0\n",
            "2.220446049250313e-16 3.141592653589793\n",
            "180.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXNmm2SQavVU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b7f0c088-e125-4c9f-bcb1-51b081760cb6"
      },
      "source": [
        "#300degree\n",
        "rotation_yaw = 3*math.pi/2\n",
        "r1 = (1 + math.sin(rotation_yaw))/2\n",
        "r2 = (1 + math.cos(rotation_yaw))/2\n",
        "print(r1,r2)\n",
        "teta1 = math.asin(2*r1 - 1)\n",
        "teta2 = math.acos(2*r2 - 1)\n",
        "print(teta1,teta2)\n",
        "print(angle_decoder([r1,r2])*180/math.pi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 0.4999999999999999\n",
            "-1.5707963267948966 1.5707963267948968\n",
            "270.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TGwbnheayIx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_2iY7HwCTlm"
      },
      "source": [
        "#Intersection Area Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLZVErYZxX4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "981748f9-b220-487c-f394-b8263b135038"
      },
      "source": [
        "from turfpy.transformation import intersect\n",
        "from turfpy.measurement import area\n",
        "from geojson import Feature\n",
        "f = Feature(geometry={\"coordinates\": [\n",
        "[[-122.801742, 45.48565], [-122.801742, 45.60491],\n",
        "[-122.584762, 45.60491], [-122.584762, 45.48565],\n",
        "[-122.801742, 45.48565]]], \"type\": \"Polygon\"})\n",
        "b = Feature(geometry={\"coordinates\": [\n",
        "[[-122.520217, 45.535693], [-122.64038, 45.553967],\n",
        "[-122.720031, 45.526554], [-122.669906, 45.507309],\n",
        "[-122.723464, 45.446643], [-122.532577, 45.408574],\n",
        "[-122.487258, 45.477466], [-122.520217, 45.535693]\n",
        "]], \"type\": \"Polygon\"})\n",
        "inter = intersect([f, b])\n",
        "area(inter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56901155.05995309"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CePQxQ8Uxaye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dc7c7f0-4be8-40bf-957a-5f31e8e5d2b3"
      },
      "source": [
        "!pip install turfpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting turfpy\n",
            "  Downloading https://files.pythonhosted.org/packages/00/9f/3327e2fbddbad1585acf37dcc9aababda0cb007c2d8180a3ae0251fa4339/turfpy-0.0.4.tar.gz\n",
            "Collecting geojson\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/8d/9e28e9af95739e6d2d2f8d4bef0b3432da40b7c3588fbad4298c1be09e48/geojson-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from turfpy) (1.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from turfpy) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from turfpy) (1.18.5)\n",
            "Building wheels for collected packages: turfpy\n",
            "  Building wheel for turfpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for turfpy: filename=turfpy-0.0.4-cp36-none-any.whl size=32317 sha256=76b9dc9f683d5b6eae6f404c1b15fd5ee26c92a78086a865e43952be574641aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/5a/1f/216423b705f113c02e3c287b8c5ce31df9a8c6a5526c4da56c\n",
            "Successfully built turfpy\n",
            "Installing collected packages: geojson, turfpy\n",
            "Successfully installed geojson-2.5.0 turfpy-0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HSDxXySxjqN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}